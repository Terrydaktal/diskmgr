#!/usr/bin/env python3
import cmd
import subprocess
import os
import sys
import shlex
import csv
import json
import time
import argparse
import random
import re
import shutil
import datetime
import threading
import atexit
import pwd
import grp
from pathlib import Path
try:
    import readline
except ImportError:
    readline = None

# Configuration
MAP_FILENAME = 'diskmap.tsv'
PASSGEN_BIN = 'passgen'
VERSION = '3.3.0'
HISTORY_FILE_ENV = 'DISKMGR_HISTORY'
DEFAULT_HISTORY_FILE = Path.home() / '.local' / 'state' / 'diskmgr' / 'history'
MAX_HISTORY_ENTRIES = 5000

# ANSI Colors
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

_CMD_LOG_FH = None
_CMD_LOG_PATH = None

def _cmd_log_write(text):
    global _CMD_LOG_FH
    if _CMD_LOG_FH is None:
        return
    try:
        _CMD_LOG_FH.write(text)
        if not text.endswith("\n"):
            _CMD_LOG_FH.write("\n")
        _CMD_LOG_FH.flush()
    except Exception:
        # Best-effort logging: never break the tool because logs can't be written.
        pass

def _cmd_log_open(prefix):
    """Enable per-command logging to /tmp; returns the path."""
    global _CMD_LOG_FH, _CMD_LOG_PATH
    try:
        ts = int(time.time())
        path = f"/tmp/diskmgr_{prefix}_{os.getpid()}_{ts}.log"
        _CMD_LOG_FH = open(path, "w", encoding="utf-8", errors="replace")
        _CMD_LOG_PATH = path
        _cmd_log_write(f"# diskmgr {VERSION}")
        _cmd_log_write(f"# started: {datetime.datetime.now().isoformat(sep=' ', timespec='seconds')}")
        return path
    except Exception:
        _CMD_LOG_FH = None
        _CMD_LOG_PATH = None
        return None

def _cmd_log_close():
    global _CMD_LOG_FH, _CMD_LOG_PATH
    try:
        if _CMD_LOG_FH is not None:
            _cmd_log_write(f"# ended: {datetime.datetime.now().isoformat(sep=' ', timespec='seconds')}")
            _CMD_LOG_FH.close()
    except Exception:
        pass
    _CMD_LOG_FH = None
    _CMD_LOG_PATH = None

def log(msg, level='INFO'):
    _cmd_log_write(f"[{datetime.datetime.now().isoformat(sep=' ', timespec='seconds')}] {level}: {msg}")
    if level == 'ERROR':
        print(f"{Colors.FAIL}ERROR: {msg}{Colors.ENDC}", file=sys.stderr)
    elif level == 'WARN':
        print(f"{Colors.WARNING}WARNING: {msg}{Colors.ENDC}", file=sys.stderr)
    else:
        print(f"{Colors.OKBLUE}diskmgr: {msg}{Colors.ENDC}")

def _fmt_hms(total_seconds):
    s = int(max(total_seconds, 0))
    h = s // 3600
    m = (s % 3600) // 60
    sec = s % 60
    return f"{h:02d}:{m:02d}:{sec:02d}"

def run_command(command, check=True, input_str=None, capture_output=True, sudo=False):
    if sudo:
        command = ['sudo'] + command
    
    try:
        start_ts = time.time()
        _cmd_log_write(f"[{datetime.datetime.now().isoformat(sep=' ', timespec='seconds')}] CMD: {' '.join(command)}")
        result = subprocess.run(
            command,
            input=input_str,
            text=True,
            check=check,
            stdout=subprocess.PIPE if capture_output else None,
            stderr=subprocess.PIPE if capture_output else None
        )
        _cmd_log_write(f"RC: {getattr(result, 'returncode', 0)}  elapsed={_fmt_hms(time.time() - start_ts)}")
        if capture_output:
            out = getattr(result, 'stdout', '') or ''
            err = getattr(result, 'stderr', '') or ''
            if out.strip():
                _cmd_log_write("--- STDOUT ---")
                _cmd_log_write(out.rstrip())
            if err.strip():
                _cmd_log_write("--- STDERR ---")
                _cmd_log_write(err.rstrip())
        return result
    except subprocess.CalledProcessError as e:
        if check:
            log(f"Command failed: {' '.join(command)}", 'ERROR')
            if e.stderr:
                log(e.stderr.strip(), 'ERROR')
            raise
        return e

def _split_nonempty_lines(s):
    if not s:
        return []
    out = []
    for line in str(s).splitlines():
        line = line.strip()
        if line and line not in out:
            out.append(line)
    return out

def find_mount_targets(source):
    """
    Return a list of mount TARGETs for a given SOURCE.

    Notes:
    - A single filesystem can be mounted at multiple targets; findmnt will then
      return multiple lines. Callers must not treat stdout as a single path.
    - We resolve the source to a real path so /dev/mapper/<name> and /dev/dm-X
      match the same mount.
    """
    src_real = os.path.realpath(source)
    res = run_command(['findmnt', '-rn', '-S', src_real, '-o', 'TARGET'], check=False)
    if getattr(res, 'returncode', 1) != 0:
        return []
    return _split_nonempty_lines(getattr(res, 'stdout', ''))

def cleanup_mountpoint_dir(mountpoint):
    """
    Best-effort cleanup of a mountpoint directory after unmount.

    Only attempts removal for mountpoints under /media/$USER/ and only if the
    directory is no longer a mount target. Uses rmdir (so it only removes empty
    directories) to avoid deleting real data.
    """
    if not mountpoint:
        return

    user = os.environ.get('USER', 'root')
    media_root = os.path.realpath(f"/media/{user}")
    mp_real = os.path.realpath(mountpoint)
    if not (mp_real == media_root or mp_real.startswith(media_root + os.sep)):
        return

    # Still mounted? Don't touch it.
    if run_command(['findmnt', '-rn', '-M', mountpoint], check=False).returncode == 0:
        return

    res = run_command(['rmdir', mountpoint], sudo=True, check=False)
    if getattr(res, 'returncode', 1) == 0:
        log(f"Removed mountpoint directory {mountpoint}")

def _sysfs_block_name(dev_path):
    """Return kernel block name (e.g. sda2, nvme0n1p1, dm-0) for a /dev path."""
    return os.path.basename(os.path.realpath(dev_path))

def _sysfs_to_parent_disk_name(block_name, max_hops=16):
    """
    Best-effort: resolve a block device name to its underlying whole-disk name.

    - Partitions: sda2 -> sda, nvme0n1p1 -> nvme0n1
    - dm devices: dm-0 -> first slave (often sda2), then keep resolving
    """
    cur = block_name
    for _ in range(max_hops):
        sys_path = f"/sys/class/block/{cur}"
        if not os.path.exists(sys_path):
            break

        # If it's a device-mapper node, walk down to its first slave.
        if cur.startswith("dm-"):
            slaves_dir = os.path.join(sys_path, "slaves")
            try:
                slaves = sorted(os.listdir(slaves_dir)) if os.path.isdir(slaves_dir) else []
            except Exception:
                slaves = []
            if slaves:
                cur = slaves[0]
                continue
            break

        # If it's a partition, its parent is the directory above in sysfs.
        if os.path.exists(os.path.join(sys_path, "partition")):
            parent = os.path.basename(os.path.realpath(os.path.join(sys_path, "..")))
            if parent and parent != cur:
                cur = parent
                continue
            break

        # Already a whole-disk node (or at least not a partition we can detect).
        break

    return cur

#
# NOTE: refresh-related helpers were removed along with the refresh command.
#

def _parse_smart_attr_raw(out, attr_id):
    """
    Parse a smartctl -a attribute table RAW_VALUE for a given attribute ID.
    Returns a string (raw value) or None.
    """
    if not out:
        return None
    for line in str(out).splitlines():
        s = line.strip()
        if not s:
            continue
        # Attribute table rows typically start with the numeric ID.
        if not s.startswith(str(attr_id) + " "):
            continue
        parts = s.split()
        if len(parts) < 2 or parts[0] != str(attr_id):
            continue
        # Old format: ID NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW...
        if len(parts) >= 10 and re.fullmatch(r"0x[0-9a-fA-F]+", parts[2]):
            return " ".join(parts[9:]).strip()
        # Brief format: ID NAME FLAGS VALUE WORST THRESH FAIL RAW...
        if len(parts) >= 8:
            return " ".join(parts[7:]).strip()
        # Fallback
        return parts[-1]
    return None

def _parse_smart_attr_row(out, attr_id):
    """
    Parse a smartctl -a attribute table row for a given attribute ID.

    Supports both smartctl ATA table formats:
      old:   ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE
      brief: ID# ATTRIBUTE_NAME FLAGS VALUE WORST THRESH FAIL RAW_VALUE
    RAW_VALUE may contain spaces (e.g. temperatures with Min/Max), so we capture the tail.
    """
    if not out:
        return None
    for line in str(out).splitlines():
        s = line.strip()
        if not s or not s.startswith(str(attr_id) + " "):
            continue
        parts = s.split()
        if len(parts) < 8 or parts[0] != str(attr_id):
            continue

        name = parts[1]
        try:
            # Old format has a hex flag in column 3.
            if re.fullmatch(r"0x[0-9a-fA-F]+", parts[2]) and len(parts) >= 10:
                value = int(parts[3], 10)
                worst = int(parts[4], 10)
                thresh = int(parts[5], 10)
                raw = " ".join(parts[9:]).strip()
            else:
                # Brief format.
                value = int(parts[3], 10)
                worst = int(parts[4], 10)
                thresh = int(parts[5], 10)
                raw = " ".join(parts[7:]).strip()
        except ValueError:
            continue

        return {
            "id": int(attr_id),
            "name": name,
            "value": value,
            "worst": worst,
            "thresh": thresh,
            "raw": raw,
        }
    return None

def _first_int_from_text(s):
    if s is None:
        return None
    m = re.search(r"([0-9][0-9,]*)", str(s))
    if not m:
        return None
    try:
        return int(m.group(1).replace(",", ""), 10)
    except ValueError:
        return None

def _parse_smart_error_log_count(out):
    if not out:
        return None
    lines = str(out).splitlines()
    for i, line in enumerate(lines):
        if "SMART Error Log" in line:
            # Fast-path: "No Errors Logged"
            for j in range(i, min(i + 40, len(lines))):
                if lines[j].strip() == "No Errors Logged":
                    return 0
            # Otherwise count "Error N occurred at" lines in the next chunk.
            cnt = 0
            for j in range(i, min(i + 300, len(lines))):
                if re.search(r"^\s*Error\s+[0-9]+\s+occurred\s+at\b", lines[j]):
                    cnt += 1
            return cnt
    return None

def _parse_smart_last_error_poh(out):
    """
    Parse the most recent ATA SMART Error Log entry's power-on lifetime (hours).

    smartctl typically formats the most recent entry as:
      "Error 667 occurred at disk power-on lifetime: 20140 hours (839 days + 4 hours)"
    Note: The error number is not necessarily "1" (it can be a running counter).

    Returns (error_number, power_on_hours) or (None, None) if not found / not an ATA SMART error log.
    """
    if not out:
        return (None, None)
    m = re.search(
        r"(?m)^\s*Error\s+([0-9]+)\s+occurred\s+at\s+disk\s+power-on\s+lifetime:\s*([0-9,]+)\s*(?:hours|h)\b",
        str(out),
    )
    if not m:
        return (None, None)
    try:
        n = int(m.group(1), 10)
        h = int(m.group(2).replace(",", ""), 10)
        return (n, h)
    except ValueError:
        return (None, None)

def _smartctl_looks_seagate(out):
    if not out:
        return False
    # Common smartctl identifiers for Seagate HDDs.
    if re.search(r"(?im)^Model Family:.*Seagate", out):
        return True
    if re.search(r"(?im)^(Device Model|Product):\s*Seagate", out):
        return True
    # Most Seagate HDDs report model starting with "ST".
    if re.search(r"(?im)^Device Model:\s*ST[0-9A-Z]", out):
        return True
    return False

def _decode_seagate_command_timeout(raw_val):
    """
    Seagate often packs SMART 188 into 6 bytes (3x 16-bit counters).

    smartctl prints the entire 48-bit value as a decimal integer, which can look huge.
    Decode it as:
      hi word:  >7.5s bucket (included in >5s)
      mid word: >5s bucket
      lo word:  total command timeouts
    """
    if raw_val is None:
        return None
    s = str(raw_val).strip().replace(",", "")
    if not s or not re.fullmatch(r"[0-9]+", s):
        return None
    try:
        v = int(s, 10)
    except ValueError:
        return None
    if v < 0 or v >= (1 << 48):
        return None
    hx = f"{v:012x}"  # 6 bytes
    hi = int(hx[0:4], 16)
    mid = int(hx[4:8], 16)
    lo = int(hx[8:12], 16)
    return {
        "raw_int": v,
        "hex": "0x" + hx,
        "timeouts": lo,
        "gt_5s": mid,
        "gt_7_5s": hi,
    }

def _decode_seagate_hi16_lo32(raw_val):
    """
    Common Seagate packing for some SMART RAW fields:
      RAW = (hi16_error_count << 32) | lo32_operation_count

    This is often seen for attribute 1 (Raw_Read_Error_Rate) and 7 (Seek_Error_Rate),
    where RAW is not "number of errors" in the intuitive sense.

    Returns dict with raw_int, hex, errors, ops; or None if not parseable.
    """
    if raw_val is None:
        return None
    s = str(raw_val).strip().replace(",", "")
    if not s or not re.fullmatch(r"[0-9]+", s):
        return None
    try:
        v = int(s, 10)
    except ValueError:
        return None
    if v < 0 or v >= (1 << 48):
        return None
    return {
        "raw_int": v,
        "hex": f"0x{v:012x}",
        "errors": (v >> 32) & 0xFFFF,
        "ops": v & 0xFFFFFFFF,
    }

def _parse_smart_long_selftest_failures(out):
    """
    Count non-success statuses in the SMART Self-test log for extended/long tests.
    Returns an int or None if the section isn't present.
    """
    if not out:
        return None
    lines = str(out).splitlines()
    start = None
    for i, line in enumerate(lines):
        if "SMART Self-test log" in line:
            start = i
            break
    if start is None:
        return None

    # Find the table header line with "#"
    header = None
    for i in range(start, min(start + 60, len(lines))):
        if lines[i].lstrip().startswith("#"):
            header = i
            break
        if "No self-tests have been logged" in lines[i]:
            return 0
    if header is None:
        # Section exists but we couldn't find the table.
        return None

    fail = 0
    for i in range(header + 1, min(header + 200, len(lines))):
        line = lines[i].strip()
        if not line:
            break
        if not line.startswith("#"):
            continue
        # Common format: "# 1  Extended offline  Completed without error  00%  1234  -"
        cols = line.split()
        if len(cols) < 4:
            continue
        desc = " ".join(cols[2:4])  # "Extended offline" or "Short offline"
        if "Extended offline" not in desc and "Long offline" not in desc:
            continue
        # Status begins after description; search the raw line for "Completed without error"
        if "Completed without error" in line:
            continue
        fail += 1
    return fail

def _find_tool_or_common_paths(tool_name, common_paths):
    """
    Find an executable by PATH, or fall back to common sbin locations.

    This avoids failures when running as a normal user with /usr/sbin not in PATH.
    Returns an absolute path or None.
    """
    p = shutil.which(tool_name)
    if p:
        return p
    for cp in common_paths:
        try:
            if cp and os.path.exists(cp) and os.access(cp, os.X_OK):
                return cp
        except Exception:
            continue
    return None

def _parse_ddrescue_failed_ranges(map_path, sector_size=512):
    """
    Return a list of failed ranges from a ddrescue mapfile.

    ddrescue map lines are typically: <start_hex> <size_hex> <status_char>
    We treat status '-' as "unrecovered".
    Ranges are returned as dicts with byte and sector offsets.
    """
    if not map_path or not os.path.exists(map_path):
        return []
    try:
        ss = int(sector_size)
        if ss <= 0:
            ss = 512
    except Exception:
        ss = 512

    out = []
    try:
        with open(map_path, 'r', encoding='utf-8', errors='replace') as f:
            for raw in f:
                line = raw.strip()
                if not line or line.startswith('#'):
                    continue
                parts = line.split()
                if len(parts) < 3:
                    continue
                a, b, st = parts[0], parts[1], parts[2]
                if not (a.startswith('0x') and b.startswith('0x') and st):
                    continue
                if st[0] != '-':
                    continue
                try:
                    start_b = int(a, 16)
                    size_b = int(b, 16)
                except ValueError:
                    continue
                if size_b <= 0:
                    continue
                end_b = start_b + size_b
                # Prefer reporting in sectors, but keep bytes if not aligned.
                start_lba = start_b // ss
                end_lba = (end_b + ss - 1) // ss  # ceil
                out.append({
                    "start_b": start_b,
                    "end_b": end_b,
                    "size_b": size_b,
                    "start_lba": start_lba,
                    "end_lba": end_lba,
                    "count_lba": max(0, end_lba - start_lba),
                })
    except Exception:
        return []
    return out

def _lsblk_type(dev_path):
    res = run_command(['lsblk', '-no', 'TYPE', dev_path], check=False)
    return (getattr(res, 'stdout', '') or '').strip()

def _lsblk_fstype(dev_path):
    res = run_command(['lsblk', '-no', 'FSTYPE', dev_path], check=False)
    out = (getattr(res, 'stdout', '') or '')
    # lsblk may return multiple rows (device + children); use only the target's first row.
    for line in out.splitlines():
        line = line.strip()
        if line:
            return line
    return ""

def _lsblk_partitions(dev_path):
    """
    Return a list of partitions under a disk device (NAME, FSTYPE).
    """
    res = run_command(['lsblk', '-nr', '-o', 'NAME,TYPE,FSTYPE', dev_path], check=False)
    rows = []
    for raw in (getattr(res, 'stdout', '') or '').splitlines():
        line = raw.strip()
        if not line:
            continue
        parts = line.split(None, 2)
        if len(parts) < 2:
            continue
        n, t = parts[0], parts[1]
        fs = parts[2].strip() if len(parts) >= 3 else ""
        if t == 'part':
            rows.append({"name": n, "fstype": fs})
    return rows

def get_script_dir():
    return Path(__file__).resolve().parent

def get_map_file_path():
    return get_script_dir() / MAP_FILENAME

def read_luks_map():
    map_file = get_map_file_path()
    if not map_file.exists():
        return {}
    
    mappings = {}
    with open(map_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split(None, 1) # Split on first whitespace
            if len(parts) == 2:
                name, path = parts
                mappings[name] = path
    return mappings

def save_luks_map(mappings):
    map_file = get_map_file_path()
    with open(map_file, 'w') as f:
        for name, path in mappings.items():
            f.write(f"{name}\t{path}\n")

def disk_base_name(dev_path):
    # Given /dev/sdb or /dev/sdb1 -> sdb
    try:
        dev_name = os.path.basename(dev_path)
        # simplistic, better to use lsblk
        res = run_command(['lsblk', '-no', 'PKNAME', dev_path], check=False)
        if res.stdout.strip():
            return res.stdout.strip()
        return dev_name
    except:
        return os.path.basename(dev_path)

def disk_is_nvme(dev_path):
    # Check if NVMe
    try:
        res = run_command(['lsblk', '-dno', 'TRAN', dev_path], check=False)
        if res.stdout.strip() == 'nvme':
            return True
        if 'nvme' in dev_path:
            return True
    except:
        pass
    return False

def disk_is_rotational(dev_path):
    try:
        base = disk_base_name(dev_path)
        p = Path(f"/sys/block/{base}/queue/rotational")
        if p.exists():
            return p.read_text().strip() == "1"
    except:
        pass
    return False

def disk_discard_supported(dev_path):
    try:
        res = run_command(['lsblk', '-dno', 'DISC-MAX', dev_path], check=False)
        val = res.stdout.strip()
        return val and val != "0B" and val != "0"
    except:
        return False

def secure_erase_disk(dev_path):
    if not os.path.exists(dev_path):
        log(f"Device not found: {dev_path}", 'ERROR')
        return False

    # Detect if partition or disk
    is_part = False
    try:
        res = run_command(['lsblk', '-dno', 'TYPE', dev_path], capture_output=True)
        if res.stdout.strip() == 'part':
            is_part = True
    except:
        pass

    target_type = "PARTITION" if is_part else "FULL DISK"
    log(f"Starting secure erase on {dev_path} ({target_type})")

    if disk_is_nvme(dev_path):
        if is_part:
            log("NVMe hardware-level erase (Sanitize/Format) skipped: Target is a partition, not a full disk.", 'WARN')
        else:
            # Query capabilities
            try:
                res = run_command(['nvme', 'id-ctrl', '-o', 'json', dev_path], sudo=True, capture_output=True)
                ctrl_data = json.loads(res.stdout)
                oacs = ctrl_data.get('oacs', 0)
                sanicap = ctrl_data.get('sanicap', 0)
                fna = ctrl_data.get('fna', 0)
                
                can_format = bool(oacs & 0x02)
                can_format_block = can_format # Baseline if Format is supported
                can_format_crypto = can_format and bool(fna & 0x04)
                can_sanitize_block = bool(sanicap & 0x02)
                can_sanitize_crypto = bool(sanicap & 0x01)
                
                # 1. Sanitize Crypto Erase (Priority 1)
                if can_sanitize_crypto:
                    log(f"Attempting NVMe Sanitize Crypto Erase (Action 4) on {dev_path}...")
                    try:
                        run_command(['nvme', 'sanitize', dev_path, '-a', '4'], sudo=True)
                        run_command(['udevadm', 'settle'], sudo=True)
                        log("NVMe Sanitize Crypto Erase completed successfully.")
                        return True
                    except Exception as e:
                        log(f"NVMe Sanitize Crypto Erase failed: {e}. Falling back...", 'WARN')

                # 2. Sanitize Block Erase (Priority 2)
                if can_sanitize_block:
                    log(f"Attempting NVMe Sanitize Block Erase (Action 2) on {dev_path}...")
                    try:
                        run_command(['nvme', 'sanitize', dev_path, '-a', '2'], sudo=True)
                        run_command(['udevadm', 'settle'], sudo=True)
                        log("NVMe Sanitize Block Erase completed successfully.")
                        return True
                    except Exception as e:
                        log(f"NVMe Sanitize Block Erase failed: {e}. Falling back...", 'WARN')

                # 3. Format Crypto Erase (Priority 3)
                if can_format_crypto:
                    log(f"Attempting NVMe Format Crypto Erase (SES 2) on {dev_path}...")
                    try:
                        run_command(['nvme', 'format', dev_path, '--ses=2'], sudo=True)
                        run_command(['udevadm', 'settle'], sudo=True)
                        log("NVMe Format Crypto Erase completed successfully.")
                        return True
                    except Exception as e:
                        log(f"NVMe Format Crypto Erase failed: {e}. Falling back...", 'WARN')

                # 4. Format Block Erase (Last NVMe Fallback)
                if can_format_block:
                    log(f"Attempting NVMe Format Block Erase (SES 1) on {dev_path}...")
                    try:
                        run_command(['nvme', 'format', dev_path, '--ses=1'], sudo=True)
                        run_command(['udevadm', 'settle'], sudo=True)
                        log("NVMe Format Block Erase completed successfully.")
                        return True
                    except Exception as e:
                        log(f"NVMe Format Block Erase failed: {e}. Falling back...", 'WARN')
                
                log("No supported NVMe hardware erase methods found. Falling back to software discard/overwrite.")

            except Exception as e:
                log(f"Failed to query NVMe capabilities: {e}. Falling back to software methods.", 'WARN')

    elif not disk_is_rotational(dev_path):
        # SSD/Flash (SATA/SAS)
        if is_part:
            log("SATA SSD hardware-level erase (ATA Sanitize/Secure Erase) skipped: Target is a partition.", 'WARN')
        else:
            # 1. PSID Revert / TCG Opal (Placeholder)
            log(f"Checking for PSID Revert / TCG Opal support (Currently Unimplemented)...")

            # 2. ATA Sanitize
            try:
                res = run_command(['hdparm', '-I', dev_path], sudo=True, capture_output=True)
                if "sanitize" in res.stdout.lower():
                     log(f"Attempting ATA Sanitize Block Erase on {dev_path}...")
                     try:
                         run_command(['hdparm', '--sanitize-block-erase', dev_path], sudo=True)
                         log("ATA Sanitize Block Erase completed successfully.")
                         return True
                     except Exception as e:
                         log(f"ATA Sanitize failed: {e}. Falling back...", 'WARN')
            except:
                pass

            # 3. ATA Secure Erase (Enhanced & Standard)
            try:
                res = run_command(['hdparm', '-I', dev_path], sudo=True, capture_output=True)
                if "supported" in res.stdout.lower() and "security:" in res.stdout.lower():
                    if "frozen" in res.stdout.lower():
                        log("ATA Secure Erase is FROZEN by BIOS/EFI. Skipping...", 'WARN')
                    else:
                        log("ATA Secure Erase supported. Setting temporary password 'diskmgr'...")
                        try:
                            pw = "diskmgr"
                            run_command(['hdparm', '--user-master', 'u', '--security-set-pass', pw, dev_path], sudo=True)
                            
                            # Enhanced
                            if "enhanced" in res.stdout.lower():
                                log(f"Attempting ATA Secure Erase (Enhanced) on {dev_path}...")
                                try:
                                    run_command(['hdparm', '--user-master', 'u', '--security-erase-enhanced', pw, dev_path], sudo=True)
                                    log("ATA Secure Erase (Enhanced) completed successfully.")
                                    return True
                                except Exception as e:
                                    log(f"ATA Secure Erase (Enhanced) failed: {e}. Falling back...", 'WARN')

                            # Standard
                            log(f"Attempting ATA Secure Erase (Standard) on {dev_path}...")
                            try:
                                run_command(['hdparm', '--user-master', 'u', '--security-erase', pw, dev_path], sudo=True)
                                log("ATA Secure Erase (Standard) completed successfully.")
                                return True
                            except Exception as e:
                                log(f"ATA Secure Erase (Standard) failed: {e}. Falling back...", 'WARN')
                        except Exception as e:
                            log(f"Failed to set security password: {e}. Falling back...", 'WARN')
            except:
                pass

    if disk_is_rotational(dev_path):
        if not is_part:
            # Try ATA methods for HDD too
            try:
                res = run_command(['hdparm', '-I', dev_path], sudo=True, capture_output=True)
                if "sanitize" in res.stdout.lower():
                     log(f"Attempting ATA Sanitize on HDD {dev_path}...")
                     try:
                         run_command(['hdparm', '--sanitize-block-erase', dev_path], sudo=True)
                         log("HDD ATA Sanitize completed successfully.")
                         return True
                     except Exception as e:
                         log(f"HDD ATA Sanitize failed: {e}. Falling back...", 'WARN')
                
                if "supported" in res.stdout.lower() and "security:" in res.stdout.lower() and "frozen" not in res.stdout.lower():
                    log(f"Attempting ATA Secure Erase on HDD {dev_path}...")
                    try:
                        pw = "diskmgr"
                        run_command(['hdparm', '--user-master', 'u', '--security-set-pass', pw, dev_path], sudo=True)
                        erase_cmd = '--security-erase-enhanced' if "enhanced" in res.stdout.lower() else '--security-erase'
                        run_command(['hdparm', '--user-master', 'u', erase_cmd, pw, dev_path], sudo=True)
                        log("HDD ATA Secure Erase completed successfully.")
                        return True
                    except Exception as e:
                        log(f"HDD ATA Secure Erase failed: {e}. Falling back...", 'WARN')
            except:
                pass

        # Final HDD Fallback
        log(f"Performing software zero-overwrite (dd) on {dev_path}...")
        try:
            run_command(['dd', 'if=/dev/zero', f'of={dev_path}', 'bs=16M', 'status=progress', 'oflag=direct'], sudo=True, capture_output=False)
            run_command(['sync'], sudo=True)
            log("Zero overwrite completed. Verifying first 1MB...")
            res_v = run_command(['dd', f'if={dev_path}', 'bs=1M', 'count=1'], sudo=True, capture_output=True)
            if any(b != 0 for b in res_v.stdout.encode('latin1') if isinstance(b, int)):
                 log("Verification failed: First 1MB is not zeroed.", 'ERROR')
                 return False
            log("Verification successful.")
            return True
        except Exception as e:
            log(f"Software overwrite failed: {e}", 'ERROR')
            return False

    # SSD Software Fallbacks
    log(f"Attempting blkdiscard --secure on {dev_path}...")
    try:
        run_command(['blkdiscard', '--secure', dev_path], sudo=True)
        run_command(['udevadm', 'settle'], sudo=True)
        log("blkdiscard --secure completed successfully.")
        return True
    except Exception as e:
        log(f"blkdiscard --secure not supported or failed: {e}. Falling back...", 'WARN')

    log(f"Attempting standard blkdiscard on {dev_path}...")
    if disk_discard_supported(dev_path):
        try:
            run_command(['blkdiscard', dev_path], sudo=True)
            run_command(['udevadm', 'settle'], sudo=True)
            log("Standard blkdiscard completed successfully.")
            return True
        except Exception as e:
            log(f"Standard blkdiscard failed: {e}", 'ERROR')
            return False
    else:
        log("Discard not supported on this device. Final software overwrite attempted.", 'WARN')
        try:
            run_command(['dd', 'if=/dev/zero', f'of={dev_path}', 'bs=16M', 'status=progress', 'oflag=direct'], sudo=True, capture_output=False)
            return True
        except:
            return False

class CmdArgumentParser(argparse.ArgumentParser):
    def error(self, message):
        raise argparse.ArgumentError(None, message)

class DiskMgrShell(cmd.Cmd):
    intro = 'Welcome to diskmgr. Type help or ? to list commands.\n'
    prompt = '(diskmgr) '
    
    def __init__(self):
        super().__init__()
        if readline is not None:
            # Mark ANSI escapes as non-printing so readline cursor math stays correct.
            self.prompt = f'\001{Colors.OKGREEN}\002(diskmgr) \001{Colors.ENDC}\002'
        else:
            self.prompt = f'{Colors.OKGREEN}(diskmgr) {Colors.ENDC}'
        self.mappings = read_luks_map()
        self.unmapped_cache = []
        self.id_cache = {}
        self.missing_map_id_cache = {}
        self._ext4_tune2fs_cache = {}
        self.history_file = Path(os.environ.get(HISTORY_FILE_ENV, str(DEFAULT_HISTORY_FILE))).expanduser()
        self.history_enabled = False
        self._init_history()

    def _init_history(self):
        if readline is None:
            return
        try:
            readline.read_history_file(str(self.history_file))
        except FileNotFoundError:
            pass
        except Exception:
            # Best-effort: shell remains usable even if history cannot be read.
            pass
        try:
            readline.set_history_length(MAX_HISTORY_ENTRIES)
        except Exception:
            pass
        atexit.register(self._save_history)
        self.history_enabled = True

    def _save_history(self):
        if not self.history_enabled or readline is None:
            return
        try:
            self.history_file.parent.mkdir(parents=True, exist_ok=True)
            readline.set_history_length(MAX_HISTORY_ENTRIES)
            readline.write_history_file(str(self.history_file))
        except Exception:
            # Best-effort: do not block shell exit on history write errors.
            pass

    def _input_no_history(self, prompt):
        """
        Read one line from stdin without leaving the entered text in readline history.
        Used for confirmation/math answers so command history stays clean.
        """
        if readline is None:
            return input(prompt)

        try:
            before = int(readline.get_current_history_length() or 0)
        except Exception:
            before = 0

        try:
            val = input(prompt)
        finally:
            # Best-effort: strip any entries added during this prompt.
            try:
                after = int(readline.get_current_history_length() or 0)
                while after > before:
                    readline.remove_history_item(after - 1)
                    after -= 1
            except Exception:
                pass
        return val

    def get_disk_info(self):
        # Use lsblk -J for JSON output
        cmd = ['lsblk', '-J', '-e', '7', '-o', 'NAME,KNAME,TYPE,RM,SIZE,FSTYPE,LABEL,MOUNTPOINT,MODEL,WWN,PKNAME,TRAN,DISC-MAX']
        try:
            res = run_command(cmd, capture_output=True)
            data = json.loads(res.stdout)
            return data.get('blockdevices', [])
        except Exception as e:
            log(f"Failed to list disks: {e}", 'ERROR')
            return []

    def flatten_disks(self, devices):
        """Recursively flatten the lsblk tree structure."""
        flat = []
        for dev in devices:
            flat.append(dev)
            if 'children' in dev:
                flat.extend(self.flatten_disks(dev['children']))
        return flat

    def find_persistent_path(self, dev_node, wwn=None, type_='disk'):
        # Try to find a /dev/disk/by-id/ match.
        #
        # Requirement: prefer a by-id link that contains the IEEE identifier (WWN/EUI),
        # e.g. "wwn-0x..." for SATA/SCSI or "nvme-eui...." for NVMe, when available.
        # For partitions, prefer the corresponding "-partN" link.

        # 1. Try WWN logic from opendisk
        if wwn:
            prefix = "nvme-" if str(wwn).startswith("eui.") else "wwn-"
            base = f"/dev/disk/by-id/{prefix}{wwn}"
            candidates = []

            if type_ == 'part':
                # Prefer partition-scoped by-id links if this is a partition.
                m = re.search(r"p?([0-9]+)$", str(dev_node))
                if m:
                    candidates.append(f"{base}-part{m.group(1)}")
            candidates.append(base)

            try:
                target = os.path.realpath(f"/dev/{dev_node}")
                for c in candidates:
                    if os.path.exists(c) and os.path.realpath(c) == target:
                        return c
            except Exception:
                pass

        # 2. Brute force check /dev/disk/by-id
        by_id_dir = Path('/dev/disk/by-id')
        if by_id_dir.exists():
            matches = []
            for link in by_id_dir.iterdir():
                try:
                    if link.resolve() == Path(f"/dev/{dev_node}").resolve():
                        matches.append(str(link))
                except Exception:
                    continue

            if matches:
                # Prefer identifiers that include IEEE IDs when present.
                def _score(p):
                    b = os.path.basename(p)
                    if b.startswith('nvme-eui.'):
                        return 0
                    if b.startswith('wwn-'):
                        return 1
                    return 2
                matches.sort(key=_score)
                return matches[0]

        return "-"

    def do_help(self, arg):
        'List available commands with "help" or detailed help with "help cmd".'
        if arg:
            super().do_help(arg)
            return

        print(f"\n{Colors.HEADER}Disk Manager (diskmgr){Colors.ENDC}")
        print("A utility to manage mapped disks/partitions, encrypted containers, and filesystems.")
        print("Mappings point to persistent device paths so names remain stable across reboots/ports.\n")

        print(f"{Colors.BOLD}all:{Colors.ENDC}")
        print(f"  {Colors.OKGREEN}list [verbose]{Colors.ENDC}")
        print("      Displays disk layout (table by default).")
        print("      Use verbose for key/value entries (alias: list list).")
        print(f"  {Colors.OKGREEN}boot{Colors.ENDC}")
        print("      Displays boot entries/submenus from GRUB and /etc/fstab detection per partition.")

        print(f"\n{Colors.BOLD}disk:{Colors.ENDC}")
        print(f"  {Colors.OKGREEN}create <name/id> [--gpt|--mbr] [--partition] [--start X] [--end Y]{Colors.ENDC}")
        print("      Creates a new GPT/MBR partition table on a whole disk (mapping name or discovery ID).")
        print("      Also supports adding another partition to an existing partitioned disk via --partition.")
        print("      If --start/--end are omitted in partition-only mode, uses the largest free extent.")
        print("      Overlapping ranges are rejected by parted; existing partitions are not overwritten.")
        print("      Safety policy for table creation: disk must be erased first (run: erase <name>).")
        print(f"  {Colors.OKGREEN}selftest <name/id>{Colors.ENDC}")
        print("      Starts a SMART long self-test (smartctl -t long) for the underlying disk")
        print("      (USB uses -d sat). Use: selftest <name/id> --watch to poll progress until complete.")
        print(f"  {Colors.OKGREEN}health <name/id> [alias: smart]{Colors.ENDC}")
        print("      Shows SMART health (smartctl -x) for the underlying disk (USB uses -d sat).")

        print(f"\n{Colors.BOLD}disk/part (applied to mapped disk/partition targets):{Colors.ENDC}")
        print(f"  {Colors.OKGREEN}map <name/id> <name>{Colors.ENDC}")
        print("      Assigns a friendly name to a disk/partition or renames an existing mapping.")
        print("      Discovery IDs use #N format (example: map #1 backup).")
        print(f"  {Colors.OKGREEN}unmap <name/id>{Colors.ENDC}")
        print("      Removes an existing mapping by name, or by discovery ID (#N).")
        print(f"  {Colors.OKGREEN}format <name/id> [options]{Colors.ENDC}")
        print("      Whole disk target: creates a superfloppy-style volume and mounts it.")
        print("      Partition target: formats inside that partition boundary (not a superfloppy), then mounts it.")
        print("      Default is plain format. Use --luks to run cryptsetup luksFormat, open a mapper,")
        print("      then mkfs the decrypted payload filesystem inside the LUKS container.")
        print("      Whole disks must be unpartitioned. format never creates, deletes, resizes, or moves partitions;")
        print("      it only writes a filesystem/LUKS+filesystem inside the selected disk or partition target.")
        print("      Newly created filesystem roots are chowned to the invoking user.")
        print("      Use: erase <name> first if the whole disk is currently partitioned.")
        print(f"  {Colors.OKGREEN}erase <name/id>{Colors.ENDC}")
        print("      Fast metadata wipe for re-provisioning (wipefs + zap GPT/MBR metadata) on disk/part.")
        print("      Whole-disk erase wipes partition signatures/metadata, GPT headers, protective MBR metadata,")
        print("      and rewrites an empty MBR table in MBR mode.")
        print(f"  {Colors.OKGREEN}nuke <name/id>{Colors.ENDC}")
        print("      Secure erase (multi-step hardware-aware wipe) on disk/part.")
        print(f"  {Colors.OKGREEN}remove <name/id>{Colors.ENDC}")
        print("      Removes a partition from its parent disk (partition targets only).")
        print(f"  {Colors.OKGREEN}clone <src_name/id> <dst_name/id>{Colors.ENDC}")
        print("      Bit-perfect block-level clone using ddrescue (requires target >= source size).")
        print("      Includes a multi-pass rescue phase to recover data from failing sectors.")

        print(f"\n{Colors.BOLD}file system (applied to disk/part entries with mountable FSTYPE):{Colors.ENDC}")
        print(f"  {Colors.OKGREEN}open <name/id>{Colors.ENDC}")
        print("      Opens and mounts a plain or encrypted partition or superfloppy.")
        print("      For encrypted targets, unlocks LUKS then mounts payload filesystem.")
        print("      Btrfs mounts are enforced with compression (compress=zstd:3).")
        print("      Uses /etc/fstab mountpoint/options when an entry exists; otherwise /media/$USER/<label>.")
        print(f"  {Colors.OKGREEN}close <name/id>{Colors.ENDC}")
        print("      close <name>: unmounts filesystem(s) and closes /dev/mapper/<name> when present (locks LUKS).")
        print("      close #id (example: close #6): unmount-only for that discovered row; does NOT run cryptsetup close.")
        print("      Use #id if you want to close only the payload filesystem and keep the LUKS container open.")
        print(f"  {Colors.OKGREEN}luks <passwd|backup|restore|header>{Colors.ENDC}")
        print("      LUKS management for mapped containers (grouped under filesystem workflows):")
        print("      password change, header backup/print, and header restore.")
        print(f"  {Colors.OKGREEN}label <name> [new_label] [--fstab]{Colors.ENDC}")
        print("      Get or set the filesystem label of an OPEN disk.")
        print("      On relabel: removes old LABEL-based fstab entry. With --fstab, adds UUID entry at /mnt/<label>.")
        print("      Generated fstab options: defaults,nofail,x-gvfs-show,x-gvfs-name=<label>.")
        print("      For LUKS: acts on payload filesystem when open; errors if locked.")
        print(f"  {Colors.OKGREEN}remount <name>{Colors.ENDC}")
        print("      Move an OPEN disk's mount to /mnt/<label> when /etc/fstab entry exists;")
        print("      otherwise /media/$USER/<label>, and clean old empty mountpoint dirs.")
        print("      For LUKS: acts on payload filesystem when open; errors if locked.")
        print(f"  {Colors.OKGREEN}sync <pri_name> <sec_name>{Colors.ENDC}")
        print("      Syncs two mounted filesystems (rsync pri -> sec).")
        print("      Primary/source is copied FROM. Secondary/destination is replaced to match source.")
        print("      Runs a dry-run pre-scan first and shows real progress from planned-bytes completed.")
        print("      Endpoints may be mapped names or absolute directory paths.")
        print("      For LUKS: resolves to payload filesystem when open; errors if locked/not mounted.")
        print(f"  {Colors.OKGREEN}diff <pri_name> <sec_name> [--depth N] [-d] [--fast] [--checksum]{Colors.ENDC}")
        print("      Dry-run filesystem diff (rsync pri -> sec): shows create/modify/delete counts+bytes,")
        print("      Primary/source is copied FROM. Secondary/destination is what would be replaced.")
        print("      then a tree-style hierarchy summary of dirs/files (+new, ~updated, -deleted regular files).")
        print("      Depth default: 2. Use -d to show directories only. ")
        print("      Use --fast to print raw rsync -an --delete --stats output only (no summaries).")
        print("      In --fast created(new+updated) regular files = 'Number of regular files transferred'.")
        print("      Use --checksum to compare file contents via rsync checksums (slower, ignores mtime-only changes).")
        print("      Endpoints may be mapped names/IDs or absolute directory paths.")
        print("      For LUKS: resolves to payload filesystem when open; errors if locked/not mounted.")
        print(f"  {Colors.OKGREEN}defrag <name> [--compress]{Colors.ENDC}")
        print("      Defragments a mounted filesystem and records user.last_defrag xattr.")
        print("      On btrfs, default runs defragment -r -v with live per-directory progress.")
        print("      Use --compress to add -czstd recompression,")
        print("      then balance start -dusage=50 and live balance status monitoring.")
        print("      For LUKS: resolves to payload filesystem when open; errors if locked/not mounted.")
        print(f"  {Colors.OKGREEN}fshealth <name>{Colors.ENDC}")
        print("      Shows filesystem diagnostics, last_defrag/last_scrub xattrs, and extents/files ratios.")
        print("      ext4: <1.1 healthy, >1.5 bad, >5 critical. btrfs: <1 good, >5 bad, >20 critical.")
        print("      For btrfs, also shows filesystem/device stats and scrub status.")
        print("      For LUKS: resolves to payload filesystem when open; errors if locked/not mounted.")
        print(f"  {Colors.OKGREEN}convert <name/id>{Colors.ENDC}")
        print("      Converts an UNMOUNTED ext4 filesystem to btrfs in place (btrfs-convert).")
        print("      Preserves data, supports plain ext4 and open LUKS payload ext4 when resolvable.")
        print("      For safety, target must be unmounted/closed before conversion.")
        print(f"  {Colors.OKGREEN}scrub <name> [--no-watch]{Colors.ENDC}")
        print("      Runs a blocking btrfs scrub on a mounted filesystem and records user.last_scrub xattr.")
        print("      By default tails kernel checksum/error logs and resolves paths when possible.")
        print("      For LUKS: resolves to payload filesystem when open; errors if locked/not mounted.")

        print(f"\n{Colors.BOLD}shell:{Colors.ENDC}")
        print(f"  {Colors.OKGREEN}version{Colors.ENDC}")
        print("      Print diskmgr version.")
        print(f"      Command history persists across sessions in {self.history_file} (override with ${HISTORY_FILE_ENV}).")
        print(f"  {Colors.OKGREEN}exit / quit / Ctrl+D{Colors.ENDC}")
        print("      Exit the application.")

    def do_version(self, arg):
        'Print diskmgr version'
        print(f"diskmgr {VERSION}")

    def do_exit(self, arg):
        'Exit the application'
        self._save_history()
        return True

    def do_quit(self, arg):
        'Exit the application'
        self._save_history()
        return True

    def do_EOF(self, arg):
        'Exit the application'
        print("")
        self._save_history()
        return True

    def do_list(self, arg):
        '''Display the physical partition layout and free space for all plugged-in disks.
        Usage:
          list            -> standard table (default)
          list verbose    -> verbose key/value entries (alias: list list)
        
        UNDER THE HOOD:
        1.  Hardware Scan: Identifies all physical 'disk' devices (excluding partitions).
        2.  Geometry Query: Runs 'sudo parted -m <dev> unit s print free' and 'blockdev --getsz'.
        3.  Parsing: 
            - Extracts Partition Table type (gpt/mbr) and sector sizes.
            - Calculates total logical sectors from blockdev output.
        4.  Formatting:
            - Adds GPT metadata blocks (Primary/Backup) if applicable.
            - Identifies 'free' space segments.
            - Calculates MiB and GiB values from sector counts.
        '''
        argv = shlex.split(arg) if arg else []
        render_mode = 'table'
        for token in argv:
            t = token.strip().lower()
            if t in ('verbose', '--verbose', '-v'):
                # verbose now means list-style key/value entries
                render_mode = 'list'
            elif t in ('list', '--list', '-l'):
                # Back-compat: list list
                render_mode = 'list'
            elif t in ('table', '--table', '-t'):
                render_mode = 'table'
            else:
                log(f"Unknown list option: {token}. Use: list [verbose]", 'ERROR')
                return

        if render_mode == 'list':
            selected_cols = self._lsblk_verbose_cols()
        else:
            selected_cols = self._lsblk_standard_cols()

        all_devs = self.get_disk_info()
        disks = [d for d in all_devs if d.get('type') == 'disk']
        
        if not disks:
            log("No physical disks found.", 'WARN')
            return

        # Precompute lsblk rows for all disks first so we can:
        # - keep the output stable across disks
        # - compute column widths across ALL disks (not per-disk)
        # - include the diskmgr mapping name (from diskmap.tsv) per real disk/partition node
        friendly_map = {}
        missing_mappings = []
        try:
            # Refresh mappings in case they changed on disk.
            self.mappings = read_luks_map()
            for friendly, target in (self.mappings or {}).items():
                try:
                    if not target:
                        continue
                    # Only map targets that currently exist, otherwise realpath() can be misleading.
                    if os.path.exists(target):
                        friendly_map[os.path.realpath(target)] = friendly
                    else:
                        missing_mappings.append((friendly, target))
                except Exception:
                    continue
        except Exception:
            friendly_map = {}
            missing_mappings = []
        self.missing_map_id_cache = {}

        fstab_real_set, fstab_uuid_set, fstab_detail_real, fstab_detail_uuid = self._fstab_lookup()
        findmnt_lookup = self._findmnt_lookup()

        disk_rows = {}
        for d in disks:
            d_name = d.get('name', '')
            if not d_name:
                continue
            dev_path = f"/dev/{d_name}"
            try:
                ls_res = run_command(['lsblk', '-J', '-b', '-f', '-o',
                                      'NAME,KNAME,TYPE,SIZE,FSTYPE,FSVER,LABEL,UUID,PARTUUID,FSAVAIL,FSUSE%,FSUSED,MOUNTPOINTS,WWN',
                                      dev_path], sudo=True, check=False)
                rows = []
                if (getattr(ls_res, 'stdout', '') or '').strip():
                    data = json.loads(ls_res.stdout)
                    if 'blockdevices' in data:
                        rows = self._collect_lsblk_rows(
                            data['blockdevices'],
                            friendly_map=friendly_map,
                            fstab_real_set=fstab_real_set,
                            fstab_uuid_set=fstab_uuid_set,
                            fstab_detail_real=fstab_detail_real,
                            fstab_detail_uuid=fstab_detail_uuid,
                            findmnt_lookup=findmnt_lookup
                        )
                disk_rows[d_name] = rows
            except Exception:
                disk_rows[d_name] = []

        # Assign a single global index in print order.
        # Number disk/part and open dm-crypt rows (TYPE=crypt). Keep all other virtual rows as "-".
        idx = 1
        for d in disks:
            d_name = d.get('name', '')
            for r in disk_rows.get(d_name, []):
                if (r.get('TYPE') or '') in ('disk', 'part', 'crypt'):
                    r['#'] = str(idx)
                    idx += 1
                else:
                    r['#'] = '-'

        all_rows = []
        for d in disks:
            d_name = d.get('name', '')
            all_rows.extend(disk_rows.get(d_name, []))

        missing_rows = []
        missing_idx = idx
        for friendly, target in missing_mappings:
            rid = str(missing_idx)
            missing_idx += 1
            friendly_name = str(friendly or "")
            target_path = str(target or "")
            self.missing_map_id_cache[rid] = friendly_name
            missing_rows.append({
                "#": rid,
                "KNAME": "",
                "PKNAME": "",
                "NAME": friendly_name,
                "DEVICE": "-",
                "PERSISTENT PATH (IEEE)": target_path,
                "TYPE": "missing",
                "STATE": "MISSING",
                "OWNER": "-",
                "FSTAB": "n",
                "SIZE": "-",
                "SIZE-BYTES": "",
                "FSTYPE": "-",
                "FSVER": "-",
                "FSLABEL": "-",
                "FSUUID": "-",
                "PARTUUID": "-",
                "FSAVAIL": "-",
                "FSAVAIL-BYTES": "",
                "FSUSE%": "-",
                "FSRESERVED": "-",
                "FSMETA": "-",
                "FSUSED-BYTES": "",
                "FSMOUNTPOINTS": "-",
                "SOURCE": "-",
                "FS-OPTIONS": "-",
                "VFS-OPTIONS": "-",
                "FS-USED": "-",
                "MOUNTPOINT": "-",
                "FSTAB ENTRY": "-",
            })

        # Display rows: standard table needs different numeric formatting.
        display_disk_rows = disk_rows
        display_all_rows = all_rows
        display_missing_rows = [dict(r) for r in missing_rows]
        if render_mode == 'table':
            display_disk_rows = {}
            display_all_rows = []
            for d in disks:
                d_name = d.get('name', '')
                out = []
                for r in disk_rows.get(d_name, []):
                    rr = dict(r)
                    # list (table): show SIZE with 2dp and no metric bracket.
                    try:
                        rr["SIZE"] = self._format_bytes_binary(rr.get("SIZE-BYTES", ""), decimals=2) or rr.get("SIZE", "")
                    except Exception:
                        pass
                    # list (table): show FSAVAIL with 2dp and NO metric bracket.
                    try:
                        rr["FSAVAIL"] = self._format_bytes_binary(rr.get("FSAVAIL-BYTES", ""), decimals=2) or rr.get("FSAVAIL", "")
                    except Exception:
                        pass
                    out.append(rr)
                display_disk_rows[d_name] = out
                display_all_rows.extend(out)

        # Discovery cache for map #N:
        # keep only unmapped disk/partition entries and bind to displayed "#" IDs.
        self.unmapped_cache = []
        # Full ID cache for commands that support #N on displayed rows (disk/part/crypt).
        self.id_cache = {}
        for r in all_rows:
            try:
                rid = str(r.get('#') or '').strip()
                kname = str(r.get('KNAME') or '').strip()
                rtype = str(r.get('TYPE') or '').strip()
                if rid and rid != '-' and kname and rtype in ('disk', 'part', 'crypt'):
                    self.id_cache[rid] = os.path.realpath(f"/dev/{kname}")

                if (r.get('TYPE') or '') not in ('disk', 'part'):
                    continue
                if (r.get('NAME') or '') != '-':
                    continue
                pdp = str(r.get('PERSISTENT PATH (IEEE)') or '').strip()
                if not rid or rid == '-' or not pdp or pdp == '-':
                    continue
                self.unmapped_cache.append({'id': rid, 'pdp': pdp})
            except Exception:
                continue

        widths_global = None
        if render_mode == 'table':
            width_rows = display_all_rows + display_missing_rows
            widths_global = self._lsblk_col_widths(width_rows, cols=selected_cols)
            separator_width = max(1, self._lsblk_rendered_width(width_rows, widths=widths_global, cols=selected_cols))
        else:
            width_rows = all_rows + missing_rows
            separator_width = max(1, self._lsblk_rendered_list_width(width_rows, cols=selected_cols))
        separator_line = "-" * separator_width

        list_entry_cursor = 1
        for disk in disks:
            d_name = disk['name']
            dev_path = f"/dev/{d_name}"
            model = disk.get('model', 'Unknown')
            
            try:
                # 1. Get Geometry from parted
                res = run_command(['parted', '-m', '-s', dev_path, 'unit', 's', 'print', 'free'], sudo=True, check=False)
                if getattr(res, 'returncode', 1) != 0:
                    # Common case: blank disk or missing/corrupt partition table.
                    # Avoid noisy "Command failed" logs and present a human-readable reason.
                    stderr = (getattr(res, 'stderr', '') or '').strip()
                    disk_fstype = (_lsblk_fstype(dev_path) or "").strip()
                    has_whole_disk_fs = bool(disk_fstype)

                    # Fall back to blockdev sector sizes for a useful header.
                    ls = run_command(['blockdev', '--getss', dev_path], sudo=True, check=False).stdout.strip()
                    ps = run_command(['blockdev', '--getpbsz', dev_path], sudo=True, check=False).stdout.strip()
                    logical_sector = int(ls) if ls.isdigit() else 512
                    physical_sector = int(ps) if ps.isdigit() else logical_sector

                    res_sz = run_command(['blockdev', '--getsz', dev_path], sudo=True, check=False)
                    total_512_sectors = int(res_sz.stdout.strip()) if (res_sz.stdout or "").strip().isdigit() else 0
                    total_logical_sectors = (total_512_sectors * 512) // logical_sector if logical_sector else 0

                    print(f"\n{Colors.BOLD}Disk: {dev_path} ({model}) [none] [Sector: L{logical_sector}/P{physical_sector}] [Total Sectors: {total_logical_sectors}]{Colors.ENDC}")
                    if stderr:
                        if has_whole_disk_fs and "unrecognised disk label" in stderr.lower():
                            # Superfloppy / whole-disk filesystem (including crypto_LUKS) is expected
                            # to have no partition table; don't show this as a warning.
                            pass
                        elif "unrecognised disk label" in stderr.lower():
                            log(f"{dev_path}: no partition table (unrecognized disk label).", 'WARN')
                        else:
                            log(f"{dev_path}: could not read partition layout: {stderr}", 'WARN')

                    if has_whole_disk_fs:
                        size_bytes = total_logical_sectors * logical_sector
                        if size_bytes < 1024:
                            size_info = f"{size_bytes:.2f}B"
                        elif size_bytes < 1024**2:
                            size_info = f"{size_bytes/1024:.2f}KiB"
                        elif size_bytes < 1024**3:
                            size_info = f"{size_bytes/(1024**2):.2f}MiB"
                        else:
                            size_info = f"{size_bytes/(1024**2):.2f}MiB  {size_bytes/(1024**3):.1f}GiB"
                            if size_bytes >= 1024**4:
                                size_info += f" ({size_bytes/(1024**4):.3f} TiB)"
                        print(f"{Colors.OKGREEN}[ {d_name} {disk_fstype} {total_logical_sectors}s ({size_info}) ]{Colors.ENDC}")

                    # Still show lsblk hierarchy so the user can see what's on the disk.
                    rows = display_disk_rows.get(d_name, [])
                    if rows:
                        print("")
                        if render_mode == 'list':
                            self._print_lsblk_rows_list(rows, cols=selected_cols, start_index=list_entry_cursor)
                            list_entry_cursor += len(rows)
                        else:
                            self._print_lsblk_rows(rows, widths=widths_global, cols=selected_cols)
                    print(separator_line)
                    continue

                lines = res.stdout.strip().splitlines()
                
                header_parts = lines[1].strip(';').split(':')
                logical_sector = int(header_parts[3])
                physical_sector = int(header_parts[4])
                ptable = header_parts[5]
                
                # 2. Get Total Size from blockdev (always in 512b units)
                res_sz = run_command(['blockdev', '--getsz', dev_path], sudo=True)
                total_512_sectors = int(res_sz.stdout.strip())
                total_logical_sectors = (total_512_sectors * 512) // logical_sector

                print(f"\n{Colors.BOLD}Disk: {dev_path} ({model}) [{ptable}] [Sector: L{logical_sector}/P{physical_sector}] [Total Sectors: {total_logical_sectors}]{Colors.ENDC}")

                # 4. Parse Data Lines from parted for visual blocks
                data_lines = [l for l in lines if l and not l.startswith('BYT') and not l.startswith('/')]
                part_fstype_by_name = {}
                try:
                    for p in _lsblk_partitions(dev_path):
                        n = (p.get('name') or '').strip()
                        if n:
                            part_fstype_by_name[n] = (p.get('fstype') or '').strip()
                except Exception:
                    part_fstype_by_name = {}
                
                segments = []
                
                # Dynamic Initial Overhead Detection
                if data_lines:
                    first_line_parts = data_lines[0].strip(';').split(':')
                    first_start = int(first_line_parts[1].strip('s'))
                    if first_start > 0:
                        overhead_size = first_start
                        overhead_bytes = overhead_size * logical_sector
                        
                        label = "Overhead"
                        if ptable == 'gpt': label = "GPT Primary"
                        elif ptable in ['msdos', 'mbr']: label = "MBR"
                        
                        segments.append(f"{Colors.FAIL}[ {label} {overhead_size}s ({overhead_bytes:.2f}B) ]{Colors.ENDC}")

                for line in data_lines:
                    parts = line.strip(';').split(':')
                    if len(parts) < 4: continue
                    
                    num = parts[0]
                    size_sectors = int(parts[3].strip('s'))
                    fs_or_type = parts[4] if len(parts) > 4 else ""
                    
                    size_bytes = size_sectors * logical_sector
                    # Use B, KiB, MiB, GiB based on size
                    if size_bytes < 1024:
                        size_info = f"{size_bytes:.2f}B"
                    elif size_bytes < 1024**2:
                        size_info = f"{size_bytes/1024:.2f}KiB"
                    elif size_bytes < 1024**3:
                        size_info = f"{size_bytes/(1024**2):.2f}MiB"
                    else:
                        size_info = f"{size_bytes/(1024**2):.2f}MiB  {size_bytes/(1024**3):.1f}GiB"
                        if size_bytes >= 1024**4:
                            size_info += f" ({size_bytes/(1024**4):.3f} TiB)"

                    if fs_or_type == 'free' or (not fs_or_type and len(parts) == 5):
                        segments.append(f"{Colors.OKCYAN}[ free {size_sectors}s ({size_info}) ]{Colors.ENDC}")
                    else:
                        flags = parts[6] if len(parts) > 6 else ""
                        kname = f"{d_name}{num}"
                        if 'nvme' in d_name and not kname.startswith(f"{d_name}p"):
                            kname = f"{d_name}p{num}"
                        
                        dtype = (fs_or_type or '').strip()
                        lsblk_fstype = (part_fstype_by_name.get(kname) or '').strip()
                        if (not dtype or dtype in ('-', 'unknown')) and lsblk_fstype:
                            dtype = lsblk_fstype
                        if not dtype:
                            dtype = "-"
                        flag_info = f" ({flags})" if flags else ""
                        segments.append(f"{Colors.OKGREEN}[ {kname} {dtype} {size_sectors}s ({size_info}){flag_info} ]{Colors.ENDC}")
                
                # GPT Backup Overhead
                if data_lines:
                    last_line_parts = data_lines[-1].strip(';').split(':')
                    last_end = int(last_line_parts[2].strip('s'))
                    if last_end < total_logical_sectors - 1:
                        overhead_size = total_logical_sectors - 1 - last_end
                        overhead_bytes = overhead_size * logical_sector
                        l_label = "Overhead"
                        if ptable == 'gpt': l_label = "GPT Backup"
                        segments.append(f"{Colors.FAIL}[ {l_label} {overhead_size}s ({overhead_bytes:.2f}B) ]{Colors.ENDC}")

                print(" ".join(segments))

                # 4. Print lsblk hierarchy at the bottom
                print("")
                try:
                    rows = display_disk_rows.get(d_name, [])
                    if rows:
                        if render_mode == 'list':
                            self._print_lsblk_rows_list(rows, cols=selected_cols, start_index=list_entry_cursor)
                            list_entry_cursor += len(rows)
                        else:
                            self._print_lsblk_rows(rows, widths=widths_global, cols=selected_cols)
                except Exception as e:
                    log(f"Could not render lsblk tree: {e}", 'DEBUG')
                print(separator_line)
            except Exception as e:
                print(f"\n{Colors.BOLD}Disk: {dev_path} ({model}){Colors.ENDC}")
                log(f"Could not read layout for {dev_path}: {e}", 'WARN')
        if display_missing_rows:
            print(f"{Colors.HEADER}Non-present mappings ({get_map_file_path()}){Colors.ENDC}")
            try:
                if render_mode == 'list':
                    self._print_lsblk_rows_list(display_missing_rows, cols=selected_cols, start_index=list_entry_cursor)
                else:
                    self._print_lsblk_rows(display_missing_rows, widths=widths_global, cols=selected_cols)
            except Exception as e:
                log(f"Could not render missing mappings: {e}", 'DEBUG')
            print(separator_line)
        print("")

    def do_layout(self, arg):
        '''(Deprecated) Alias for list: layout

        This command was renamed to 'list'. Prefer: list
        '''
        log("layout was renamed to list; running list ...", 'WARN')
        return self.do_list(arg)

        # Missing mappings section: show friendly names and their configured persistent IDs.
        if missing_mappings:
            print(f"{Colors.HEADER}--- Missing Mappings ({get_map_file_path()}) ---{Colors.ENDC}")
            rows = []
            missing_idx = idx
            for friendly, target in missing_mappings:
                rows.append({
                    "#": str(missing_idx),
                    "NAME": str(friendly),
                    "PERSISTENT ID": str(target),
                })
                missing_idx += 1

            cols = ["#", "NAME", "PERSISTENT ID"]
            widths = {c: len(c) for c in cols}
            for r in rows:
                for c in cols:
                    widths[c] = max(widths[c], len(str(r.get(c, "") or "")))
            # 1-space padding each side.
            for c in cols:
                widths[c] += 2

            def _cell(text, width):
                inner = max(width - 2, 0)
                return f" {text:<{inner}} "

            header = "".join([_cell(c, widths[c]) for c in cols]).rstrip()
            print(f"{Colors.BOLD}{header}{Colors.ENDC}")
            for r in rows:
                line = "".join([_cell(str(r.get(c, "") or ""), widths[c]) for c in cols]).rstrip()
                print(line)
            print("")

    def _lsblk_verbose_cols(self):
        return [
            "#",
            "NAME",
            "DEVICE",
            "TYPE",
            "STATE",
            "OWNER",
            "FSTYPE",
            "FSVER",
            "FSLABEL",
            "FSUUID",
            "PARTUUID",
            "SIZE",
            "FSAVAIL",
            "FSUSE%",
            "FSRESERVED",
            "FSMETA",
            "FSMOUNTPOINTS",
            "SOURCE",
            "FS-OPTIONS",
            "VFS-OPTIONS",
            "FSTAB",
            "FSTAB ENTRY",
            "PERSISTENT PATH (IEEE)",
        ]

    def _lsblk_standard_cols(self):
        return [
            "#",
            "NAME",
            "DEVICE",
            "TYPE",
            "STATE",
            "FSTYPE",
            "FSLABEL",
            "FSUUID",
            "SIZE",
            "FSAVAIL",
            "FSMOUNTPOINTS",
            "PERSISTENT PATH (IEEE)",
        ]

    def _lsblk_concise_cols(self):
        return [
            "#",
            "NAME",
            "DEVICE",
            "TYPE",
            "MOUNTPOINT",
            "PERSISTENT PATH (IEEE)",
        ]

    def _resolve_fstab_spec_to_realdev(self, spec):
        """
        Resolve one /etc/fstab source spec to a real /dev path when possible.
        Returns a realpath string or None.
        """
        s = (spec or "").strip()
        if not s:
            return None

        # Common non-block pseudo filesystems.
        if s in ("none", "proc", "sysfs", "tmpfs", "devtmpfs", "devpts", "cgroup", "cgroup2", "overlay", "swap"):
            return None

        try:
            if s.startswith("/dev/"):
                return os.path.realpath(s) if os.path.exists(s) else None

            if s.startswith("UUID="):
                uuid = s[len("UUID="):]
                by_uuid = f"/dev/disk/by-uuid/{uuid}"
                if os.path.exists(by_uuid):
                    return os.path.realpath(by_uuid)
                res = run_command(['blkid', '-U', uuid], capture_output=True, check=False)
                p = (getattr(res, 'stdout', '') or '').strip()
                return os.path.realpath(p) if p and os.path.exists(p) else None

            if s.startswith("PARTUUID="):
                pu = s[len("PARTUUID="):]
                by_partuuid = f"/dev/disk/by-partuuid/{pu}"
                if os.path.exists(by_partuuid):
                    return os.path.realpath(by_partuuid)
                res = run_command(['blkid', '-t', f'PARTUUID={pu}', '-o', 'device'], capture_output=True, check=False)
                lines = [ln.strip() for ln in (getattr(res, 'stdout', '') or '').splitlines() if ln.strip()]
                if lines and os.path.exists(lines[0]):
                    return os.path.realpath(lines[0])
                return None

            if s.startswith("LABEL="):
                lbl = s[len("LABEL="):]
                by_label = f"/dev/disk/by-label/{lbl}"
                if os.path.exists(by_label):
                    return os.path.realpath(by_label)
                res = run_command(['blkid', '-L', lbl], capture_output=True, check=False)
                p = (getattr(res, 'stdout', '') or '').strip()
                return os.path.realpath(p) if p and os.path.exists(p) else None

            if s.startswith("PARTLABEL="):
                pl = s[len("PARTLABEL="):]
                by_partlabel = f"/dev/disk/by-partlabel/{pl}"
                if os.path.exists(by_partlabel):
                    return os.path.realpath(by_partlabel)
                res = run_command(['blkid', '-t', f'PARTLABEL={pl}', '-o', 'device'], capture_output=True, check=False)
                lines = [ln.strip() for ln in (getattr(res, 'stdout', '') or '').splitlines() if ln.strip()]
                if lines and os.path.exists(lines[0]):
                    return os.path.realpath(lines[0])
                return None
        except Exception:
            return None

        return None

    def _fstab_real_devices(self):
        """
        Build set of real /dev paths referenced by active OS /etc/fstab.
        """
        real_set, _, _, _ = self._fstab_lookup()
        return real_set

    def _fstab_uuid_values(self):
        """
        Build set of UUID values referenced as UUID=... in /etc/fstab.
        """
        _, uuid_set, _, _ = self._fstab_lookup()
        return uuid_set

    def _fstab_lookup(self):
        """
        Parse /etc/fstab once and return:
          real device set, UUID set, real-device detail map, UUID detail map.
        """
        real_set = set()
        uuid_set = set()
        real_detail = {}
        uuid_detail = {}
        fstab = Path('/etc/fstab')
        if not fstab.exists():
            return real_set, uuid_set, real_detail, uuid_detail
        try:
            lines = fstab.read_text(errors='replace').splitlines()
        except Exception:
            return real_set, uuid_set, real_detail, uuid_detail

        for raw in lines:
            line = (raw or '').strip()
            if not line or line.startswith('#'):
                continue
            body = raw.split('#', 1)[0].strip()
            if not body:
                continue
            parts = body.split()
            if len(parts) < 2:
                continue
            spec = (parts[0] or '').strip()
            mountpoint = parts[1] if len(parts) > 1 else "-"
            fstype = parts[2] if len(parts) > 2 else "-"
            opts = parts[3] if len(parts) > 3 else "-"
            dumpf = parts[4] if len(parts) > 4 else "0"
            passno = parts[5] if len(parts) > 5 else "0"
            detail = f"{mountpoint} ({fstype}, opts={opts}, dump={dumpf}, pass={passno})"

            real_dev = self._resolve_fstab_spec_to_realdev(spec)
            if real_dev:
                real_set.add(real_dev)
                real_detail.setdefault(real_dev, []).append(detail)

            if spec.startswith("UUID="):
                uuid = spec[len("UUID="):].strip().lower()
                if uuid:
                    uuid_set.add(uuid)
                    uuid_detail.setdefault(uuid, []).append(detail)

        return real_set, uuid_set, real_detail, uuid_detail

    def _fstab_unescape(self, value):
        s = str(value or "")
        return s.replace("\\040", " ").replace("\\011", "\t")

    def _fstab_escape(self, value):
        s = str(value or "")
        return s.replace("\\", "\\\\").replace("\t", "\\011").replace(" ", "\\040")

    def _read_system_fstab_lines(self):
        fstab = Path('/etc/fstab')
        if not fstab.exists():
            return []
        try:
            return fstab.read_text(errors='replace').splitlines()
        except Exception:
            return []

    def _write_system_fstab_lines(self, lines):
        # Write through a temporary file, then copy with sudo.
        content = "\n".join(lines).rstrip("\n") + "\n"
        tmp = Path(f"/tmp/diskmgr_fstab_{os.getpid()}_{int(time.time())}.tmp")
        tmp.write_text(content, encoding='utf-8')
        try:
            run_command(['cp', str(tmp), '/etc/fstab'], sudo=True)
            run_command(['chmod', '644', '/etc/fstab'], sudo=True, check=False)
        finally:
            try:
                tmp.unlink()
            except Exception:
                pass

    def _iter_fstab_entries(self, lines=None):
        if lines is None:
            lines = self._read_system_fstab_lines()
        out = []
        for idx, raw in enumerate(lines):
            stripped = (raw or "").strip()
            if not stripped or stripped.startswith('#'):
                continue
            body = raw.split('#', 1)[0].strip()
            if not body:
                continue
            parts = body.split()
            if len(parts) < 2:
                continue
            spec = (parts[0] or "").strip()
            mountpoint = self._fstab_unescape(parts[1].strip()) if len(parts) > 1 else ""
            fstype = (parts[2] or "").strip() if len(parts) > 2 else "auto"
            opts = (parts[3] or "").strip() if len(parts) > 3 else "defaults"
            dumpf = (parts[4] or "").strip() if len(parts) > 4 else "0"
            passno = (parts[5] or "").strip() if len(parts) > 5 else "0"
            out.append({
                'index': idx,
                'raw': raw,
                'spec': spec,
                'mountpoint': mountpoint,
                'fstype': fstype,
                'opts': opts,
                'dump': dumpf,
                'passno': passno,
            })
        return out

    def _find_fstab_entry_for_device(self, devnode, preferred_label=None):
        """
        Return the first /etc/fstab entry that appears to target this device.
        Matching priority: real device path, UUID, then LABEL.
        """
        target_real = os.path.realpath(devnode)
        target_uuid = ""
        target_label = preferred_label or ""
        try:
            r_uuid = run_command(['blkid', '-o', 'value', '-s', 'UUID', devnode], sudo=True, check=False)
            target_uuid = (getattr(r_uuid, 'stdout', '') or '').strip().lower()
        except Exception:
            target_uuid = ""
        if not target_label:
            try:
                r_lbl = run_command(['blkid', '-o', 'value', '-s', 'LABEL', devnode], sudo=True, check=False)
                target_label = (getattr(r_lbl, 'stdout', '') or '').strip()
            except Exception:
                target_label = ""

        entries = self._iter_fstab_entries()

        # 1) Exact device resolution
        for ent in entries:
            try:
                resolved = self._resolve_fstab_spec_to_realdev(ent['spec'])
            except Exception:
                resolved = None
            if resolved and os.path.realpath(resolved) == target_real:
                return ent

        # 2) UUID/LABEL text match
        for ent in entries:
            spec = ent['spec']
            if target_uuid and spec.startswith("UUID="):
                uuid = self._fstab_unescape(spec[len("UUID="):]).strip().lower()
                if uuid == target_uuid:
                    return ent
            if target_label and spec.startswith("LABEL="):
                lbl = self._fstab_unescape(spec[len("LABEL="):]).strip()
                if lbl == target_label:
                    return ent

        return None

    def _select_mountpoint_for_device(self, devnode, fallback_mountpoint, preferred_label=None):
        """
        Choose mountpoint for a device. Prefer /etc/fstab when present.
        Returns: (mountpoint, use_fstab, fstab_entry_or_none)
        """
        fstab_entry = self._find_fstab_entry_for_device(devnode, preferred_label=preferred_label)
        if fstab_entry:
            return fstab_entry['mountpoint'], True, fstab_entry
        return fallback_mountpoint, False, None

    def _detect_fstype(self, devnode):
        fstype = (_lsblk_fstype(devnode) or "").strip().lower()
        if fstype:
            return fstype
        try:
            res = run_command(['blkid', '-o', 'value', '-s', 'TYPE', devnode], sudo=True, check=False)
            return (getattr(res, 'stdout', '') or '').strip().lower()
        except Exception:
            return ""

    def _ensure_btrfs_compression_on_mount(self, mountpoint):
        res = run_command(['findmnt', '-rn', '-M', mountpoint, '-o', 'FSTYPE,OPTIONS'], check=False)
        if getattr(res, 'returncode', 1) != 0:
            return
        out = (getattr(res, 'stdout', '') or '').strip()
        if not out:
            return

        parts = out.split(None, 1)
        fstype = (parts[0] if parts else '').strip().lower()
        opts = (parts[1] if len(parts) > 1 else '').strip().lower()
        if fstype != 'btrfs':
            return
        if ('compress=' in opts) or ('compress-force=' in opts):
            return

        log(f"Enabling btrfs compression on {mountpoint} (compress=zstd:3).")
        run_command(['mount', '-o', 'remount,compress=zstd:3', mountpoint], sudo=True)

        verify = run_command(['findmnt', '-rn', '-M', mountpoint, '-o', 'OPTIONS'], check=False)
        vopts = (getattr(verify, 'stdout', '') or '').strip().lower()
        if ('compress=' not in vopts) and ('compress-force=' not in vopts):
            raise RuntimeError(f"Btrfs mount at {mountpoint} is missing compression options after remount.")

    def _mount_device(self, devnode, mountpoint, use_fstab=False, announce_btrfs=False):
        dev_fstype = self._detect_fstype(devnode)
        if announce_btrfs and dev_fstype == 'btrfs':
            log(f"Enabling btrfs compression on {mountpoint} (compress=zstd:3).")
        run_command(['mkdir', '-p', mountpoint], sudo=True)
        if use_fstab:
            # Use /etc/fstab mount options and source selection.
            run_command(['mount', mountpoint], sudo=True)
        else:
            if dev_fstype == 'btrfs':
                run_command(['mount', '-o', 'compress=zstd:3', devnode, mountpoint], sudo=True)
            else:
                run_command(['mount', devnode, mountpoint], sudo=True)

        if dev_fstype == 'btrfs' or use_fstab:
            self._ensure_btrfs_compression_on_mount(mountpoint)

    def _invoking_user_group(self):
        """
        Return (user, group) for ownership operations.
        Prefer the invoking non-root user when diskmgr itself is launched via sudo.
        """
        user = (os.environ.get('SUDO_USER') or os.environ.get('USER') or '').strip()
        if user:
            try:
                pw = pwd.getpwnam(user)
                gid = int(pw.pw_gid)
                try:
                    group = grp.getgrgid(gid).gr_name
                except KeyError:
                    group = str(gid)
                return user, group
            except Exception:
                pass

        uid = os.getuid()
        gid = os.getgid()
        return str(uid), str(gid)

    def _chown_new_filesystem_root(self, mountpoint):
        """
        Set ownership of a newly-created filesystem root directory to the invoking user.
        Non-recursive by design.
        """
        mp = str(mountpoint or '').strip()
        if not mp:
            return
        user, group = self._invoking_user_group()
        try:
            run_command(['chown', f'{user}:{group}', mp], sudo=True, check=False)
            log(f"Set new filesystem ownership: {mp} -> {user}:{group}")
        except Exception as e:
            log(f"Could not set ownership on new filesystem root {mp}: {e}", 'WARN')

    def _desired_fstab_options(self, label, fstype=None):
        gvfs_name = str(label or "").replace(",", "_")
        gvfs_name = self._fstab_escape(gvfs_name)
        opts = ["defaults", "nofail"]
        if (str(fstype or "").strip().lower() == "btrfs"):
            opts.append("compress=zstd:3")
        opts.extend(["x-gvfs-show", f"x-gvfs-name={gvfs_name}"])
        return ",".join(opts)

    def _update_fstab_mountpoint(self, entry, new_mountpoint, new_opts=None):
        """
        Rewrite one existing /etc/fstab entry (matched by entry index).
        Preserves source/fstype/options/dump/pass and trailing inline comment.
        """
        idx = int(entry.get('index'))
        lines = self._read_system_fstab_lines()
        if idx < 0 or idx >= len(lines):
            raise RuntimeError("fstab entry index out of range")

        raw = lines[idx]
        comment = ""
        if '#' in raw:
            comment = raw.split('#', 1)[1].strip()

        line = (
            f"{entry.get('spec', '')}\t"
            f"{self._fstab_escape(new_mountpoint)}\t"
            f"{entry.get('fstype', 'auto')}\t"
            f"{new_opts if new_opts is not None else entry.get('opts', 'defaults')}\t"
            f"{entry.get('dump', '0')}\t"
            f"{entry.get('passno', '0')}"
        )
        if comment:
            line += f"  # {comment}"
        lines[idx] = line
        self._write_system_fstab_lines(lines)

    def _update_fstab_for_label_change(self, target_dev, old_label, new_label, fstype, add_entry):
        """
        Update host /etc/fstab after relabel.
        - Removes old-label fstab entry when old label is known.
        - Adds a new UUID= entry mounted at /mnt/<label> when add_entry=True.
        Returns (removed_count, added_count, new_mountpoint_or_empty).
        """
        lines = self._read_system_fstab_lines()
        old_mountpoint_media = f"/media/{os.environ.get('USER', 'root')}/{old_label}" if old_label else ""
        old_mountpoint_mnt = f"/mnt/{old_label}" if old_label else ""
        new_mountpoint = f"/mnt/{new_label}" if new_label else ""
        target_uuid = ""
        if add_entry:
            try:
                r_uuid = run_command(['blkid', '-o', 'value', '-s', 'UUID', target_dev], sudo=True, check=False)
                target_uuid = (getattr(r_uuid, 'stdout', '') or '').strip()
            except Exception:
                target_uuid = ""
            if not target_uuid:
                raise RuntimeError(f"Could not determine filesystem UUID for {target_dev}")

        out = []
        removed = 0

        for raw in lines:
            stripped = (raw or "").strip()
            if not stripped or stripped.startswith('#'):
                out.append(raw)
                continue

            body = raw.split('#', 1)[0].strip()
            parts = body.split()
            if len(parts) < 2:
                out.append(raw)
                continue

            spec = (parts[0] or "").strip()
            mountpoint = self._fstab_unescape((parts[1] or "").strip()) if len(parts) > 1 else ""
            spec_unesc = self._fstab_unescape(spec)
            remove = False

            if old_label:
                if spec.startswith("LABEL="):
                    lbl = self._fstab_unescape(spec[len("LABEL="):]).strip()
                    if lbl == old_label:
                        remove = True
                if spec_unesc == f"/dev/disk/by-label/{old_label}":
                    remove = True
                if mountpoint in (old_mountpoint_media, old_mountpoint_mnt):
                    remove = True

            if add_entry and new_label:
                if spec.startswith("LABEL="):
                    lbl = self._fstab_unescape(spec[len("LABEL="):]).strip()
                    if lbl == new_label:
                        remove = True
                if target_uuid and spec.startswith("UUID="):
                    u = self._fstab_unescape(spec[len("UUID="):]).strip().lower()
                    if u == str(target_uuid).strip().lower():
                        remove = True
                if mountpoint == new_mountpoint:
                    remove = True

            if remove:
                removed += 1
                continue
            out.append(raw)

        added = 0
        if add_entry and new_label:
            fs_t = (fstype or "auto").strip() or "auto"
            opts = self._desired_fstab_options(new_label, fs_t)
            entry = (
                f"UUID={self._fstab_escape(target_uuid)}\t"
                f"{self._fstab_escape(new_mountpoint)}\t"
                f"{fs_t}\t{opts}\t0\t0"
            )
            if out and out[-1].strip():
                out.append("")
            out.append(entry)
            added = 1

        if removed or added:
            self._write_system_fstab_lines(out)

        return removed, added, new_mountpoint

    def _findmnt_lookup(self):
        """
        Build mount metadata by source device from findmnt JSON.
        Returns:
          {
            "<real /dev path>": {
              "SOURCE": "<joined>",
              "FS-OPTIONS": "<joined>",
              "VFS-OPTIONS": "<joined>",
              "FS-USED": "<joined>",
            },
            ...
          }
        """
        lookup = {}
        try:
            res = run_command(['findmnt', '-A', '--output-all', '--json'], check=False)
            if getattr(res, 'returncode', 1) != 0:
                return {}
            raw = (getattr(res, 'stdout', '') or '').strip()
            if not raw:
                return {}
            data = json.loads(raw)
            roots = data.get('filesystems', [])
            if not isinstance(roots, list):
                return {}
        except Exception:
            return {}

        def _add_unique(lst, val):
            v = str(val or '').strip()
            if not v:
                return
            if v not in lst:
                lst.append(v)

        def _iter_findmnt_nodes(nodes):
            if not isinstance(nodes, list):
                return
            for node in nodes:
                if not isinstance(node, dict):
                    continue
                yield node
                children = node.get('children')
                if isinstance(children, list):
                    yield from _iter_findmnt_nodes(children)

        for fs in _iter_findmnt_nodes(roots):
            if not isinstance(fs, dict):
                continue
            src = str(fs.get('source') or '').strip()
            if not src or not src.startswith('/dev/'):
                continue

            fs_opts = str(fs.get('fs-options') or '').strip()
            vfs_opts = str(fs.get('vfs-options') or '').strip()
            fs_used = str(fs.get('used') or '').strip()

            keys = [src]
            try:
                src_real = os.path.realpath(src)
                if src_real and src_real not in keys:
                    keys.append(src_real)
            except Exception:
                pass

            for key in keys:
                slot = lookup.setdefault(key, {'SOURCE': [], 'FS-OPTIONS': [], 'VFS-OPTIONS': [], 'FS-USED': []})
                _add_unique(slot['SOURCE'], src)
                _add_unique(slot['FS-OPTIONS'], fs_opts)
                _add_unique(slot['VFS-OPTIONS'], vfs_opts)
                _add_unique(slot['FS-USED'], fs_used)

        out = {}
        for key, slot in lookup.items():
            out[key] = {
                'SOURCE': " | ".join(slot['SOURCE']) if slot['SOURCE'] else '-',
                'FS-OPTIONS': " | ".join(slot['FS-OPTIONS']) if slot['FS-OPTIONS'] else '-',
                'VFS-OPTIONS': " | ".join(slot['VFS-OPTIONS']) if slot['VFS-OPTIONS'] else '-',
                'FS-USED': " | ".join(slot['FS-USED']) if slot['FS-USED'] else '-',
            }
        return out

    def _lsblk_col_widths(self, rows, cols=None):
        if cols is None:
            cols = self._lsblk_verbose_cols()
        widths = {}
        for c in cols:
            widths[c] = len(c)
        for r in rows:
            for c in cols:
                v = str(r.get(c, "") or "")
                if len(v) > widths[c]:
                    widths[c] = len(v)
        # Add 1 space padding on each side.
        for c in cols:
            widths[c] += 2
        return widths

    def _lsblk_rendered_width(self, rows, widths=None, cols=None):
        """
        Return the maximum visible width for the rendered lsblk table (header + rows)
        using the same formatting logic as _print_lsblk_rows().
        """
        if cols is None:
            cols = self._lsblk_verbose_cols()
        if widths is None:
            widths = self._lsblk_col_widths(rows, cols=cols)

        def _line_for(values):
            parts = []
            for c in cols:
                inner = max(widths[c] - 2, 0)
                parts.append(f" {str(values.get(c, '') or ''):<{inner}} ")
            return "".join(parts).rstrip()

        max_len = len(_line_for({c: c for c in cols}))
        for r in rows:
            max_len = max(max_len, len(_line_for(r)))
        return max_len

    def _lsblk_rendered_list_width(self, rows, cols=None):
        """Return max visible width for list-style lsblk rendering."""
        if cols is None:
            cols = self._lsblk_verbose_cols()
        max_len = len("Entry 1")
        for i, r in enumerate(rows, start=1):
            max_len = max(max_len, len(f"Entry {i}"))
            for c in cols:
                v = self._lsblk_list_value(r, c)
                max_len = max(max_len, len(f"  {c}: {v}"))
        return max_len

    def _format_size_tib_gib(self, size_value):
        """
        Format byte-count sizes with higher precision in binary units.
        Uses GiB/TiB (and higher if needed), promoting units when rounding
        would otherwise show 1024.000 of the lower unit.
        """
        raw = str(size_value or '').strip()
        if not raw:
            return ""
        try:
            n = int(raw, 10)
        except (TypeError, ValueError):
            # Fallback for unexpected non-byte strings.
            return raw

        if n == 0:
            return "0 GiB"

        value = n / float(1024 ** 3)  # start in GiB
        units = ["GiB", "TiB", "PiB", "EiB"]
        idx = 0
        while idx < len(units) - 1 and round(value, 3) >= 1024.0:
            value /= 1024.0
            idx += 1
        return f"{value:.3f} {units[idx]}"

    def _format_bytes_binary(self, byte_value, decimals=2):
        """Format a raw byte count using binary units (B, KiB, MiB, GiB, TiB...) with fixed decimals."""
        raw = str(byte_value or '').strip()
        if not raw or raw == "-":
            return ""
        try:
            n = int(raw, 10)
        except (TypeError, ValueError):
            return raw
        if n < 0:
            return ""

        units = ["B", "KiB", "MiB", "GiB", "TiB", "PiB", "EiB"]
        idx = 0
        value = float(n)
        while idx < len(units) - 1 and value >= 1024.0:
            value /= 1024.0
            idx += 1
        while idx < len(units) - 1 and round(value, decimals) >= 1024.0:
            value /= 1024.0
            idx += 1

        if units[idx] == "B":
            return f"{int(value)} B"
        return f"{value:.{decimals}f} {units[idx]}"

    def _format_bytes_binary_with_metric(self, byte_value):
        """
        Format a raw byte count as:
          - binary: MiB/GiB/TiB (base 1024)
          - metric: (MB/GB/TB) in brackets (base 1000)
        Picks unit based on range (MiB < 1 GiB, GiB < 1 TiB, else TiB+).
        """
        raw = str(byte_value or "").strip()
        if not raw or raw == "-":
            return raw
        try:
            n = int(raw, 10)
        except (TypeError, ValueError):
            return raw
        if n < 0:
            return "-"

        if n >= 1024 ** 4:
            bin_unit = "TiB"
            bin_div = 1024 ** 4
            met_unit = "TB"
            met_div = 1000 ** 4
        elif n >= 1024 ** 3:
            bin_unit = "GiB"
            bin_div = 1024 ** 3
            met_unit = "GB"
            met_div = 1000 ** 3
        else:
            bin_unit = "MiB"
            bin_div = 1024 ** 2
            met_unit = "MB"
            met_div = 1000 ** 2

        bin_val = n / float(bin_div)
        met_val = n / float(met_div)

        # Binary: keep consistent 3-decimal precision like SIZE.
        bin_s = f"{bin_val:.3f} {bin_unit}"

        # Metric: fewer decimals for readability.
        if met_val >= 100:
            met_s = f"{met_val:.0f}{met_unit}"
        elif met_val >= 10:
            met_s = f"{met_val:.1f}{met_unit}"
        else:
            met_s = f"{met_val:.2f}{met_unit}"

        return f"{bin_s} ({met_s})"

    def _collect_lsblk_rows(self, devices, indent="", is_root=True, parent_wwn="", friendly_map=None, fstab_real_set=None, fstab_uuid_set=None, fstab_detail_real=None, fstab_detail_uuid=None, findmnt_lookup=None, include_ext4_details=True):
        """
        Collect an lsblk JSON tree into flat rows, while preserving the tree glyphs in NAME.
        Returns a list of dicts with consistent string keys.
        """
        rows = []
        if fstab_real_set is None:
            fstab_real_set = set()
        if fstab_uuid_set is None:
            fstab_uuid_set = set()
        if fstab_detail_real is None:
            fstab_detail_real = {}
        if fstab_detail_uuid is None:
            fstab_detail_uuid = {}
        if findmnt_lookup is None:
            findmnt_lookup = {}
        for i, dev in enumerate(devices):
            is_last = (i == len(devices) - 1)

            name = dev.get('name', '') or ""
            kname = dev.get('kname', '') or name
            dtype = dev.get('type') or ""
            size_bytes_raw = str(dev.get('size') or "").strip()
            size = self._format_size_tib_gib(size_bytes_raw)
            fstype = dev.get('fstype') or ""
            fsver = dev.get('fsver') or ""
            label = dev.get('label') or ""
            uuid = dev.get('uuid') or ""
            partuuid = dev.get('partuuid') or ""
            fsavail_raw = dev.get('fsavail') or ""
            fsavail = self._format_bytes_binary_with_metric(fsavail_raw)
            fsuse = dev.get('fsuse%') or ""
            fsused_bytes_raw = str(dev.get('fsused') or "").strip()
            # Partitions often don't carry WWN/EUI in lsblk output; inherit from parent disk when missing.
            wwn = dev.get('wwn') or parent_wwn or ""

            mp = dev.get('mountpoints', [])
            owner_probe_mount = ""
            if isinstance(mp, list):
                mount_list = [m for m in mp if m]
                mounts = ", ".join(mount_list)
                if mount_list:
                    owner_probe_mount = mount_list[0]
            else:
                mounts = str(mp or "")
                owner_probe_mount = mounts.split(",")[0].strip() if mounts else ""
            mounts_clean = mounts.strip()
            owner = "-"
            if owner_probe_mount:
                try:
                    st = os.stat(owner_probe_mount)
                    try:
                        owner_user = pwd.getpwuid(int(st.st_uid)).pw_name
                    except Exception:
                        owner_user = str(int(st.st_uid))
                    try:
                        owner_group = grp.getgrgid(int(st.st_gid)).gr_name
                    except Exception:
                        owner_group = str(int(st.st_gid))
                    owner = f"{owner_user} {owner_group}"
                except Exception:
                    owner = "-"

            # Persistent path: prefer IEEE identifier by-id links (WWN/EUI) when possible.
            pdp = "-"
            try:
                pdp = self.find_persistent_path(name, wwn=wwn, type_=dtype or 'disk')
            except Exception:
                pdp = "-"

            # Tree characters
            if is_root:
                # For device-mapper/crypto nodes, show the kernel name plus friendly name in brackets.
                # Example: dm-0 (1a)
                if dtype == 'crypt' and kname and name and kname != name:
                    tree_part = f"{kname} ({name})"
                else:
                    tree_part = name
                next_indent = ""
            else:
                char = "" if is_last else ""
                shown = name
                if dtype == 'crypt' and kname and name and kname != name:
                    shown = f"{kname} ({name})"
                tree_part = indent + char + shown
                next_indent = indent + ("    " if is_last else "   ")

            # Friendly name (diskmap.tsv) is only for real disk/partition nodes.
            friendly = "-"
            if dtype in ('disk', 'part') and friendly_map:
                try:
                    devnode = f"/dev/{name}"
                    if os.path.exists(devnode):
                        friendly = friendly_map.get(os.path.realpath(devnode), "-")
                except Exception:
                    friendly = "-"

            dev_real = os.path.realpath(f"/dev/{kname}")
            uuid_norm = (str(uuid).strip().lower() if uuid else "")
            in_fstab = (dev_real in fstab_real_set) or (uuid_norm in fstab_uuid_set if uuid_norm else False)
            fstab_entries = []
            for ent in fstab_detail_real.get(dev_real, []):
                if ent and ent not in fstab_entries:
                    fstab_entries.append(ent)
            if uuid_norm:
                for ent in fstab_detail_uuid.get(uuid_norm, []):
                    if ent and ent not in fstab_entries:
                        fstab_entries.append(ent)
            fstab_entry = " | ".join(fstab_entries) if fstab_entries else "-"
            findmnt_row = findmnt_lookup.get(dev_real) or findmnt_lookup.get(f"/dev/{kname}") or {}
            mount_source = str(findmnt_row.get('SOURCE') or '-')
            fs_options = str(findmnt_row.get('FS-OPTIONS') or '-')
            vfs_options = str(findmnt_row.get('VFS-OPTIONS') or '-')
            fs_used_metric = str(findmnt_row.get('FS-USED') or '-')
            fs_reserved = "-"
            fs_meta = "-"
            if include_ext4_details and str(fstype).strip().lower() == "ext4":
                fs_reserved, fs_meta = self._ext4_reserved_and_meta(
                    dev_real=dev_real,
                    size_bytes_raw=size_bytes_raw,
                    fsused_bytes_raw=fsused_bytes_raw,
                    fsavail_bytes_raw=str(fsavail_raw or "").strip(),
                )
            fstype_l = str(fstype or "").strip().lower()
            state = "-"
            if fstype_l == "crypto_luks":
                children = dev.get('children') or []
                has_crypt_child = any((str(ch.get('type') or "").strip().lower() == "crypt") for ch in children if isinstance(ch, dict))
                state = "OPEN" if has_crypt_child else "CLOSED"
            elif fstype_l:
                # Plain filesystem entries and open LUKS child filesystems.
                state = "MOUNTED" if mounts_clean else "UNMOUNTED"
            rows.append({
                "#": "-",
                "KNAME": kname,
                "PKNAME": str(dev.get('pkname') or ""),
                "NAME": friendly,
                "DEVICE": tree_part,
                "PERSISTENT PATH (IEEE)": pdp,
                "TYPE": dtype,
                "STATE": state,
                "OWNER": owner,
                "FSTAB": "y" if in_fstab else "n",
                "SIZE": size,
                "SIZE-BYTES": size_bytes_raw,
                "FSTYPE": fstype,
                "FSVER": fsver,
                "FSLABEL": label,
                "FSUUID": uuid,
                "PARTUUID": partuuid,
                "FSAVAIL": fsavail,
                "FSAVAIL-BYTES": str(fsavail_raw or "").strip(),
                "FSUSE%": fsuse,
                "FSRESERVED": fs_reserved,
                "FSMETA": fs_meta,
                "FSUSED-BYTES": fsused_bytes_raw,
                "FSMOUNTPOINTS": mounts,
                "SOURCE": mount_source,
                "FS-OPTIONS": fs_options,
                "VFS-OPTIONS": vfs_options,
                "FS-USED": fs_used_metric,
                "MOUNTPOINT": mounts,
                "FSTAB ENTRY": fstab_entry,
            })

            if 'children' in dev:
                rows.extend(self._collect_lsblk_rows(
                    dev['children'],
                    next_indent,
                    is_root=False,
                    parent_wwn=wwn,
                    friendly_map=friendly_map,
                    fstab_real_set=fstab_real_set,
                    fstab_uuid_set=fstab_uuid_set,
                    fstab_detail_real=fstab_detail_real,
                    fstab_detail_uuid=fstab_detail_uuid,
                    findmnt_lookup=findmnt_lookup,
                    include_ext4_details=include_ext4_details
                ))
        return rows

    def _build_list_rows_snapshot(self, include_ext4_details=True):
        """
        Build current list rows in the same shape as `list verbose`.
        Returns flat rows with global # numbering for disk/part/crypt entries.
        """
        all_devs = self.get_disk_info()
        disks = [d for d in all_devs if d.get('type') == 'disk']
        if not disks:
            return []

        friendly_map = {}
        try:
            self.mappings = read_luks_map()
            for friendly, target in (self.mappings or {}).items():
                try:
                    if target and os.path.exists(target):
                        friendly_map[os.path.realpath(target)] = friendly
                except Exception:
                    continue
        except Exception:
            friendly_map = {}

        fstab_real_set, fstab_uuid_set, fstab_detail_real, fstab_detail_uuid = self._fstab_lookup()
        findmnt_lookup = self._findmnt_lookup()

        rows = []
        for d in disks:
            d_name = d.get('name', '')
            if not d_name:
                continue
            dev_path = f"/dev/{d_name}"
            try:
                ls_res = run_command(['lsblk', '-J', '-b', '-f', '-o',
                                      'NAME,KNAME,PKNAME,TYPE,SIZE,FSTYPE,FSVER,LABEL,UUID,PARTUUID,FSAVAIL,FSUSE%,FSUSED,MOUNTPOINTS,WWN',
                                      dev_path], sudo=True, check=False)
                if (getattr(ls_res, 'stdout', '') or '').strip():
                    data = json.loads(ls_res.stdout)
                    blockdevices = data.get('blockdevices', [])
                    rows.extend(self._collect_lsblk_rows(
                        blockdevices,
                        friendly_map=friendly_map,
                        fstab_real_set=fstab_real_set,
                        fstab_uuid_set=fstab_uuid_set,
                        fstab_detail_real=fstab_detail_real,
                        fstab_detail_uuid=fstab_detail_uuid,
                        findmnt_lookup=findmnt_lookup,
                        include_ext4_details=include_ext4_details,
                    ))
            except Exception:
                continue

        idx = 1
        for r in rows:
            if (r.get('TYPE') or '') in ('disk', 'part', 'crypt'):
                r['#'] = str(idx)
                idx += 1
            else:
                r['#'] = '-'
        return rows

    def _show_target_entries_for_confirmation(self, target_name):
        """
        Print current list-list entry/entries for the target before math confirmation.
        Also includes an open crypt child when target is a LUKS container parent.
        """
        try:
            rows = self._build_list_rows_snapshot(include_ext4_details=True)
            if not rows:
                return

            target_paths = set()
            text = str(target_name or "").strip()

            # Any explicit /dev paths embedded in the confirmation label.
            for p in re.findall(r"/dev/[A-Za-z0-9._/-]+", text):
                p = p.rstrip("),]")
                if os.path.exists(p):
                    target_paths.add(os.path.realpath(p))

            # Direct path input.
            if text and os.path.exists(text):
                target_paths.add(os.path.realpath(text))

            token = text.split()[0].strip("[](),") if text else ""
            if token:
                try:
                    resolved = self.resolve_target(token, allow_id=True)
                except Exception:
                    resolved = None
                if resolved and os.path.exists(resolved):
                    target_paths.add(os.path.realpath(resolved))

                mapper_path = f"/dev/mapper/{token}"
                if os.path.exists(mapper_path):
                    target_paths.add(os.path.realpath(mapper_path))

            if not target_paths:
                return

            matched_knames = set()
            selected = []
            for r in rows:
                kname = str(r.get('KNAME') or "").strip()
                if not kname:
                    continue
                devreal = os.path.realpath(f"/dev/{kname}")
                if devreal in target_paths:
                    selected.append(r)
                    matched_knames.add(kname)

            # If a matched row is a LUKS container parent, include open crypt child row too.
            for r in rows:
                if (r.get('TYPE') or '') != 'crypt':
                    continue
                pk = str(r.get('PKNAME') or "").strip()
                if pk and pk in matched_knames and str(r.get('KNAME') or '') not in matched_knames:
                    selected.append(r)
                    matched_knames.add(str(r.get('KNAME') or ''))

            if not selected:
                return

            print(f"\n{Colors.BOLD}Target entry snapshot:{Colors.ENDC}")
            self._print_lsblk_rows_list(selected, cols=self._lsblk_verbose_cols())
        except Exception:
            # Confirmation should continue even if snapshot rendering fails.
            pass

    def _print_lsblk_rows(self, rows, widths=None, cols=None):
        """
        Print a column-aligned table where each cell is padded with one space on each side.
        Persistent path is printed immediately after NAME.
        """
        if cols is None:
            cols = self._lsblk_verbose_cols()
        if widths is None:
            widths = self._lsblk_col_widths(rows, cols=cols)

        def _cell(text, width):
            inner = max(width - 2, 0)
            return f" {text:<{inner}} "

        header = "".join([_cell(c, widths[c]) for c in cols]).rstrip()
        print(f"{Colors.BOLD}{header}{Colors.ENDC}")
        for r in rows:
            line = "".join([_cell(str(r.get(c, '') or ''), widths[c]) for c in cols]).rstrip()
            print(line)

    def _print_lsblk_rows_list(self, rows, cols=None, start_index=1):
        """Print rows as list-style key/value entries."""
        if cols is None:
            cols = self._lsblk_verbose_cols()
        for i, r in enumerate(rows, start=1):
            print(f"{Colors.BOLD}Entry {start_index + i - 1}{Colors.ENDC}")

            for c in cols:
                print(f"  {c}: {self._lsblk_list_value(r, c)}")
            if i != len(rows):
                print("")

    def _ext4_reserved_and_meta(self, dev_real, size_bytes_raw, fsused_bytes_raw, fsavail_bytes_raw):
        """
        Return (FSRESERVED, FSMETA) strings for an ext4 filesystem.
        FSRESERVED comes from tune2fs reserved block counters.
        FSMETA is metadata overhead estimate (prefers Overhead clusters when available).
        """
        key = (
            str(dev_real or ""),
            str(size_bytes_raw or ""),
            str(fsused_bytes_raw or ""),
            str(fsavail_bytes_raw or ""),
        )
        if key in self._ext4_tune2fs_cache:
            return self._ext4_tune2fs_cache[key]

        def _fmt_int(v):
            if v is None:
                return "-"
            return f"{int(v):,}"

        reserved_disp = "-"
        meta_disp = "-"
        try:
            res = run_command(['tune2fs', '-l', dev_real], sudo=True, capture_output=True, check=False)
            txt = (getattr(res, 'stdout', '') or '') + "\n" + (getattr(res, 'stderr', '') or '')
            if getattr(res, 'returncode', 1) != 0 or not txt.strip():
                self._ext4_tune2fs_cache[key] = (reserved_disp, meta_disp)
                return reserved_disp, meta_disp

            def _grab_int(pattern):
                m = re.search(pattern, txt, re.MULTILINE | re.IGNORECASE)
                if not m:
                    return None
                return _first_int_from_text(m.group(1))

            block_count = _grab_int(r"^\s*Block count:\s*([0-9,]+)\s*$")
            block_size = _grab_int(r"^\s*Block size:\s*([0-9,]+)\s*$")
            cluster_size = _grab_int(r"^\s*Cluster size:\s*([0-9,]+)\s*$")
            reserved_block_count = _grab_int(r"^\s*Reserved block count:\s*([0-9,]+)\s*$")
            reserved_pct = _grab_int(r"^\s*Reserved block percentage:\s*([0-9,]+)")
            overhead_clusters = _grab_int(r"^\s*Overhead clusters:\s*([0-9,]+)\s*$")

            reserved_bytes = None
            if reserved_block_count is not None and block_size is not None:
                reserved_bytes = int(reserved_block_count) * int(block_size)
                reserved_h = self._format_bytes_binary_with_metric(str(reserved_bytes))
                pct_txt = f"{reserved_pct}%" if reserved_pct is not None else "-"
                reserved_disp = f"{reserved_h} (rbc={_fmt_int(reserved_block_count)}, {pct_txt})"

            meta_bytes = None
            # Prefer ext4's explicit overhead clusters if available.
            if overhead_clusters is not None:
                unit = cluster_size if cluster_size is not None else block_size
                if unit is not None:
                    meta_bytes = int(overhead_clusters) * int(unit)
            # Fallback: derive metadata remainder from size-used-avail minus reserve.
            if meta_bytes is None:
                size_b = _first_int_from_text(size_bytes_raw)
                used_b = _first_int_from_text(fsused_bytes_raw)
                avail_b = _first_int_from_text(fsavail_bytes_raw)
                if size_b is not None and used_b is not None and avail_b is not None:
                    rem = int(size_b) - int(used_b) - int(avail_b)
                    if reserved_bytes is not None:
                        rem -= int(reserved_bytes)
                    meta_bytes = max(0, rem)

            if meta_bytes is not None:
                meta_h = self._format_bytes_binary_with_metric(str(meta_bytes))
                meta_disp = f"{meta_h} (bc={_fmt_int(block_count)}, bs={_fmt_int(block_size)})"

        except Exception:
            reserved_disp = "-"
            meta_disp = "-"

        self._ext4_tune2fs_cache[key] = (reserved_disp, meta_disp)
        return reserved_disp, meta_disp

    def _lsblk_list_value(self, row, col):
        """Return display value for list-mode cells."""
        if col == "DEVICE":
            dev = str(row.get("DEVICE", "") or "")
            # list-list only: remove lsblk tree glyph prefix (table view keeps glyphs).
            dev = re.sub(r"^[\s]*[]\s*", "", dev)
            return dev
        if col == "SIZE":
            size = str(row.get("SIZE", "") or "")
            size_gb = self._size_bytes_to_gb_label(row.get("SIZE-BYTES", ""))
            if size and size != "-" and size_gb and size_gb != "-":
                return f"{size} ({size_gb})"
            return size
        if col == "FSUSE%":
            fsuse = str(row.get("FSUSE%", "") or "")
            used = self._bytes_to_gib_tib_with_metric(row.get("FSUSED-BYTES", "")) or self._format_used_as_gib_tib(row.get("FS-USED", ""))
            if fsuse and fsuse != "-" and used and used != "-":
                return f"{fsuse} {used}"
            return fsuse
        return str(row.get(col, "") or "")

    def _bytes_to_gib_tib_with_metric(self, value):
        """Convert a raw byte-count string into 'GiB/TiB (GB/TB)' with 3-decimal binary precision."""
        raw = str(value or "").strip()
        if not raw:
            return "-"
        try:
            n = int(raw, 10)
        except (TypeError, ValueError):
            return "-"
        if n < 0:
            return "-"
        if n >= 1024 ** 4:
            bin_val = n / float(1024 ** 4)
            met_val = n / float(1000 ** 4)
            bin_s = f"{bin_val:.3f} TiB"
            met_unit = "TB"
        else:
            bin_val = n / float(1024 ** 3)
            met_val = n / float(1000 ** 3)
            bin_s = f"{bin_val:.3f} GiB"
            met_unit = "GB"

        if met_val >= 100:
            met_s = f"{met_val:.0f}{met_unit}"
        elif met_val >= 10:
            met_s = f"{met_val:.1f}{met_unit}"
        else:
            met_s = f"{met_val:.2f}{met_unit}"

        return f"{bin_s} ({met_s})"

    def _format_used_as_gib_tib(self, value):
        """
        Convert findmnt 'used' (usually like 822.8G / 1T / bytes) into a binary GiB/TiB string.
        Only outputs GiB or TiB (no MiB) as requested.
        """
        raw = str(value or "").strip()
        if not raw or raw == "-":
            return "-"

        # Bytes (e.g. if findmnt ever returns numeric-only).
        try:
            if raw.isdigit():
                n = int(raw, 10)
            else:
                m = re.match(r'^([0-9]+(?:\.[0-9]+)?)\\s*([KMGTPE])?$', raw, re.IGNORECASE)
                if not m:
                    return "-"
                num = float(m.group(1))
                unit = (m.group(2) or "").upper()
                pow_map = {"": 0, "K": 1, "M": 2, "G": 3, "T": 4, "P": 5, "E": 6}
                n = int(num * (1024 ** pow_map.get(unit, 0)))
        except Exception:
            return "-"

        if n < 0:
            return "-"
        if n >= 1024 ** 4:
            return f"{(n / float(1024 ** 4)):.3f} TiB"
        return f"{(n / float(1024 ** 3)):.3f} GiB"

    def _size_bytes_to_gb_label(self, size_bytes):
        """Render raw byte size as decimal GB for list-mode SIZE annotations."""
        try:
            n = int(str(size_bytes or "").strip(), 10)
        except (TypeError, ValueError):
            return "-"
        if n < 0:
            return "-"
        gb = n / float(1000 ** 3)
        if gb >= 100:
            return f"{gb:.0f}GB"
        if gb >= 10:
            return f"{gb:.1f}GB"
        return f"{gb:.2f}GB"

    def resolve_uuid_to_dev(self, uuid):
        '''Resolves a UUID to a short device name like sda1 or nvme0n1p1.'''
        uuid = uuid.strip()
        if not uuid or uuid == "(firmware)":
            return ""
        try:
            # Use check=False to avoid noisy logs if UUID doesn't resolve
            res = run_command(['blkid', '-U', uuid], sudo=True, capture_output=True, check=False)
            path = res.stdout.strip()
            if path:
                return os.path.basename(path)
        except:
            pass
        return ""

    def _render_fstab_file(self, fstab_path, indent="  "):
        """
        Render a single fstab file in a readable table.
        Returns True when a file is parsed/rendered, False otherwise.
        """
        fstab_path = Path(fstab_path)
        if not fstab_path.exists():
            print(f"{indent}{Colors.WARNING}Result: No fstab detected ({fstab_path}).{Colors.ENDC}")
            return False

        try:
            lines = fstab_path.read_text(errors='replace').splitlines()
        except Exception as e:
            print(f"{indent}{Colors.FAIL}Result: Could not read fstab ({fstab_path}): {e}{Colors.ENDC}")
            return False

        cols = ["#", "SOURCE", "TARGET", "FSTYPE", "OPTIONS", "DUMP", "PASS"]
        rows = []
        malformed = []
        ignored_comments = 0
        ignored_blank = 0

        for ln_no, raw in enumerate(lines, start=1):
            line = (raw or "").strip()
            if not line:
                ignored_blank += 1
                continue
            if line.startswith('#'):
                ignored_comments += 1
                continue

            body = raw.split('#', 1)[0].strip()
            if not body:
                ignored_comments += 1
                continue

            parts = body.split()
            if len(parts) < 4:
                malformed.append((ln_no, raw.rstrip()))
                continue

            spec, target, fstype, options = parts[:4]
            dump = parts[4] if len(parts) > 4 else "-"
            passno = parts[5] if len(parts) > 5 else "-"

            src_display = spec
            if spec.startswith("UUID="):
                uuid = spec[len("UUID="):]
                dev = self.resolve_uuid_to_dev(uuid)
                src_display = f"{spec} [{dev if dev else '-'}]"

            rows.append({
                "#": str(len(rows) + 1),
                "SOURCE": src_display,
                "TARGET": target,
                "FSTYPE": fstype,
                "OPTIONS": options,
                "DUMP": dump,
                "PASS": passno,
            })

        print(f"{indent}{Colors.OKGREEN}Result: Found fstab at {fstab_path}{Colors.ENDC}")
        if rows:
            widths = self._lsblk_col_widths(rows, cols=cols)

            def _cell(text, width):
                inner = max(width - 2, 0)
                return f" {text:<{inner}} "

            header = "".join([_cell(c, widths[c]) for c in cols]).rstrip()
            print(f"{indent}{Colors.BOLD}{header}{Colors.ENDC}")
            for r in rows:
                line = "".join([_cell(str(r.get(c, '') or ''), widths[c]) for c in cols]).rstrip()
                print(f"{indent}{line}")
        else:
            print(f"{indent}(No active fstab entries found.)")

        meta = f"Entries: {len(rows)}"
        meta += f" | Ignored comments: {ignored_comments}"
        meta += f" | Ignored blank lines: {ignored_blank}"
        print(f"{indent}{meta}")

        if malformed:
            print(f"{indent}{Colors.WARNING}Malformed lines (showing up to 5):{Colors.ENDC}")
            for ln_no, txt in malformed[:5]:
                print(f"{indent}  line {ln_no}: {txt}")
            if len(malformed) > 5:
                print(f"{indent}  ... {len(malformed) - 5} more")

        return True

    def do_boot(self, arg):
        '''Display boot entries from GRUB and fstab detection for each partition.
        
        UNDER THE HOOD:
        Scans partition devices. If mounted, it parses /boot/grub/grub.cfg
        and checks for /etc/fstab inside that mounted partition.
        If unmounted or encrypted, it explains why it cannot yet read the config.
        '''
        all_devs = self.get_disk_info()
        flat_disks = self.flatten_disks(all_devs)
        
        # AWK script parses Title <TAB> Entry <TAB> SEARCH <TAB> ROOT
        awk_script = r"""
  /search[[:space:]].*--fs-uuid/ {g_search=$NF}

  /^[[:space:]]*submenu / {
    submenu_title=$2
    next
  }

  /^[[:space:]]*menuentry / {
    e=$2; search_u=""; root_u=""; in_entry=1
    next
  }

  in_entry && search_u=="" && /search[[:space:]].*--fs-uuid/ {search_u=$NF}
  in_entry && root_u=="" && /(linux|linuxefi)[[:space:]].*root=UUID=/ {
    match($0,/root=UUID=[0-9a-fA-F-]+/)
    if (RSTART) root_u=substr($0,RSTART+10,RLENGTH-10)
  }

  in_entry && /^[[:space:]]*}/ {
    if (submenu_title=="") submenu_title="Top-level"
    s = (search_u!="" ? search_u : g_search)
    r = (root_u!=""   ? root_u   : "-")
    if (e ~ /UEFI Firmware Settings/) { s="(firmware)"; r="(firmware)" }
    
    print submenu_title "\t" e "\t" s "\t" r
    in_entry=0
  }
"""
        processed_devs = set()

        print(f"\n{Colors.HEADER}{Colors.BOLD}--- Partition Boot Configuration Scan ---{Colors.ENDC}")

        for dev in flat_disks:
            d_name = dev.get('name')
            d_kname = dev.get('kname', d_name)
            d_path = f"/dev/{d_kname}"
            d_type = dev.get('type')
            fstype = dev.get('fstype')
            mountpoint = dev.get('mountpoint')

            if d_type != 'part':
                continue
            
            if d_path in processed_devs:
                continue
            processed_devs.add(d_path)

            print(f"\n{Colors.OKBLUE}Partition: {d_path} ({fstype or 'unknown FS'}){Colors.ENDC}")

            if fstype == 'crypto_LUKS':
                print(f"  {Colors.WARNING}Result: LUKS container is LOCKED. Please 'open' this partition to scan for boot entries.{Colors.ENDC}")
                print(f"  {Colors.WARNING}Result: No fstab detected (locked encrypted partition).{Colors.ENDC}")
            elif not mountpoint:
                if fstype and fstype != '-':
                    print(f"  {Colors.WARNING}Result: Partition is UNMOUNTED. Please 'open' or mount the partition to scan for boot entries.{Colors.ENDC}")
                else:
                    print(f"  {Colors.WARNING}Result: No recognizable filesystem found.{Colors.ENDC}")
                print(f"  {Colors.WARNING}Result: No fstab detected (partition is not mounted).{Colors.ENDC}")
            else:
                cfg_path = Path(mountpoint) / "boot/grub/grub.cfg"
                fstab_path = Path(mountpoint) / "etc/fstab"
                display_path = str(cfg_path).replace("//", "/")
                try:
                    if cfg_path.exists():
                        print(f"  {Colors.OKGREEN}Result: Found GRUB config at {display_path}{Colors.ENDC}")
                        cmd = ['sudo', 'awk', '-F', "'", awk_script, str(cfg_path)]
                        res = run_command(cmd, capture_output=True)
                        
                        if res.stdout.strip():
                            entries = {}
                            for line in res.stdout.strip().splitlines():
                                if '\t' in line:
                                    parts = [x.strip() for x in line.split('\t')]
                                    if len(parts) == 4:
                                        sub, title, s_uuid, r_uuid = parts
                                        if sub not in entries: entries[sub] = []
                                        entries[sub].append((title, s_uuid, r_uuid))
                            
                            for sub, items in entries.items():
                                print(f"\n{sub}")
                                for i, (title, s_uuid, r_uuid) in enumerate(items):
                                    connector = "  " if i == len(items) - 1 else "  "
                                    
                                    s_dev = self.resolve_uuid_to_dev(s_uuid)
                                    r_dev = self.resolve_uuid_to_dev(r_uuid)
                                    
                                    s_info = f"SEARCH={s_uuid:<36} [{s_dev if s_dev else '-'}]"
                                    r_info = f"ROOT={r_uuid:<36} [{r_dev if r_dev else '-'}]"
                                    
                                    print(f"{connector} {title:<72}  {Colors.OKCYAN}{s_info}  {r_info}{Colors.ENDC}")
                        else:
                            print("  (No menu entries found in config)")
                    else:
                        print(f"  {Colors.OKCYAN}Result: Mounted at {mountpoint}, but no GRUB configuration found.{Colors.ENDC}")
                    self._render_fstab_file(fstab_path, indent="  ")
                except PermissionError:
                    print(f"  {Colors.FAIL}Result: Permission denied scanning {mountpoint} (System protected path).{Colors.ENDC}")
                    print(f"  {Colors.WARNING}Result: No fstab detected (permission denied).{Colors.ENDC}")
                except Exception as e:
                    print(f"  {Colors.FAIL}Result: Error checking path: {e}{Colors.ENDC}")
                    print(f"  {Colors.WARNING}Result: No fstab detected (scan error).{Colors.ENDC}")
            
            print("-" * 60)

    def resolve_target(self, target_str, allow_id=True):
        '''Resolves a target string to a physical path.
        Supports Discovery IDs (#1, [#1], and legacy U1/[U1]) or existing mapping names.
        '''
        clean = target_str.strip('[]')
        
        # 1. Check Discovery ID
        if allow_id:
            idx = None
            if clean.startswith('#') and clean[1:].isdigit():
                wanted = clean[1:]
                # Primary lookup: exact display ID from the last `list` run (e.g. "#7").
                for entry in (self.unmapped_cache or []):
                    try:
                        if str(entry.get('id', '')).strip() == wanted:
                            return entry.get('pdp')
                    except Exception:
                        continue
                # Backward-compatible fallback: positional index in cache.
                idx = int(wanted) - 1
            elif clean.startswith('U') and clean[1:].isdigit():
                # Backward-compatible legacy ID format.
                idx = int(clean[1:]) - 1

            if idx is not None:
                if 0 <= idx < len(self.unmapped_cache):
                    return self.unmapped_cache[idx]['pdp']
                return None
            
        # 2. Check Mapping Name
        self.mappings = read_luks_map()
        if target_str in self.mappings:
            return self.mappings[target_str]
            
        return None

    def extensive_confirm(self, target_name, destructive=True):
        print(f"\n{Colors.FAIL}{Colors.BOLD}!!! EXTENSIVE CONFIRMATION REQUIRED !!!{Colors.ENDC}")
        if destructive:
            print(f"You are about to perform a DESTRUCTIVE operation on: {Colors.WARNING}{target_name}{Colors.ENDC}")
        else:
            print(f"You are about to perform a HIGH-IMPACT operation on: {Colors.WARNING}{target_name}{Colors.ENDC}")
        self._show_target_entries_for_confirmation(target_name)
        print("To proceed, you must answer two math questions correctly.")
        
        for i in range(2):
            a = random.randint(11, 99)
            b = random.randint(11, 99)
            op = random.choice(['+', '-'])
            if op == '+':
                ans = a + b
            else:
                ans = a - b
            
            try:
                user_ans = self._input_no_history(f"Question {i+1}/2: What is {a} {op} {b}? ")
                if not user_ans or int(user_ans) != ans:
                    log("Incorrect answer. Aborting operation.", 'ERROR')
                    return False
            except ValueError:
                log("Invalid input. Aborting operation.", 'ERROR')
                return False
        
        print(f"{Colors.OKGREEN}Verification successful. Proceeding...{Colors.ENDC}")
        return True

    def is_root_disk(self, target_path):
        """Checks if the target path is the root disk or partition."""
        try:
            # Root SOURCE can be a partition (/dev/nvme0n1p1) or a dm-crypt device (/dev/dm-0).
            res = run_command(['findmnt', '-nro', 'SOURCE', '/'], capture_output=True)
            root_source = os.path.realpath(res.stdout.strip())

            target_real = os.path.realpath(target_path)

            def _top_level_disk(dev_path):
                """Return the top-level /dev/<disk> for any block device (partition/dm/crypt), or None."""
                cur = os.path.realpath(dev_path)
                seen = set()
                for _ in range(16):
                    if cur in seen:
                        return None
                    seen.add(cur)

                    if _lsblk_type(cur) == 'disk':
                        return cur

                    res_pk = run_command(['lsblk', '-no', 'PKNAME', cur], check=False)
                    pk = (getattr(res_pk, 'stdout', '') or '').strip()
                    if not pk:
                        return None
                    cur = os.path.realpath(f"/dev/{pk}")
                return None

            root_disk = _top_level_disk(root_source)
            target_disk = _top_level_disk(target_real)

            # Direct match against the root source (e.g., /dev/nvme0n1p1 or /dev/dm-0).
            if target_real == root_source:
                return True

            # Anything that resolves to the same physical disk as '/' counts as "root drive".
            if root_disk and target_disk and target_disk == root_disk:
                return True

        except:
            pass
        return False

    def _block_if_root_drive(self, target_path, operation):
        """Return True (and log) if target_path is on the system root drive."""
        try:
            if self.is_root_disk(target_path):
                log(f"OPERATION BLOCKED: {operation} is not allowed on the system root drive ({target_path}).", 'ERROR')
                return True
        except Exception:
            pass
        return False

    def do_map(self, arg):
        '''Create or modify a persistent mapping: map <name/id> <name>
        
        Usage:
          map [#1] backup    Assigns friendly name to discovery ID (e.g., map #1 backup)
          map 1a backup      Renames an existing mapping (e.g., map 1a backup)
        
        Note: Raw device paths (e.g., /dev/sdb) are NOT allowed.
        
        UNDER THE HOOD:
        1.  Input Resolution: 
            - discovery ID (e.g., [#1]): Resolves the temporary device to its Persistent Device Path (PDP).
            - mapping name (e.g., 1a): Selects an existing mapping for RENAME operations.
        2.  PDP Linking: Extracts the /dev/disk/by-id/ path for the target hardware.
        3.  Conflict Check: Ensures the new friendly name is not already in use.
        4.  Persistence: Writes the [Name <TAB> PDP] pair to diskmap.tsv.
        
        This ensures the disk is recognized correctly regardless of USB port or device node changes.
        '''
        args = arg.split()
        if len(args) != 2:
            log("Usage: map <id/name> <new_name>", 'ERROR')
            return

        target, name = args
        self.mappings = read_luks_map() # Refresh

        clean_target = target.strip('[]')
        old_name = None
        real_target = None

        # 1. Rename by current mapping name.
        if target in self.mappings:
            old_name = target
            real_target = self.mappings[target]
            log(f"Renaming mapping {target} -> {name}")
        else:
            # 2. Rename by missing-mapping list ID (#N) from latest `list`.
            if clean_target.startswith('#') and clean_target[1:].isdigit():
                missing_old = self.missing_map_id_cache.get(clean_target[1:])
                if missing_old and missing_old in self.mappings:
                    old_name = missing_old
                    real_target = self.mappings[missing_old]
                    log(f"Renaming missing mapping {missing_old} -> {name}")

        # 3. New map (target is a normal discovery ID/path).
        if real_target is None:
            real_target = self.resolve_target(target)
            if not real_target:
                log(f"Invalid target: '{target}'. Use a Discovery ID (e.g., [#1]) or an existing name.", 'ERROR')
                return
            log(f"Resolved {target} -> {real_target}")

        if name in self.mappings and name != old_name:
            log(f"Mapping '{name}' already exists.", 'ERROR')
            return

        # Collision Prevention: Prevent names that look like IDs
        clean_name = name.strip('[]')
        if (
            (clean_name.startswith('#') and clean_name[1:].isdigit()) or
            (clean_name.startswith('U') and clean_name[1:].isdigit()) or
            clean_name.isdigit()
        ):
            log(f"Invalid name: '{name}'. Names cannot be simple numbers or match discovery ID formats like '#1'.", 'ERROR')
            return

        if old_name and old_name in self.mappings:
            del self.mappings[old_name]
        self.mappings[name] = real_target
        save_luks_map(self.mappings)
        log(f"Mapping saved: {name} -> {real_target}")

    def do_unmap(self, arg):
        '''Remove a persistent mapping: unmap <name/id>
        
        UNDER THE HOOD:
        1.  Resolution:
            - Name mode: removes the exact mapping name.
            - ID mode (#N): resolves to a device and removes mapping(s) pointing to that device.
        2.  Removal: Deletes the [Name <TAB> PDP] pair(s) from the internal dictionary.
        3.  Persistence: Re-writes diskmap.tsv with the mapping(s) removed.
        '''
        target = arg.strip()
        if not target:
            log("Usage: unmap <name/id>", 'ERROR')
            return

        self.mappings = read_luks_map()
        if target in self.mappings:
            del self.mappings[target]
            save_luks_map(self.mappings)
            log(f"Mapping '{target}' removed successfully.")
            return

        # ID path: resolve target and remove any mapping(s) that point to that same real device.
        resolved = self.resolve_target(target, allow_id=True)
        if not resolved:
            log(f"Unknown target: '{target}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        resolved_real = os.path.realpath(resolved)
        to_remove = []
        for name, path in list(self.mappings.items()):
            try:
                if os.path.realpath(path) == resolved_real:
                    to_remove.append(name)
            except Exception:
                continue

        if not to_remove:
            log(f"No mapping found for target: '{target}' ({resolved_real})", 'ERROR')
            return

        for name in to_remove:
            del self.mappings[name]
        save_luks_map(self.mappings)
        if len(to_remove) == 1:
            log(f"Mapping '{to_remove[0]}' removed successfully.")
        else:
            log(f"Removed {len(to_remove)} mappings for {resolved_real}: {', '.join(to_remove)}")

    def do_open(self, arg):
        '''Unlock (if encrypted) and mount a disk: open <name/id>
        
        UNDER THE HOOD:
        1.  Identity Resolution: Looks up the friendly name in diskmap.tsv.
        2.  Hardware Wait: Polls for up to 10 seconds to allow for hardware spin-up/udev events.
        3.  Validation: 
            - Runs 'cryptsetup isLuks' to check for encryption.
            - If NOT encrypted (Plain Disk): 
              * Skips decryption step.
              * Verifies the existence of a valid filesystem.
              * Proceeds to label detection and mounting.
        4.  Decryption (LUKS only):
            - Executes 'passgen' to retrieve the passphrase.
            - Pipes the passphrase into 'cryptsetup open' to create a cleartext device in /dev/mapper/.
        5.  Mounting:
            - Uses /etc/fstab mountpoint/options when an entry exists for the device.
            - Otherwise identifies preferred mountpoint: /media/$USER/<label>.
            - If no hardware label is present, falls back to /media/$USER/<mapping_name>.
            - Ensures the directory exists and attaches the device.
            - For btrfs, enforces compression (compress=zstd:3) on the mounted filesystem.
        6.  Policy Enforcement: If the disk is already mounted at a non-standard path, 
            it unmounts and remounts it to the preferred path.

        SAFETY NOTE:
        - If your mapping points to a whole disk (e.g. /dev/sda) but the actual LUKS/filesystem
          lives on a partition (e.g. /dev/sda2), diskmgr will only auto-select a partition when
          it is unambiguous (exactly one candidate). Otherwise it will refuse and ask you to map
          the correct partition explicitly.
        '''
        target = arg.strip()
        if not target:
             log("Usage: open <name/id>", 'ERROR')
             return

        self.mappings = read_luks_map()
        mapping_name = None
        src = None

        if target.startswith('#') and target[1:].isdigit():
            rid = target[1:]
            src = self.id_cache.get(rid)
            if not src:
                # Backward-compatible fallback (unmapped discovery subset).
                src = self.resolve_target(target, allow_id=True)
            if not src:
                log(f"Unknown discovery ID: {target}. Run 'list' first to refresh IDs.", 'ERROR')
                return
            src_real = os.path.realpath(src)
            for n, p in self.mappings.items():
                try:
                    if os.path.realpath(p) == src_real:
                        mapping_name = n
                        break
                except Exception:
                    continue
        else:
            mapping_name = target
            if mapping_name not in self.mappings:
                log(f"Unknown mapping: {mapping_name}. Use 'list' to find Discovery IDs and 'map' them first.", 'ERROR')
                return
            src = self.mappings[mapping_name]
        
        # Wait for device
        log(f"Waiting for device {src}...")
        for _ in range(50): # 10s wait
            if os.path.exists(src):
                break
            time.sleep(0.2)
            
        if not os.path.exists(src):
            log(f"Device not found: {src}", 'ERROR')
            return
            
        mapped_devnode = os.path.realpath(src)
        op_ref = mapping_name or target
        if self._block_if_root_drive(mapped_devnode, f"open {op_ref}"):
            return
        devnode = mapped_devnode

        # Check LUKS / filesystem, with safe partition auto-detection when mapping points at a disk.
        is_luks = False
        try:
            res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
            if res.returncode == 0:
                is_luks = True
        except Exception:
            pass

        if not is_luks:
            dev_type = _lsblk_type(devnode)

            # If mapping points at a whole disk, try to locate the real payload on a partition.
            if dev_type == 'disk':
                disk_fs = _lsblk_fstype(devnode)
                if disk_fs:
                    log(f"Device {devnode} is a whole-disk filesystem ({disk_fs}). Proceeding with plain mount.")
                else:
                    parts = _lsblk_partitions(devnode)
                    luks_parts = [p for p in parts if p.get('fstype') == 'crypto_LUKS']
                    fs_parts = [p for p in parts if p.get('fstype') and p.get('fstype') != 'crypto_LUKS']

                    if len(luks_parts) == 1:
                        part_path = os.path.realpath(f"/dev/{luks_parts[0]['name']}")
                        log(f"Target '{op_ref}' points to disk {mapped_devnode}, but LUKS was detected on {part_path}. Using the partition for open.")
                        devnode = part_path
                        is_luks = True
                    elif len(luks_parts) > 1:
                        log(f"Target '{op_ref}' points to disk {mapped_devnode}, but multiple LUKS partitions were found.", 'ERROR')
                        for p in luks_parts:
                            log(f"  candidate: /dev/{p['name']} (fstype={p.get('fstype')})", 'ERROR')
                        log("Please map the correct partition explicitly and open that mapping.", 'ERROR')
                        return
                    elif len(fs_parts) == 1:
                        part_path = os.path.realpath(f"/dev/{fs_parts[0]['name']}")
                        log(f"Target '{op_ref}' points to disk {mapped_devnode}, but a filesystem was detected on {part_path} ({fs_parts[0].get('fstype')}). Using the partition for open.")
                        devnode = part_path
                    elif len(fs_parts) > 1:
                        log(f"Target '{op_ref}' points to disk {mapped_devnode}, but multiple filesystem partitions were found.", 'ERROR')
                        for p in fs_parts:
                            log(f"  candidate: /dev/{p['name']} (fstype={p.get('fstype')})", 'ERROR')
                        log("Please map the correct partition explicitly and open that mapping.", 'ERROR')
                        return
                    else:
                        log(f"Device {devnode} is not a valid LUKS device and has no recognizable filesystem (disk has partitions but none look mountable).", 'ERROR')
                        return

            # Re-check LUKS if we switched from disk -> partition.
            if devnode != mapped_devnode and not is_luks:
                try:
                    res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
                    if res.returncode == 0:
                        is_luks = True
                except Exception:
                    pass

            if not is_luks:
                # Not LUKS, check if it has a filesystem
                fs = _lsblk_fstype(devnode)
                if not fs:
                    log(f"Device {devnode} is not a valid LUKS device and has no recognizable filesystem.", 'ERROR')
                    return
                log(f"Device {devnode} is not LUKS, but has a filesystem ({fs}). Proceeding with plain mount.")

        mapper_path = f"/dev/mapper/{mapping_name}" if mapping_name else None
        target_to_mount = mapper_path if mapper_path else devnode

        if is_luks:
            if not mapping_name:
                log("ID target points to a LUKS container. Map it first (map #N <name>) and run open <name>.", 'ERROR')
                return
            if not os.path.exists(mapper_path):
                log(f"Opening LUKS mapping {mapping_name}...")
                # Use passgen
                pg_cmd = subprocess.Popen([PASSGEN_BIN], stdout=subprocess.PIPE, text=True)
                # Pipe to cryptsetup
                try:
                    run_command(
                        ['cryptsetup', 'open', '--key-file', '-', src, mapping_name],
                        input_str=pg_cmd.communicate()[0],
                        sudo=True,
                        check=True
                    )
                    log("LUKS opened.")
                except Exception as e:
                    log(f"Failed to open LUKS: {e}", 'ERROR')
                    return
            else:
                log("Mapping already exists.")
        else:
            # Plain disk
            target_to_mount = devnode

        # Detect label for fallback mountpoint
        mount_name = mapping_name if mapping_name else os.path.basename(devnode)
        try:
            res_b = run_command(['blkid', '-o', 'value', '-s', 'LABEL', target_to_mount], sudo=True, check=False)
            if res_b.stdout.strip():
                mount_name = res_b.stdout.strip()
        except:
            pass

        fallback_mountpoint = f"/media/{os.environ.get('USER', 'root')}/{mount_name}"
        mountpoint, use_fstab_mount, fstab_entry = self._select_mountpoint_for_device(
            target_to_mount,
            fallback_mountpoint,
            preferred_label=mount_name
        )
        if use_fstab_mount:
            log(f"Using fstab mount for {target_to_mount}: {fstab_entry['spec']} -> {mountpoint}")
        
        # Safety Check: Is this mountpoint already in use by another device?
        res_check = run_command(['findmnt', '-rn', '-M', mountpoint], check=False)
        if res_check.returncode == 0:
            # Check if it's a DIFFERENT device
            res_src = run_command(['findmnt', '-rn', '-M', mountpoint, '-o', 'SOURCE'], capture_output=True)
            current_src = os.path.realpath(res_src.stdout.strip())
            if current_src != os.path.realpath(target_to_mount):
                log(f"MOUNT BLOCKED: Path {mountpoint} is already in use by {current_src}.", 'ERROR')
                return

        # Check if mounted (may have multiple mount targets)
        current_targets = find_mount_targets(target_to_mount)

        if not current_targets:
            log(f"Mounting {target_to_mount} to {mountpoint}...")
            self._mount_device(target_to_mount, mountpoint, use_fstab=use_fstab_mount, announce_btrfs=True)
            log("Mounted.")
        elif mountpoint in current_targets:
            extra = [t for t in current_targets if t != mountpoint]
            if extra:
                log(f"Disk is also mounted at {', '.join(extra)}. Unmounting extra mount(s)...")
                for mp in extra:
                    try:
                        run_command(['umount', mp], sudo=True)
                    except Exception as e:
                        log(f"Failed to unmount {mp}: {e}. It may be in use.", 'WARN')
            try:
                self._ensure_btrfs_compression_on_mount(mountpoint)
            except Exception as e:
                log(f"Failed to enforce btrfs compression on {mountpoint}: {e}", 'ERROR')
                return
            log(f"Already mounted at {mountpoint}.")
        else:
            log(f"Disk is mounted at {', '.join(current_targets)} (system default). Overriding...")
            try:
                for mp in current_targets:
                    run_command(['umount', mp], sudo=True)
                self._mount_device(target_to_mount, mountpoint, use_fstab=use_fstab_mount, announce_btrfs=True)
                log(f"Successfully moved mount to {mountpoint}")
            except Exception as e:
                log(f"Failed to override mount: {e}. It may be in use.", 'WARN')

    def do_close(self, arg):
        '''Unmount and lock (if encrypted) a disk: close <name/id>
        
        UNDER THE HOOD:
        1.  Unmounting (Encrypted & Plain): 
            - Flushes all pending writes to the disk (data integrity).
            - Terminates active file handles to the device.
            - Attempts unmount by mapper path (LUKS), source path (Plain), or guessed mountpoint.
        2.  Locking (LUKS only):
            - Commands the kernel to wipe encryption keys from RAM.
            - Removes the virtual cleartext device from /dev/mapper/.
        3.  Audit: Checks and displays remaining active mappings for security awareness.
        '''
        target = arg.strip()
        if not target:
            log("Usage: close <name/id>", 'ERROR')
            return

        # Support discovery IDs (#N) from the latest `list` output.
        if target.startswith('#') and target[1:].isdigit():
            rid = target[1:]
            dev_from_id = self.id_cache.get(rid)
            if not dev_from_id:
                log(f"Unknown discovery ID: {target}. Run 'list' first to refresh IDs.", 'ERROR')
                return
            dev_from_id = os.path.realpath(dev_from_id)

            # If this ID corresponds to an existing friendly mapping, delegate to close <name>
            # so LUKS mapper-name semantics (cryptsetup close <name>) are preserved.
            self.mappings = read_luks_map()
            mapped_name = None
            for n, p in self.mappings.items():
                try:
                    if os.path.realpath(p) == dev_from_id:
                        mapped_name = n
                        break
                except Exception:
                    continue
            if mapped_name:
                return self.do_close(mapped_name)

            # Otherwise perform a direct close by device path.
            if self._block_if_root_drive(dev_from_id, f"close {target}"):
                return

            run_command(['sudo', '-v'])  # Refresh sudo

            targets = find_mount_targets(dev_from_id)
            unmounted_targets = []
            for mp in targets:
                log(f"Unmounting {mp}...")
                run_command(['umount', mp], sudo=True)
                unmounted_targets.append(mp)
            for mp in unmounted_targets:
                cleanup_mountpoint_dir(mp)

            # For ID-targeted close, do not implicitly lock LUKS.
            # This path is used heavily for payload/embedded filesystem rows; keep it as unmount-only.
            d_type = (_lsblk_type(dev_from_id) or '').strip().lower()
            if d_type == 'crypt':
                if unmounted_targets:
                    log("Unmounted target filesystem. LUKS mapping left open (ID close is unmount-only).")
                else:
                    log("Target is a crypt mapping but nothing was mounted. LUKS mapping left open (ID close is unmount-only).")
            elif not unmounted_targets:
                log("Target is not mounted and has no closable crypt mapping.")
            return

        name = target

        # Never attempt unmount/close operations on the system root drive.
        self.mappings = read_luks_map()
        if name in self.mappings:
            real_src = os.path.realpath(self.mappings[name])
            if self._block_if_root_drive(real_src, f"close {name}"):
                return

        mapper_path = f"/dev/mapper/{name}"
        mount_guess = f"/media/{os.environ.get('USER', 'root')}/{name}"

        run_command(['sudo', '-v']) # Refresh sudo

        # Unmount
        unmounted = False
        unmounted_targets = []
        # 1. Try by mapper
        targets = find_mount_targets(mapper_path)
        if targets:
            for mp in targets:
                log(f"Unmounting {mp}...")
                run_command(['umount', mp], sudo=True)
                unmounted_targets.append(mp)
            unmounted = True
        
        # 2. Try by source path (for non-LUKS)
        if not unmounted:
            self.mappings = read_luks_map()
            if name in self.mappings:
                src = self.mappings[name]
                targets = find_mount_targets(src)
                if targets:
                    for mp in targets:
                        log(f"Unmounting {mp}...")
                        run_command(['umount', mp], sudo=True)
                        unmounted_targets.append(mp)
                    unmounted = True

        # 3. Try by guess
        if not unmounted:
            if run_command(['findmnt', '-rn', '-M', mount_guess], check=False).returncode == 0:
                 log(f"Unmounting {mount_guess}...")
                 run_command(['umount', mount_guess], sudo=True)
                 unmounted_targets.append(mount_guess)
                 unmounted = True

        # Cleanup mountpoint dir(s) (best-effort)
        for mp in unmounted_targets:
            cleanup_mountpoint_dir(mp)
        
        # Close
        if os.path.exists(mapper_path):
            log(f"Closing mapping {name}...")
            run_command(['cryptsetup', 'close', name], sudo=True)
            log("Closed.")
        else:
            log("Mapping not open or already closed.")

    def do_label(self, arg):
        '''Get or set the filesystem label of an OPEN disk: label <name> [new_label] [--fstab]

        UNDER THE HOOD:
        1.  Validation: Verifies that the disk is currently open/unlocked.
        2.  Identification: Queries the filesystem type (ext4, xfs, etc.) via 'lsblk'.
        3.  Labeling:
            - ext4: Uses 'e2label' on the active device.
            - xfs: Requires a temporary unmount, then uses 'xfs_admin -L', then remounts.
        4.  Refresh: Executes 'udevadm trigger' to force tools like 'lsblk' to see the change.
        5.  Optional fstab update (--fstab):
            - Removes old label-based /etc/fstab entry.
            - Adds UUID-based entry with mountpoint /mnt/<new_label>.
        
        The label is written directly to the disk hardware and persists across different computers.
        '''
        parser = CmdArgumentParser(prog='label', add_help=False)
        parser.add_argument('name')
        parser.add_argument('new_label', nargs='?')
        parser.add_argument('--fstab', action='store_true', help='Add a new LABEL= fstab entry for the new label')
        
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.name
        new_label = args.new_label
        write_fstab = args.fstab

        if write_fstab and not new_label:
            log("Usage: label <name> <new_label> [--fstab]", 'ERROR')
            return
        
        # Resolve target device
        target_dev = None
        mapper_path = f"/dev/mapper/{name}"
        
        if os.path.exists(mapper_path):
            target_dev = mapper_path
        else:
            self.mappings = read_luks_map()
            if name in self.mappings:
                src = self.mappings[name]
                if not os.path.exists(src):
                    log(f"Device for mapping '{name}' is missing: {src}", 'ERROR')
                    return
                
                devnode = os.path.realpath(src)
                # Check if it's LUKS
                try:
                    res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
                    if res.returncode == 0:
                        log(f"Mapping '{name}' is LUKS but not open. Please 'open {name}' first.", 'ERROR')
                        return
                    # if returncode != 0, it's not LUKS, which is what we want for a plain disk
                except:
                    pass
                
                target_dev = devnode
            else:
                log(f"Device not found or unknown mapping: {name}", 'ERROR')
                return
             
        if self._block_if_root_drive(target_dev, f"label {name}"):
            return

        # Get info
        try:
            cmd = ['lsblk', '-J', '-o', 'FSTYPE,MOUNTPOINT,LABEL', target_dev]
            res = run_command(cmd, capture_output=True)
            data = json.loads(res.stdout)
            dev = data.get('blockdevices', [{}])[0]
            fstype = dev.get('fstype')
            mountpoint = dev.get('mountpoint')
            current_label = dev.get('label')
        except Exception as e:
            log(f"Failed to inspect device: {e}", 'ERROR')
            return
            
        if not new_label:
            print(f"Label for {name} ({fstype}): {current_label if current_label else '<none>'}")
            return

        label_changed = False
        remount_needed = False
        old_label = current_label or ""

        if current_label == new_label:
            log("Label is already set to that value.")
        else:
            log(f"Changing label: '{current_label}' -> '{new_label}' ({fstype})")

            if fstype == 'ext4':
                try:
                    run_command(['e2label', target_dev, new_label], sudo=True)
                    run_command(['udevadm', 'trigger', '--name-match=' + target_dev], sudo=True)
                    run_command(['udevadm', 'settle'], sudo=True)
                    label_changed = True
                    log("Label updated.")
                except Exception:
                    return
            elif fstype == 'xfs':
                # XFS requires unmount
                targets = find_mount_targets(target_dev)
                if targets:
                    log(f"XFS requires unmounting to label. Unmounting {', '.join(targets)}...")
                    try:
                        for mp in targets:
                            run_command(['umount', mp], sudo=True)
                        remount_needed = True
                        # Best effort: remember prior mountpoint if we don't have an fstab entry.
                        mountpoint = mountpoint or targets[0]
                    except Exception as e:
                        log(f"Failed to unmount: {e}", 'ERROR')
                        return

                try:
                    run_command(['xfs_admin', '-L', new_label, target_dev], sudo=True)
                    run_command(['udevadm', 'trigger', '--name-match=' + target_dev], sudo=True)
                    run_command(['udevadm', 'settle'], sudo=True)
                    label_changed = True
                    log("Label updated.")
                except Exception:
                    return
            else:
                log(f"Unsupported filesystem for labeling: {fstype}", 'ERROR')
                return

        if label_changed or write_fstab:
            if write_fstab and not label_changed:
                log("Label is unchanged; ensuring /etc/fstab entry is present for this label.")
            try:
                removed, added, new_mp = self._update_fstab_for_label_change(
                    target_dev=target_dev,
                    old_label=old_label,
                    new_label=new_label,
                    fstype=fstype,
                    add_entry=write_fstab
                )
                if removed:
                    log(f"Removed {removed} old fstab entr{'y' if removed == 1 else 'ies'} for previous label.")
                if write_fstab:
                    if added:
                        log(f"Added new fstab entry: UUID=<fsuuid> -> {new_mp}")
                    else:
                        log("No new fstab entry was added.")
            except Exception as e:
                log(f"Failed to update /etc/fstab after relabel: {e}", 'ERROR')

        if remount_needed:
            fallback_mp = mountpoint or f"/media/{os.environ.get('USER', 'root')}/{new_label}"
            final_mp, use_fstab_mount, fstab_entry = self._select_mountpoint_for_device(
                target_dev,
                fallback_mp,
                preferred_label=new_label
            )
            if use_fstab_mount:
                log(f"Remounting via fstab: {fstab_entry['spec']} -> {final_mp}")
            else:
                log(f"Remounting {final_mp}...")
            try:
                self._mount_device(target_dev, final_mp, use_fstab=use_fstab_mount)
            except Exception as e:
                log(f"Failed to remount: {e}. You may need to mount manually.", 'ERROR')

    def do_remount(self, arg):
        '''Remount an OPEN disk to its label mountpoint: remount <name>

        This fixes "mounted twice" and "data1/data2 suffix" issues by moving the mount
        to the canonical path: /mnt/<label> when the device has an /etc/fstab entry;
        otherwise /media/$USER/<label>.

        SAFETY RULES:
        - Refuses if the target mountpoint is already mounted by a different device.
        - Refuses if the target directory exists, is not a mountpoint, and is non-empty.
        - Refuses only when neither /etc/fstab entry nor filesystem LABEL is available.

        UNDER THE HOOD:
        1.  Resolve Device: Uses /dev/mapper/<name> if present, otherwise the mapped source path.
            If the mapping is LUKS and not OPEN, it refuses.
        2.  Target Mountpoint:
            - If /etc/fstab entry exists, enforce /mnt/<label> (and update the fstab mountpoint if needed).
            - Otherwise, fall back to /media/$USER/<label>.
        3.  Preflight: Validates selected mountpoint is safe to use.
        4.  Unmount: Unmounts all current mount targets for the device (if any).
        5.  Cleanup: Removes empty old mountpoint directories under /media/$USER (best-effort rmdir).
        6.  Mount: Uses fstab mount when present; otherwise direct mount to LABEL path.
            For btrfs, compression is enforced (compress=zstd:3).
        '''
        parser = CmdArgumentParser(prog='remount', add_help=False)
        parser.add_argument('name')

        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.name

        # Resolve target device (must be OPEN if it's LUKS).
        target_dev = None
        mapper_path = f"/dev/mapper/{name}"
        if os.path.exists(mapper_path):
            target_dev = mapper_path
        else:
            self.mappings = read_luks_map()
            if name not in self.mappings:
                log(f"Device not found or unknown mapping: {name}", 'ERROR')
                return

            src = self.mappings[name]
            if not os.path.exists(src):
                log(f"Device for mapping '{name}' is missing: {src}", 'ERROR')
                return

            devnode = os.path.realpath(src)
            try:
                res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
                if res.returncode == 0:
                    log(f"Mapping '{name}' is LUKS but not open. Please 'open {name}' first.", 'ERROR')
                    return
            except:
                pass

            target_dev = devnode

        if self._block_if_root_drive(target_dev, f"remount {name}"):
            return

        # Preferred mountpoint: fstab entry first, otherwise /media/$USER/<label>.
        label = ""
        try:
            res_b = run_command(['blkid', '-o', 'value', '-s', 'LABEL', target_dev], sudo=True, check=False)
            label = (getattr(res_b, 'stdout', '') or '').strip()
        except:
            pass
        fs_type = self._detect_fstype(target_dev)

        fallback_mountpoint = f"/media/{os.environ.get('USER', 'root')}/{label}" if label else ""
        fstab_entry = self._find_fstab_entry_for_device(target_dev, preferred_label=label or None)
        use_fstab_mount = bool(fstab_entry)

        if use_fstab_mount:
            if label:
                desired_mountpoint = f"/mnt/{label}"
                desired_opts = self._desired_fstab_options(label, fs_type)
                need_mountpoint_update = (fstab_entry.get('mountpoint') != desired_mountpoint)
                need_opts_update = (str(fstab_entry.get('opts') or '') != desired_opts)
                if need_mountpoint_update or need_opts_update:
                    try:
                        self._update_fstab_mountpoint(fstab_entry, desired_mountpoint, new_opts=desired_opts)
                        if need_mountpoint_update and need_opts_update:
                            log(f"Updated fstab mountpoint/options for remount: {fstab_entry['spec']} -> {desired_mountpoint} ({desired_opts})")
                        elif need_mountpoint_update:
                            log(f"Updated fstab mountpoint for remount: {fstab_entry['spec']} -> {desired_mountpoint}")
                        else:
                            log(f"Updated fstab options for remount: {fstab_entry['spec']} -> {desired_opts}")
                    except Exception as e:
                        log(f"Failed to update fstab entry for remount: {e}", 'ERROR')
                        return
                new_mountpoint = desired_mountpoint
            else:
                new_mountpoint = fstab_entry['mountpoint']
            log(f"Using fstab mount for remount: {fstab_entry['spec']} -> {new_mountpoint}")
        else:
            if not label:
                log(f"REMOUNT BLOCKED: {name} has no filesystem label and no fstab entry.", 'ERROR')
                log("Set a label with: label <name> <new_label> or add an /etc/fstab entry.", 'ERROR')
                return
            new_mountpoint = fallback_mountpoint

        # Safety: is target mountpoint already in use by another device?
        res_check = run_command(['findmnt', '-rn', '-M', new_mountpoint], check=False)
        if res_check.returncode == 0:
            res_src = run_command(['findmnt', '-rn', '-M', new_mountpoint, '-o', 'SOURCE'], check=False)
            current_src = os.path.realpath(res_src.stdout.strip()) if res_src.stdout.strip() else ""
            if current_src and current_src != os.path.realpath(target_dev):
                log(f"REMOUNT BLOCKED: Mountpoint {new_mountpoint} is already in use by {current_src}.", 'ERROR')
                return

        # Figure out where it's mounted now (may be multiple targets).
        current_targets = find_mount_targets(target_dev)

        if new_mountpoint in current_targets:
            extra = [t for t in current_targets if t != new_mountpoint]
            if not extra:
                try:
                    self._ensure_btrfs_compression_on_mount(new_mountpoint)
                except Exception as e:
                    log(f"Failed to enforce btrfs compression on {new_mountpoint}: {e}", 'ERROR')
                    return
                log(f"Already mounted at {new_mountpoint}.")
                return

            log(f"Disk is also mounted at {', '.join(extra)}. Unmounting extra mount(s)...")
            try:
                for mp in extra:
                    run_command(['umount', mp], sudo=True)
                    cleanup_mountpoint_dir(mp)
            except Exception as e:
                log(f"Failed to unmount extra mount(s): {e}", 'ERROR')
                return
            try:
                self._ensure_btrfs_compression_on_mount(new_mountpoint)
            except Exception as e:
                log(f"Failed to enforce btrfs compression on {new_mountpoint}: {e}", 'ERROR')
            return

        if current_targets:
            log(f"Unmounting {', '.join(current_targets)} for remount...")
            try:
                for mp in current_targets:
                    run_command(['umount', mp], sudo=True)
                    if mp != new_mountpoint:
                        cleanup_mountpoint_dir(mp)
            except Exception as e:
                log(f"Failed to unmount existing mount(s): {e}", 'ERROR')
                return

        # Target dir exists but isn't a mountpoint; it must be empty to be safe to mount over.
        if os.path.exists(new_mountpoint):
            if run_command(['findmnt', '-rn', '-M', new_mountpoint], check=False).returncode != 0:
                try:
                    if os.path.isdir(new_mountpoint) and os.listdir(new_mountpoint):
                        log(f"REMOUNT BLOCKED: Directory {new_mountpoint} exists and is not empty.", 'ERROR')
                        return
                except Exception as e:
                    log(f"REMOUNT BLOCKED: Unable to inspect {new_mountpoint}: {e}", 'ERROR')
                    return

        log(f"Mounting {target_dev} to {new_mountpoint}...")
        try:
            self._mount_device(target_dev, new_mountpoint, use_fstab=use_fstab_mount, announce_btrfs=True)
            log(f"Remounted successfully at {new_mountpoint}")
        except Exception as e:
            log(f"Failed to mount at {new_mountpoint}: {e}", 'ERROR')

    def do_luks(self, arg):
        '''LUKS encryption management: luks <passwd|backup|restore|header> [options]
        
        Subcommands:
          passwd <name>           Change the LUKS passphrase.
          backup <name> [file]    Save the LUKS header to a file.
          restore <name> <file>   Restore the LUKS header from a file (Destructive).
          header <name>           Print the current LUKS header (cryptsetup luksDump).
        '''
        args = arg.split()
        if not args:
            self.do_help('luks')
            return

        subcmd = args[0]
        sub_args = args[1:]

        if subcmd == 'passwd':
            if not sub_args:
                log("Usage: luks passwd <name>", 'ERROR')
                return
            name = sub_args[0]
            src = self.resolve_target(name, allow_id=False)
            if not src:
                log(f"Unknown mapping: '{name}'.", 'ERROR')
                return
            devnode = os.path.realpath(src)
            if self._block_if_root_drive(devnode, f"luks passwd {name}"):
                return
            res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
            if res.returncode != 0:
                log(f"Device {name} ({devnode}) is not a LUKS encrypted device.", 'ERROR')
                return
            log(f"Starting passphrase change for {name} ({devnode})...")
            try:
                run_command(['cryptsetup', 'luksChangeKey', devnode], sudo=True, capture_output=False)
                log("Passphrase updated successfully.")
            except Exception as e:
                log(f"Failed to change passphrase: {e}", 'ERROR')

        elif subcmd == 'backup':
            if not sub_args:
                log("Usage: luks backup <name> [filename]", 'ERROR')
                return
            name = sub_args[0]
            filename = sub_args[1] if len(sub_args) > 1 else f"{name}.header.bak"
            src = self.resolve_target(name)
            if not src:
                log(f"Unknown target: '{name}'", 'ERROR')
                return
            devnode = os.path.realpath(src)
            if self._block_if_root_drive(devnode, f"luks backup {name}"):
                return
            res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
            if res.returncode != 0:
                log(f"Device {devnode} is not a valid LUKS device.", 'ERROR')
                return
            log(f"Backing up LUKS header from {name} ({devnode}) to {filename}...")
            try:
                run_command(['cryptsetup', 'luksHeaderBackup', devnode, '--header-backup-file', filename], sudo=True)
                log(f"Header backup successful: {filename}")
            except Exception as e:
                log(f"Backup failed: {e}", 'ERROR')

        elif subcmd == 'restore':
            if len(sub_args) < 2:
                log("Usage: luks restore <name> <filename>", 'ERROR')
                return
            name, filename = sub_args[0], sub_args[1]
            if not os.path.exists(filename):
                log(f"Backup file not found: {filename}", 'ERROR')
                return
            src = self.resolve_target(name)
            if not src:
                log(f"Unknown target: '{name}'", 'ERROR')
                return
            devnode = os.path.realpath(src)
            if self._block_if_root_drive(devnode, f"luks restore {name}"):
                return
            log(f"RESTORE WARNING: About to overwrite LUKS header on {name} ({devnode}) using {filename}")
            if not self.extensive_confirm(name):
                return
            run_command(['sudo', '-v'])
            try:
                run_command(['cryptsetup', 'luksHeaderRestore', devnode, '--header-backup-file', filename], sudo=True)
                log("Header restore completed successfully.")
            except Exception as e:
                log(f"Restore failed: {e}", 'ERROR')
        elif subcmd == 'header':
            if not sub_args:
                log("Usage: luks header <name>", 'ERROR')
                return
            name = sub_args[0]
            src = self.resolve_target(name)
            if not src:
                log(f"Unknown target: '{name}'", 'ERROR')
                return
            devnode = os.path.realpath(src)
            if self._block_if_root_drive(devnode, f"luks header {name}"):
                return
            res = run_command(['cryptsetup', 'isLuks', devnode], sudo=True, check=False)
            if res.returncode != 0:
                log(f"Device {devnode} is not a valid LUKS device.", 'ERROR')
                return
            log(f"Printing LUKS header for {name} ({devnode})...")
            try:
                dump = run_command(['cryptsetup', 'luksDump', devnode], sudo=True, capture_output=True)
                print(getattr(dump, 'stdout', '') or "")
            except Exception as e:
                log(f"Failed to print LUKS header: {e}", 'ERROR')
        else:
            log(f"Unknown LUKS subcommand: {subcmd}", 'ERROR')
            self.do_help('luks')

    def _soft_erase_target(self, real_target):
        dev_type = _lsblk_type(real_target)

        wipefs_bin = _find_tool_or_common_paths('wipefs', [
            '/usr/sbin/wipefs',
            '/sbin/wipefs',
            '/usr/bin/wipefs',
            '/bin/wipefs',
        ]) or 'wipefs'
        sgdisk_bin = _find_tool_or_common_paths('sgdisk', [
            '/usr/sbin/sgdisk',
            '/sbin/sgdisk',
            '/usr/bin/sgdisk',
            '/bin/sgdisk',
        ])
        sfdisk_bin = _find_tool_or_common_paths('sfdisk', [
            '/usr/sbin/sfdisk',
            '/sbin/sfdisk',
            '/usr/bin/sfdisk',
            '/bin/sfdisk',
        ]) or 'sfdisk'

        log(f"Soft erase: wiping signatures on {real_target} ...")

        # If this is a whole disk, wipe signatures on existing partitions first (best-effort).
        if dev_type == 'disk':
            parts = []
            try:
                res_p = run_command(['lsblk', '-nr', '-o', 'NAME,TYPE', real_target], check=False)
                for line in (getattr(res_p, 'stdout', '') or '').splitlines():
                    cols = line.strip().split()
                    if len(cols) >= 2 and cols[1] == 'part':
                        parts.append(os.path.realpath(f"/dev/{cols[0]}"))
            except Exception:
                parts = []

            for p in parts:
                run_command([wipefs_bin, '-a', p], sudo=True, check=False)

            # For whole disks, --force is required to erase partition-table signatures.
            run_command([wipefs_bin, '-a', '--force', real_target], sudo=True, check=False)

            # Zap GPT/MBR metadata to remove "ghost" headers (e.g., GPT backup at end-of-disk).
            try:
                res_pt = run_command(['lsblk', '-no', 'PTTYPE', real_target], check=False)
                pttype = (getattr(res_pt, 'stdout', '') or '').strip().lower()
            except Exception:
                pttype = ""

            if pttype == 'gpt' or not pttype:
                if sgdisk_bin:
                    run_command([sgdisk_bin, '--zap-all', real_target], sudo=True, check=False)
            if pttype in ('dos', 'msdos'):
                # Write an empty DOS partition table (no partitions).
                script = "label: dos\n"
                run_command([sfdisk_bin, '--wipe', 'always', '--wipe-partitions', 'always', real_target],
                            sudo=True, input_str=script, check=False)

            run_command(['udevadm', 'settle'], sudo=True, check=False)
            run_command(['partprobe', real_target], sudo=True, check=False)
        else:
            run_command([wipefs_bin, '-a', real_target], sudo=True, check=False)
            run_command(['udevadm', 'settle'], sudo=True, check=False)

        log("Soft erase completed.")

    def _disk_looks_erased_for_create(self, real_target):
        """Best-effort precheck used by create: disk must look erased."""
        if _lsblk_type(real_target) != 'disk':
            return (False, "target is not a whole disk")

        # Must have no child partitions.
        try:
            res_p = run_command(['lsblk', '-nr', '-o', 'NAME,TYPE', real_target], check=False)
            parts = []
            for line in (getattr(res_p, 'stdout', '') or '').splitlines():
                cols = line.strip().split()
                if len(cols) >= 2 and cols[1] == 'part':
                    parts.append(cols[0])
            if parts:
                return (False, f"disk still has partition(s): {', '.join(parts)}")
        except Exception:
            pass

        # Must not currently report a partition table type.
        try:
            res_pt = run_command(['lsblk', '-no', 'PTTYPE', real_target], check=False)
            pttype = (getattr(res_pt, 'stdout', '') or '').strip().lower()
            if pttype:
                return (False, f"disk still has partition-table metadata ({pttype})")
        except Exception:
            pass

        # Must not have a probe-detectable signature on the whole-disk node.
        try:
            res_b = run_command(['blkid', '-p', real_target], check=False)
            if getattr(res_b, 'returncode', 1) == 0:
                sig = (getattr(res_b, 'stdout', '') or '').strip() or (getattr(res_b, 'stderr', '') or '').strip()
                if sig:
                    return (False, f"disk still has metadata/signature: {sig}")
                return (False, "disk still has metadata/signature")
        except Exception:
            pass

        return (True, "")

    def _largest_free_extent_sectors(self, disk_dev):
        """
        Return (start_sector, end_sector, size_sector) for the largest free extent on a disk,
        using `parted -m unit s print free`. Returns None if no free extent is found.
        """
        try:
            res = run_command(['parted', '-m', '-s', disk_dev, 'unit', 's', 'print', 'free'],
                              sudo=True, check=False)
            if getattr(res, 'returncode', 1) != 0:
                return None

            best = None
            for raw in (getattr(res, 'stdout', '') or '').splitlines():
                line = raw.strip()
                if not line or line.startswith('BYT') or line.startswith('/'):
                    continue
                parts = line.strip(';').split(':')
                if len(parts) < 5:
                    continue

                fs_or_type = parts[4].strip()
                if fs_or_type != 'free':
                    continue

                try:
                    start_s = int(parts[1].rstrip('s'))
                    end_s = int(parts[2].rstrip('s'))
                    size_s = int(parts[3].rstrip('s'))
                except Exception:
                    continue

                if size_s <= 0:
                    continue

                if (best is None) or (size_s > best[2]):
                    best = (start_s, end_s, size_s)

            return best
        except Exception:
            return None

    def do_erase(self, arg):
        '''Fast metadata wipe (soft erase): erase <name/id> [--soft]
        
        This is a fast "re-provisioning" wipe. It removes recognizable signatures and zaps GPT/MBR metadata
        (when the target is a whole disk). It is NOT a secure wipe.

        It performs:
          - wipefs -a (and --force for whole-disk partition-table signatures)
          - sgdisk --zap-all (GPT) when available
          - sfdisk (MBR)

        Note: This is a DESTRUCTIVE operation. Solving two math problems is MANDATORY to proceed.
        '''
        parser = CmdArgumentParser(prog='erase', add_help=False)
        parser.add_argument('target', help='Target name or device')
        parser.add_argument('--soft', action='store_true', help='(Deprecated) erase is already soft; flag is ignored')

        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.target
        real_target = self.resolve_target(name, allow_id=True)

        if not real_target:
            log(f"Unknown target: '{name}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        if not os.path.exists(real_target):
            log(f"Target not found: {real_target}", 'ERROR')
            return

        real_target = os.path.realpath(real_target)
        log(f"Target resolved: {real_target}")

        if self.is_root_disk(real_target):
            log(f"OPERATION BLOCKED: {real_target} is part of the system root drive!", 'ERROR')
            return

        # Refuse to operate on mounted devices (erase is destructive).
        try:
            res_m = run_command(['lsblk', '-nr', '-o', 'MOUNTPOINT', real_target], check=False)
            mounts = [ln.strip() for ln in (getattr(res_m, 'stdout', '') or '').splitlines() if ln.strip()]
            if mounts:
                log(f"OPERATION BLOCKED: {real_target} has mounted filesystems ({', '.join(mounts)}). Unmount/close it first.", 'ERROR')
                return
        except Exception:
            pass

        if not self.extensive_confirm(real_target):
            return

        run_command(['sudo', '-v'])

        if args.soft:
            log("--soft is deprecated: erase is already a soft/metadata wipe.", 'WARN')

        self._soft_erase_target(real_target)

    def do_nuke(self, arg):
        '''Securely erase a disk: nuke <name/id>
        
        Note: You must 'map' a disk first to give it a name before erasing it.

        NUANCES & SAFETY:
        - Whole Disk (sda): 
          Attempts deep hardware-level wipes (NVMe Sanitize, ATA Secure Erase, etc.). 
          Destroys the Partition Table and ALL partitions on the drive.
        - Partition (sda2): 
          Hardware-level wipes are SKIPPED for safety. The script falls back to 
          highly effective software wipes (blkdiscard or dd zero-overwrite).
          ONLY the specified partition is wiped; other partitions remain safe.
        - Mapped Name (1a): 
          Resolves to the physical partition and follows partition-level safety rules.
        
        UNDER THE HOOD:
        1.  Target Resolution: Maps friendly name to a raw block device.
        2.  Destructive Wipe:
            - NVMe: Prioritizes (1) Sanitize Crypto Erase, (2) Sanitize Block Erase, 
              (3) Format Crypto Erase, and (4) Format Block Erase.
            - SSD: Prioritizes (1) PSID Revert, (2) ATA Sanitize, (3) ATA Secure Erase (Enhanced), 
              (4) ATA Secure Erase (Standard), (5) blkdiscard --secure, and (6) blkdiscard.
            - HDD: Prioritizes (1) ATA Sanitize, (2) ATA Secure Erase (Enhanced), 
              (3) ATA Secure Erase (Standard), and (4) Zero Overwrite + Verify.
        3.  Verification: Executes 'udevadm settle' and 'sync' to ensure all operations are committed.
        
        Note: This is a DESTRUCTIVE operation. Solving two math problems is MANDATORY to proceed.

        WARNING: This operation is IRREVERSIBLE.
        '''
        parser = CmdArgumentParser(prog='nuke', add_help=False)
        parser.add_argument('target', help='Target name or device')
        
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.target
        real_target = self.resolve_target(name, allow_id=True)
        
        if not real_target:
            log(f"Unknown target: '{name}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return
        
        if not os.path.exists(real_target):
            log(f"Target not found: {real_target}", 'ERROR')
            return
            
        real_target = os.path.realpath(real_target)
        log(f"Target resolved: {real_target}")
        
        if self.is_root_disk(real_target):
            log(f"OPERATION BLOCKED: {real_target} is part of the system root drive!", 'ERROR')
            return

        # Refuse to operate on mounted devices (soft erase is still destructive).
        try:
            res_m = run_command(['lsblk', '-nr', '-o', 'MOUNTPOINT', real_target], check=False)
            mounts = [ln.strip() for ln in (getattr(res_m, 'stdout', '') or '').splitlines() if ln.strip()]
            if mounts:
                log(f"OPERATION BLOCKED: {real_target} has mounted filesystems ({', '.join(mounts)}). Unmount/close it first.", 'ERROR')
                return
        except Exception:
            pass

        if not self.extensive_confirm(real_target):
            return

        run_command(['sudo', '-v'])

        start_ts = time.time()
        log_path = _cmd_log_open("nuke") if (_CMD_LOG_FH is None) else _CMD_LOG_PATH
        if log_path:
            print(f"Log: {log_path}")
        ok = False
        try:
            ok = bool(secure_erase_disk(real_target))
            if ok:
                log("Secure erase completed successfully.")
            else:
                log("Secure erase failed.", 'ERROR')
        finally:
            print(f"Duration: {_fmt_hms(time.time() - start_ts)}")
            _cmd_log_close()

    def do_clone(self, arg):
        '''Clone one disk or partition to another: clone <src_name/id> <dst_name/id>
        
        WARNING (DATA DESTRUCTION):
        - This command writes directly to the destination block device (like running ddrescue/dd).
        - The destination is overwritten starting at byte 0. Any existing partition table,
          filesystems, and files on the destination WILL BE DESTROYED.
        - If the destination is larger than the source, bytes beyond the source size are
          not overwritten. Old data may still physically exist there, but it will not be
          referenced by the cloned partition table.
        - diskmgr does NOT unmount the destination for you. Unmount/close it first to
          avoid live corruption.
        - If you need to sanitize the destination (secure wipe), run: nuke <dst_name>
        - If you only need a fast metadata wipe for re-provisioning, run: erase <dst_name>

        Note: The target disk MUST be the same size or larger than the source.
        
        STEP-BY-STEP PROCESS:
        1.  Resolution: Maps both friendly names to their physical device nodes (PDP).
        2.  Size Validation: Queries 'blockdev --getsize64' for both. Aborts if dst < src.
        3.  Safety Audit: Verifies that the target is NOT the system root drive.
        4.  Confirmation: Requires solving two math problems to authorize data destruction.
        5.  Cloning: Executes ddrescue in two phases:
            - Pass 1: 'ddrescue --force <src> <dst> <mapfile>'
            - Retry:  'ddrescue --force -r3 <src> <dst> <mapfile>'
        6.  Sync: Flushes kernel buffers to ensure all data is physically committed to disk.

        Note: This is a DESTRUCTIVE operation. Solving two math problems is MANDATORY to proceed.

        SCENARIOS:
        - Drive to Drive: 
          Creates a 1:1 bit-perfect clone. The target disk becomes an identical twin, 
          including the Partition Table, UUIDs, and all partitions. 
          Note: If the target is larger, the extra space appears as 'free' at the end.
        - Partition to Partition: 
          Copies the internal data of the source partition into the target partition. 
          Useful for moving a LUKS container or a specific filesystem. 
          Warning: Filesystem UUIDs will be duplicated; avoid mounting both simultaneously.
        - Partition to Drive: 
          The source partition's content is written to the start of the physical disk. 
          This destroys the target's partition table and turns the disk into a 
          "partitionless" volume (e.g., a raw LUKS device).
        - Drive to Partition (DANGEROUS): 
          Writes the source's boot sectors and partition table into the target partition. 
          This usually results in an unreadable "nested" structure.

        CLONING & ENCRYPTION (CRITICAL):
        - Source is LOCKED (e.g., clone sda sdb): 
          Creates a bit-perfect "Encrypted Twin." The destination remains encrypted 
          and requires the same password. (Recommended for backups).
        - Source is OPEN (e.g., clone sda sdb): 
          Copies encrypted data but may capture a "dirty" filesystem state if 
          files are currently being written. (Close before cloning if possible).
        - Source is MAPPER (e.g., clone dm-0 sdb): 
          Performs a "Strip-and-Clone." The destination receives RAW DECRYPTED 
          DATA. The resulting clone will be completely UNENCRYPTED.
        '''
        args = arg.split()
        if len(args) != 2:
            log("Usage: clone <src_name/id> <dst_name/id>", 'ERROR')
            return

        src_name, dst_name = args
        src_path = self.resolve_target(src_name, allow_id=True)
        dst_path = self.resolve_target(dst_name, allow_id=True)

        if not src_path:
            log(f"Unknown source target: '{src_name}'. Use mapping name or discovery ID (#N).", 'ERROR')
            return
        if not dst_path:
            log(f"Unknown destination target: '{dst_name}'. Use mapping name or discovery ID (#N).", 'ERROR')
            return

        src_real = os.path.realpath(src_path)
        dst_real = os.path.realpath(dst_path)

        if src_real == dst_real:
            log("Source and target are the same device!", 'ERROR')
            return

        # Also block cloning within the same physical disk (e.g. name for disk + #N resolving to same disk).
        def _top_level_disk(dev_path):
            try:
                mapped_name = _sysfs_block_name(dev_path)
                disk_name = _sysfs_to_parent_disk_name(mapped_name)
                candidate = os.path.realpath(f"/dev/{disk_name}")
                if os.path.exists(candidate):
                    return candidate
            except Exception:
                pass
            return None

        src_disk = _top_level_disk(src_real)
        dst_disk = _top_level_disk(dst_real)
        if src_disk and dst_disk and src_disk == dst_disk:
            log(f"OPERATION BLOCKED: source ({src_real}) and target ({dst_real}) are on the same physical disk ({src_disk}).", 'ERROR')
            log("Choose a destination on a different physical disk.", 'ERROR')
            return

        if self.is_root_disk(dst_real):
            log(f"OPERATION BLOCKED: {dst_name} ({dst_real}) is the system root drive!", 'ERROR')
            return

        # Compare sizes
        try:
            src_bytes = int(run_command(['sudo', 'blockdev', '--getsize64', src_real], capture_output=True).stdout.strip())
            dst_bytes = int(run_command(['sudo', 'blockdev', '--getsize64', dst_real], capture_output=True).stdout.strip())
            
            if dst_bytes < src_bytes:
                log(f"Target disk is too small! (Source: {src_bytes}B, Target: {dst_bytes}B)", 'ERROR')
                return
        except Exception as e:
            log(f"Failed to verify disk sizes: {e}", 'ERROR')
            return

        ddrescue_bin = _find_tool_or_common_paths('ddrescue', [
            '/usr/bin/ddrescue',
            '/bin/ddrescue',
            '/usr/local/bin/ddrescue',
        ])
        if ddrescue_bin is None:
            log("ddrescue not found. Install 'gddrescue' and retry.", 'ERROR')
            return

        # Prefer logical sector size for reporting failures.
        sector_size = 512
        try:
            res_ss = run_command(['sudo', 'blockdev', '--getss', src_real], capture_output=True, check=False)
            ss = (getattr(res_ss, 'stdout', '') or '').strip()
            if ss.isdigit():
                sector_size = int(ss)
        except Exception:
            sector_size = 512

        # Refuse to run if anything on the destination device tree is mounted.
        # (Whole-disk clone should not proceed if any target partitions are mounted.)
        try:
            res_m = run_command(['lsblk', '-nr', '-o', 'MOUNTPOINT', dst_real], check=False)
            mounts = [ln.strip() for ln in (getattr(res_m, 'stdout', '') or '').splitlines() if ln.strip()]
            if mounts:
                log(f"Target has mounted filesystems ({', '.join(mounts)}). Unmount/close {dst_name} first.", 'ERROR')
                return
        except Exception:
            pass

        # Confirmation
        if not self.extensive_confirm(f"{dst_name} ({dst_real})"):
            return

        run_command(['sudo', '-v'])
        log(f"Cloning {src_name} -> {dst_name}...")
        start_ts = time.time()
        
        # Perform clone
        try:
            safe_src = re.sub(r'[^A-Za-z0-9_.-]+', '_', src_name)
            safe_dst = re.sub(r'[^A-Za-z0-9_.-]+', '_', dst_name)
            mapdir = Path('/tmp/diskmgr_clone_maps')
            os.makedirs(mapdir, exist_ok=True)
            mapfile = str(mapdir / f"{safe_src}_to_{safe_dst}.map")

            log(f"ddrescue mapfile: {mapfile}")
            # Pass 1: fast clone + mapfile progress.
            cmd = [ddrescue_bin, '--force', src_real, dst_real, mapfile]
            res1 = run_command(cmd, sudo=True, capture_output=False, check=False)

            # Pass 2: retry failed areas (up to 3 times).
            log("ddrescue retry pass: -r3 (retry failed sectors up to 3 times)...")
            cmd_retry = [ddrescue_bin, '--force', '-r3', src_real, dst_real, mapfile]
            res2 = run_command(cmd_retry, sudo=True, capture_output=False, check=False)
            run_command(['sync'], sudo=True, check=False)

            # Report failures based on mapfile after retries.
            failed = _parse_ddrescue_failed_ranges(mapfile, sector_size=sector_size)
            if failed:
                log(f"Unrecovered sectors remain after retries (mapfile: {mapfile}).", 'WARN')
                print(f"\n{Colors.FAIL}{Colors.BOLD}Unrecovered sector ranges:{Colors.ENDC}")
                max_show = 80
                for r in failed[:max_show]:
                    # LBA range shown as [start, end) for clarity.
                    print(f"  LBA [{r['start_lba']}, {r['end_lba']})  count={r['count_lba']}  bytes={r['size_b']}")
                if len(failed) > max_show:
                    print(f"  ... truncated ({len(failed)} ranges total)")
                print(f"\n{Colors.WARNING}Mapfile:{Colors.ENDC} {mapfile}")
            else:
                log("Cloning complete (no unrecovered sectors reported in the ddrescue mapfile).")

            # ddrescue uses bitmask exit codes; preserve them in logs for troubleshooting.
            rc1 = getattr(res1, 'returncode', 0)
            rc2 = getattr(res2, 'returncode', 0)
            if rc1 != 0 or rc2 != 0:
                log(f"ddrescue exit status: pass1={rc1}, retry={rc2} (non-zero can indicate read errors even if output is usable).", 'WARN')
        except Exception as e:
            log(f"Cloning failed: {e}", 'ERROR')
        finally:
            print(f"Duration: {_fmt_hms(time.time() - start_ts)}")

    def do_health(self, arg):
        '''Display SMART health for a mapped disk: health <name/id>

        Runs smartctl against the underlying DISK device for the mapping.
        - If the mapping points to a partition, diskmgr automatically targets the parent disk.
        - If the disk transport is USB and the device is /dev/sdX, diskmgr uses:
              smartctl -d sat -x /dev/sdX
          (common for USB-SATA bridges).
        '''
        args = arg.split()
        if len(args) != 1:
            log("Usage: health <name/id>", 'ERROR')
            return

        name = args[0]
        src = self.resolve_target(name, allow_id=True)
        if not src:
            log(f"Unknown target: '{name}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        smartctl_bin = _find_tool_or_common_paths('smartctl', [
            '/usr/sbin/smartctl',
            '/sbin/smartctl',
            '/usr/local/sbin/smartctl',
        ])
        if smartctl_bin is None:
            log("smartctl not found. Install 'smartmontools' and retry.", 'ERROR')
            return

        mapped_dev = os.path.realpath(src)

        # Always query SMART on the underlying whole-disk device (SMART is not partition-scoped).
        disk_dev = mapped_dev
        try:
            mapped_name = _sysfs_block_name(mapped_dev)
            disk_name = _sysfs_to_parent_disk_name(mapped_name)
            candidate = os.path.realpath(f"/dev/{disk_name}")
            if os.path.exists(candidate):
                disk_dev = candidate
        except Exception:
            # Fall back to the mapped device (best-effort) if sysfs probing fails.
            disk_dev = mapped_dev

        tran = ""
        try:
            res_tran = run_command(['lsblk', '-no', 'TRAN', disk_dev], check=False)
            tran = (getattr(res_tran, 'stdout', '') or '').strip().lower()
        except Exception:
            tran = ""

        use_sat = (tran == 'usb' and os.path.basename(disk_dev).startswith('sd'))
        cmd = [smartctl_bin, '-x', disk_dev]
        if use_sat:
            cmd = [smartctl_bin, '-d', 'sat', '-x', disk_dev]

        run_command(['sudo', '-v'])

        res = run_command(cmd, sudo=True, capture_output=True, check=False)
        out = (res.stdout or "")
        err = (res.stderr or "")

        # If SAT probing fails on a USB bridge, retry without -d sat as a best-effort fallback.
        if use_sat and res.returncode != 0 and ("Unknown USB bridge" in (out + err) or "Please specify device type" in (out + err)):
            log("smartctl -d sat failed on this USB bridge; retrying without '-d sat'...", 'WARN')
            cmd = [smartctl_bin, '-x', disk_dev]
            res = run_command(cmd, sudo=True, capture_output=True, check=False)
            out = (res.stdout or "")
            err = (res.stderr or "")

        def _find_first(patterns):
            for p in patterns:
                m = re.search(p, out, re.MULTILINE)
                if m:
                    return m.group(1).strip()
            return None

        overall = _find_first([
            r"^SMART overall-health self-assessment test result:\s*(.+)$",
            r"^SMART Health Status:\s*(.+)$",
        ])
        temp = _find_first([
            r"^Current Temperature:\s*([0-9]+)\s*C",
            r"^Current Drive Temperature:\s*([0-9]+)\s*C",
            r"^Temperature:\s*([0-9]+)\s*C",
            r"^\s*194\s+Temperature_Celsius\s+.*\s([0-9]+)\s*$",
            r"^\s*190\s+Airflow_Temperature_Cel\s+.*\s([0-9]+)\s*$",
        ])
        poh = _find_first([
            r"^Power On Hours:\s*([0-9,]+)",
            r"^\s*9\s+Power_On_Hours\s+.*\s([0-9]+)\s*$",
        ])
        realloc = _find_first([r"^\s*5\s+Reallocated_Sector_Ct\s+.*\s([0-9]+)\s*$"])
        pending = _find_first([r"^\s*197\s+Current_Pending_Sector\s+.*\s([0-9]+)\s*$"])
        offline_unc = _find_first([r"^\s*198\s+Offline_Uncorrectable\s+.*\s([0-9]+)\s*$"])

        # Prefer SCT lifetime min/max (from -x) over attribute 194 Min/Max.
        temp_life_min = None
        temp_life_max = None
        temp_life_src = None
        m_sct = re.search(r"(?im)^\s*Lifetime\s+Min/Max\s+Temperature:\s*([0-9]+)\s*/\s*([0-9]+)\s*Celsius\s*$", out)
        if m_sct:
            temp_life_min = m_sct.group(1)
            temp_life_max = m_sct.group(2)
            temp_life_src = "SCT"
        else:
            m_194 = re.search(r"(?im)^\s*194\s+Temperature_Celsius\s+.*\(\s*Min/Max\s*([0-9]+)\s*/\s*([0-9]+)\s*\)\s*$", out)
            if m_194:
                temp_life_min = m_194.group(1)
                temp_life_max = m_194.group(2)
                temp_life_src = "attr194"

        mode = "-d sat -x" if ('-d' in cmd) else "-x"
        extra = f"{tran}" if tran else "unknown transport"
        print(f"\n{Colors.HEADER}{Colors.BOLD}=== SMART health: {name} ({extra}, smartctl {mode}) ==={Colors.ENDC}")
        print(f"{Colors.BOLD}Mapped device:{Colors.ENDC} {mapped_dev}")
        if mapped_dev != disk_dev:
            print(f"{Colors.BOLD}SMART queried on:{Colors.ENDC} {disk_dev} (SMART is disk-level, not partition-level)")
        else:
            print(f"{Colors.BOLD}SMART queried on:{Colors.ENDC} {disk_dev}")

        # NVMe drives don't expose ATA SMART attributes/logs in the same format. For NVMe, just show smartctl output.
        is_nvme = (
            os.path.basename(disk_dev).startswith('nvme')
            or ('SMART/Health Information (NVMe Log' in out)
            or ('NVMe Version' in out)
        )
        if is_nvme:
            def _nv_field(label_patterns):
                for p in label_patterns:
                    m = re.search(p, out, re.MULTILINE)
                    if m:
                        return m.group(1).strip()
                return None

            def _nv_int(v, base=10):
                if v is None:
                    return None
                s = str(v).strip()
                try:
                    if base == 16:
                        return int(s, 16)
                    return int(s.replace(',', ''), 10)
                except Exception:
                    return _first_int_from_text(s)

            def _ok_watch_bad(val, ok_when=None, watch_when=None, bad_when=None, default_color=Colors.OKGREEN):
                if val is None:
                    return "-"
                text = str(val)
                ival = _nv_int(val)
                if ival is None:
                    return text
                if bad_when is not None and bad_when(ival):
                    return f"{Colors.FAIL}{text}{Colors.ENDC}"
                if watch_when is not None and watch_when(ival):
                    return f"{Colors.WARNING}{text}{Colors.ENDC}"
                if ok_when is not None:
                    if ok_when(ival):
                        return f"{Colors.OKGREEN}{text}{Colors.ENDC}"
                    return f"{Colors.WARNING}{text}{Colors.ENDC}"
                return f"{default_color}{text}{Colors.ENDC}"

            nv_critical_warning_raw = _nv_field([r"^Critical Warning:\s*(0x[0-9a-fA-F]+|[0-9]+)\s*$"])
            nv_media_err_raw = _nv_field([r"^Media and Data Integrity Errors:\s*([0-9,]+)\s*$"])
            nv_avail_spare_raw = _nv_field([r"^Available Spare:\s*([0-9]+)%\s*$", r"^Available Spare:\s*([0-9,]+)\s*$"])
            nv_pct_used_raw = _nv_field([r"^Percentage Used:\s*([0-9]+)%\s*$", r"^Percentage Used:\s*([0-9,]+)\s*$"])
            nv_errlog_raw = _nv_field([r"^Error Information Log Entries:\s*([0-9,]+)\s*$"])
            nv_unsafe_raw = _nv_field([r"^Unsafe Shutdowns:\s*([0-9,]+)\s*$"])
            nv_temp_crit_time_raw = _nv_field([r"^Critical Comp\.\s+Temperature Time:\s*([0-9,]+)\s*$"])
            nv_temp_warn_time_raw = _nv_field([r"^Warning\s+Comp\.\s+Temperature Time:\s*([0-9,]+)\s*$"])
            nv_temp_raw = _nv_field([r"^Temperature:\s*([0-9]+)\s+Celsius\s*$", r"^Temperature:\s*([0-9]+)\s*C\s*$"])
            nv_duw_raw = _nv_field([r"^Data Units Written:\s*(.+)$"])
            nv_poh_raw = _nv_field([r"^Power On Hours:\s*([0-9,]+)\s*$"])
            nv_pcycles_raw = _nv_field([r"^Power Cycles:\s*([0-9,]+)\s*$"])
            nv_dur_raw = _nv_field([r"^Data Units Read:\s*(.+)$"])
            nv_busy_raw = _nv_field([r"^Controller Busy Time:\s*([0-9,]+)\s*$"])

            nv_unsafe_int = _nv_int(nv_unsafe_raw)
            nv_pcycles_int = _nv_int(nv_pcycles_raw)

            unsafe_ratio = None
            if nv_unsafe_int is not None and nv_pcycles_int not in (None, 0):
                unsafe_ratio = float(nv_unsafe_int) / float(nv_pcycles_int)

            print(f"\n{Colors.BOLD}NVMe attributes ranked by severity (Tier 1 -> Tier 4):{Colors.ENDC}")
            print(f"\n{Colors.BOLD}Tier 1: Replace Immediately Zone{Colors.ENDC}")
            cw_text = nv_critical_warning_raw if nv_critical_warning_raw is not None else "-"
            print(f"  Critical Warning: {_ok_watch_bad(cw_text, ok_when=lambda v: v == 0, bad_when=lambda v: v != 0)} - Master alarm; non-zero indicates controller-level fault/overheat/read-only condition.")
            me_text = nv_media_err_raw if nv_media_err_raw is not None else "-"
            print(f"  Media and Data Integrity Errors: {_ok_watch_bad(me_text, ok_when=lambda v: v == 0, bad_when=lambda v: v > 0)} - Counts real data-integrity failures.")
            as_text = f"{nv_avail_spare_raw}%" if nv_avail_spare_raw is not None else "-"
            print(f"  Available Spare: {_ok_watch_bad(as_text, ok_when=lambda v: v >= 10, watch_when=lambda v: 10 <= v < 20, bad_when=lambda v: v < 10)} - Spare block reserve; low values are critical.")

            print(f"\n{Colors.BOLD}Tier 2: Wear and Tear Zone{Colors.ENDC}")
            pu_text = f"{nv_pct_used_raw}%" if nv_pct_used_raw is not None else "-"
            print(f"  Percentage Used: {_ok_watch_bad(pu_text, watch_when=lambda v: 70 <= v < 100, bad_when=lambda v: v >= 100)} - Wear-life consumed.")
            el_text = nv_errlog_raw if nv_errlog_raw is not None else "-"
            print(f"  Error Information Log Entries: {_ok_watch_bad(el_text, ok_when=lambda v: v == 0, watch_when=lambda v: 0 < v < 100, bad_when=lambda v: v >= 100)} - Internal error history (controller stability signal).")
            us_text = nv_unsafe_raw if nv_unsafe_raw is not None else "-"
            if unsafe_ratio is not None:
                us_text = f"{us_text} ({unsafe_ratio*100:.1f}% of power cycles)"
            us_col = Colors.OKGREEN
            if nv_unsafe_int is not None and nv_unsafe_int > 0:
                us_col = Colors.WARNING
            if unsafe_ratio is not None and unsafe_ratio >= 0.5:
                us_col = Colors.FAIL
            print(f"  Unsafe Shutdowns: {us_col}{us_text}{Colors.ENDC} - High counts increase corruption risk.")

            print(f"\n{Colors.BOLD}Tier 3: Abuse History Zone{Colors.ENDC}")
            ctt_text = nv_temp_crit_time_raw if nv_temp_crit_time_raw is not None else "-"
            print(f"  Critical Composite Temperature Time: {_ok_watch_bad(ctt_text, ok_when=lambda v: v == 0, bad_when=lambda v: v > 0)} - Time spent at critical thermal level.")
            wtt_text = nv_temp_warn_time_raw if nv_temp_warn_time_raw is not None else "-"
            print(f"  Warning Composite Temperature Time: {_ok_watch_bad(wtt_text, ok_when=lambda v: v == 0, watch_when=lambda v: v > 0)} - Time spent in warning thermal range.")
            t_text = f"{nv_temp_raw} C" if nv_temp_raw is not None else "-"
            print(f"  Temperature: {_ok_watch_bad(t_text, ok_when=lambda v: v < 70, watch_when=lambda v: 70 <= v < 80, bad_when=lambda v: v >= 80)} - Current temperature status.")

            print(f"\n{Colors.BOLD}Tier 4: Biography Zone (Informational){Colors.ENDC}")
            print(f"  Data Units Written: {Colors.OKCYAN}{nv_duw_raw or '-'}{Colors.ENDC} - Total data written (wear context).")
            print(f"  Power On Hours: {Colors.OKCYAN}{nv_poh_raw or '-'}{Colors.ENDC} - Device age in hours.")
            print(f"  Power Cycles: {Colors.OKCYAN}{nv_pcycles_raw or '-'}{Colors.ENDC} - Number of power cycles.")
            print(f"  Data Units Read: {Colors.OKCYAN}{nv_dur_raw or '-'}{Colors.ENDC} - Total data read (informational).")
            print(f"  Controller Busy Time: {Colors.OKCYAN}{nv_busy_raw or '-'}{Colors.ENDC} - Controller active time (informational).")

            print("")
            if out.strip():
                print(out.rstrip())
            if err.strip():
                print(err.rstrip(), file=sys.stderr)

            # Also show nvme-cli smart-log output (often includes vendor-specific counters smartctl doesn't).
            nvme_bin = _find_tool_or_common_paths('nvme', [
                '/usr/sbin/nvme',
                '/sbin/nvme',
                '/usr/local/sbin/nvme',
                '/usr/bin/nvme',
                '/bin/nvme',
            ])
            if nvme_bin is None:
                log("nvme tool not found. Install 'nvme-cli' to show 'nvme smart-log'.", 'WARN')
            else:
                # Prefer the controller device (/dev/nvmeX) when available; fall back to the namespace node.
                nvme_target = disk_dev
                m = re.match(r"^(/dev/nvme[0-9]+)n[0-9]+$", disk_dev)
                if m:
                    ctrl = m.group(1)
                    if os.path.exists(ctrl):
                        nvme_target = ctrl

                print(f"\n{Colors.HEADER}{Colors.BOLD}--- nvme smart-log {nvme_target} ---{Colors.ENDC}")
                res_nv = run_command([nvme_bin, 'smart-log', nvme_target], sudo=True, capture_output=True, check=False)
                nv_out = (res_nv.stdout or "").rstrip()
                nv_err = (res_nv.stderr or "").rstrip()
                if nv_out:
                    print(nv_out)
                if nv_err:
                    print(nv_err, file=sys.stderr)
                if getattr(res_nv, 'returncode', 0) != 0:
                    log(f"nvme smart-log exit status: {res_nv.returncode}", 'WARN')

            if getattr(res, 'returncode', 0) != 0:
                log(f"smartctl exit status: {res.returncode} (non-zero may indicate SMART warnings).", 'WARN')
            return

        def _print_smartctl_info_block():
            """
            Print the smartctl prolog + information section, but not the full attribute tables/logs.
            """
            if not out:
                return
            lines = str(out).splitlines()
            if not lines:
                return
            info_idx = None
            read_idx = None
            for i, line in enumerate(lines):
                if line.strip() == "=== START OF INFORMATION SECTION ===":
                    info_idx = i
                if line.strip() == "=== START OF READ SMART DATA SECTION ===":
                    read_idx = i
                    break
            if info_idx is None:
                return
            end = read_idx if read_idx is not None else len(lines)
            # Print from the beginning through the end of the information section header block.
            for line in lines[:end]:
                print(line)

        def _print_smartctl_remaining_block():
            """
            Print the remainder of the smartctl output (everything after the information section),
            so the user can still see the attribute tables and logs without duplicating the header/info.
            """
            if not out:
                return
            lines = str(out).splitlines()
            if not lines:
                return
            read_idx = None
            for i, line in enumerate(lines):
                if line.strip() == "=== START OF READ SMART DATA SECTION ===":
                    read_idx = i
                    break
            if read_idx is None:
                # Fall back to the entire output if we can't locate the split point.
                print(out.rstrip())
                return
            tail = lines[read_idx:]
            if not tail:
                return
            print(f"{Colors.HEADER}{Colors.BOLD}--- smartctl details ---{Colors.ENDC}")
            for line in tail:
                print(line)

        _print_smartctl_info_block()

        # Time since last SMART error (if the drive has an ATA SMART Error Log).
        poh_row = _parse_smart_attr_row(out, 9)
        cur_poh_h = _first_int_from_text((poh_row or {}).get("raw")) or _first_int_from_text(poh)
        last_err_no, last_err_poh_h = _parse_smart_last_error_poh(out)
        errlog_cnt = _parse_smart_error_log_count(out)
        if last_err_poh_h is not None:
            delta_h = cur_poh_h - last_err_poh_h if (cur_poh_h is not None) else None
            if delta_h is not None and delta_h >= 0:
                delta_days = delta_h / 24.0
                # Color: green if very old, yellow if recent.
                if delta_h < 72:
                    delta_disp = f"{Colors.WARNING}{delta_h}h{Colors.ENDC} (~{delta_days:.1f} days)"
                else:
                    delta_disp = f"{Colors.OKGREEN}{delta_h}h{Colors.ENDC} (~{delta_days:.1f} days)"
                eno = f"Error {last_err_no}" if last_err_no is not None else "Last error"
                print(f"\n{Colors.BOLD}Time since last SMART error:{Colors.ENDC} {delta_disp} ({eno} at POH {last_err_poh_h}h)\n")
            else:
                eno = f"Error {last_err_no}" if last_err_no is not None else "Last error"
                print(f"\n{Colors.BOLD}Last SMART error logged at:{Colors.ENDC} {eno} at POH {last_err_poh_h}h\n")
        elif errlog_cnt == 0:
            print(f"\n{Colors.BOLD}SMART Error Log:{Colors.ENDC} {Colors.OKGREEN}No Errors Logged{Colors.ENDC}\n")

        # Key HDD indicators (earliest -> most severe), with current values if present.
        crc199 = _parse_smart_attr_raw(out, 199)
        cmd188 = _parse_smart_attr_raw(out, 188)
        errlog = errlog_cnt
        pend197 = _parse_smart_attr_raw(out, 197)
        off198 = _parse_smart_attr_raw(out, 198)
        rep187 = _parse_smart_attr_raw(out, 187)
        realloc5 = _parse_smart_attr_raw(out, 5)
        relocev196 = _parse_smart_attr_raw(out, 196)
        long_fail = _parse_smart_long_selftest_failures(out)

        def _to_int(x):
            if x is None:
                return None
            if isinstance(x, int):
                return x
            s = str(x).strip().replace(",", "")
            if s.isdigit() or (s.startswith('-') and s[1:].isdigit()):
                try:
                    return int(s, 10)
                except ValueError:
                    return None
            return None

        def _v(x):
            return x if x is not None else "-"

        def _color_val(kind, val):
            """
            Colorize values: OK=green, WATCH=yellow, BAD=red.
            """
            ival = _to_int(val)
            raw = str(_v(val))

            # Unknown/unavailable
            if val is None:
                return raw

            # Severity rules (conservative; trend is unknown).
            if kind in ("pending", "unc", "reported", "selftest"):
                if ival is not None and ival > 0:
                    return f"{Colors.FAIL}{raw}{Colors.ENDC}"
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}"
            if kind in ("crc", "timeout", "errlog", "realloc"):
                if ival is not None and ival > 0:
                    return f"{Colors.WARNING}{raw}{Colors.ENDC}"
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}"
            if kind == "temp":
                if ival is None:
                    return raw
                if ival >= 60:
                    return f"{Colors.FAIL}{raw}{Colors.ENDC}"
                if ival >= 50:
                    return f"{Colors.WARNING}{raw}{Colors.ENDC}"
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}"
            return raw

        def _color_overall(s):
            if not s:
                return "-"
            t = str(s).strip()
            if "PASSED" in t.upper() or "OK" == t.upper():
                return f"{Colors.OKGREEN}{t}{Colors.ENDC}"
            return f"{Colors.FAIL}{t}{Colors.ENDC}"

        is_seagate = _smartctl_looks_seagate(out)

        # Fix Seagate SMART 188 formatting: decode packed 48-bit value into real counters.
        cmd188_disp = cmd188
        cmd188_for_color = cmd188
        d188 = None
        if is_seagate:
            d188 = _decode_seagate_command_timeout(cmd188)
            if d188 and d188["raw_int"] > 0xFFFF:
                cmd188_for_color = d188["timeouts"]
                cmd188_disp = f'{d188["timeouts"]} (packed: >5s={d188["gt_5s"]}, >7.5s={d188["gt_7_5s"]}; raw={d188["raw_int"]} {d188["hex"]})'

        # SMART pretext block (fixed ranking 1=most critical -> 24=least critical).
        rows = {
            1: _parse_smart_attr_row(out, 1),
            3: _parse_smart_attr_row(out, 3),
            4: _parse_smart_attr_row(out, 4),
            5: _parse_smart_attr_row(out, 5),
            7: _parse_smart_attr_row(out, 7),
            9: _parse_smart_attr_row(out, 9),
            10: _parse_smart_attr_row(out, 10),
            12: _parse_smart_attr_row(out, 12),
            184: _parse_smart_attr_row(out, 184),
            187: _parse_smart_attr_row(out, 187),
            188: _parse_smart_attr_row(out, 188),
            189: _parse_smart_attr_row(out, 189),
            190: _parse_smart_attr_row(out, 190),
            191: _parse_smart_attr_row(out, 191),
            192: _parse_smart_attr_row(out, 192),
            193: _parse_smart_attr_row(out, 193),
            197: _parse_smart_attr_row(out, 197),
            198: _parse_smart_attr_row(out, 198),
            199: _parse_smart_attr_row(out, 199),
            240: _parse_smart_attr_row(out, 240),
            241: _parse_smart_attr_row(out, 241),
            242: _parse_smart_attr_row(out, 242),
            254: _parse_smart_attr_row(out, 254),
            194: _parse_smart_attr_row(out, 194),
        }

        # Seagate packed SMART 188 decode already applied to cmd188_disp/cmd188_for_color above.
        cmd188_timeouts = _first_int_from_text(cmd188_for_color)

        def _tb_from_lbas(lbas):
            try:
                n = int(lbas)
            except Exception:
                return None
            # 512-byte LBAs
            return (n * 512) / (1024 ** 4)

        def _rank_color(rank):
            if rank <= 5:
                return Colors.FAIL
            if rank <= 15:
                return Colors.WARNING
            if rank <= 21:
                return Colors.OKCYAN
            return Colors.OKGREEN

        def _norm_suffix(row, include_worst=False):
            """Append normalized VALUE/THRESH (and WORST when requested)."""
            if not row:
                return ""
            value = row.get('value', '-')
            worst = row.get('worst', '-')
            thresh = row.get('thresh', '-')
            t_i = _first_int_from_text(thresh)
            if include_worst:
                if t_i is not None and t_i > 0:
                    return f" (VALUE {value}, WORST {worst}, THRESH {thresh})"
                return f" (VALUE {value}, WORST {worst})"
            if t_i is not None and t_i > 0:
                return f" (VALUE {value}, THRESH {thresh})"
            return f" (VALUE {value})"

        def _fmt_smart_value(aid):
            # Single-line value formatting (no multi-line blocks).
            if aid == 188 and is_seagate and d188 and d188.get("raw_int") is not None and d188["raw_int"] > 0xFFFF:
                v = f"{d188['timeouts']} (decoded: >5s={d188['gt_5s']}, >7.5s={d188['gt_7_5s']}; raw={d188['hex']})"
                return _color_val('timeout', d188['timeouts']) + v[len(str(d188['timeouts'])):]

            row = rows.get(aid)
            if not row:
                return "-"

            raw = row.get("raw", "-")
            if aid in (1, 7) and is_seagate:
                # Common Seagate packing: hi16=error_count, lo32=op_count.
                d = _decode_seagate_hi16_lo32(raw)
                if d:
                    err_col = f"{Colors.OKGREEN}{d['errors']}{Colors.ENDC}" if d["errors"] == 0 else f"{Colors.FAIL}{d['errors']}{Colors.ENDC}"
                    if aid == 1:
                        return f"read_ops={d['ops']:,}, read_errors={err_col} (raw={d['hex']}; VALUE {row.get('value', '-')}, THRESH {row.get('thresh', '-')})"
                    return f"seek_ops={d['ops']:,}, seek_errors={err_col} (raw={d['hex']}; VALUE {row.get('value', '-')}, THRESH {row.get('thresh', '-')})"

            if aid in (5, 1, 7, 10):
                kind = 'realloc' if aid == 5 else ('reported' if aid == 10 else 'errlog')
                if aid == 10:
                    kind = 'reported'
                v = f"{raw} (VALUE {row.get('value', '-')}, THRESH {row.get('thresh', '-')})"
                # Colorize the RAW count where non-zero is meaningful.
                raw_i = _first_int_from_text(raw)
                if aid == 5:
                    return (_color_val('realloc', raw_i if raw_i is not None else raw)) + v[len(str(raw_i if raw_i is not None else raw)):]
                if aid == 10:
                    return (_color_val('reported', raw_i if raw_i is not None else raw)) + v[len(str(raw_i if raw_i is not None else raw)):]
                # 1/7 fall through above for Seagate; otherwise keep as-is (vendor-specific).
                return v
            if aid == 187:
                raw_i = _first_int_from_text(raw)
                v = f"{raw}{_norm_suffix(row)}"
                return (_color_val('reported', raw_i if raw_i is not None else raw)) + v[len(str(raw_i if raw_i is not None else raw)):]
            if aid == 188:
                raw_i = cmd188_timeouts or _first_int_from_text(raw)
                v = f"{raw}{_norm_suffix(row, include_worst=True)}"
                return (_color_val('timeout', raw_i if raw_i is not None else raw)) + v[len(str(raw_i if raw_i is not None else raw)):]
            if aid == 3:
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}{_norm_suffix(row)}"
            if aid == 193:
                rv = _first_int_from_text(raw)
                if rv is not None:
                    col = Colors.WARNING if rv > 300000 else Colors.OKGREEN
                    return f"{col}{rv:,}{Colors.ENDC}{_norm_suffix(row)}"
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}{_norm_suffix(row)}"
            if aid in (241, 242):
                rv = _first_int_from_text(raw)
                tb = _tb_from_lbas(rv) if rv is not None else None
                if tb is not None:
                    return f"{Colors.OKGREEN}{raw}{Colors.ENDC} (~{tb:.2f} TiB){_norm_suffix(row)}"
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}{_norm_suffix(row)}"
            if aid in (197, 198, 184):
                raw_i = _first_int_from_text(raw)
                v = str(raw)
                kind = 'pending' if aid == 197 else 'unc'
                if aid == 184:
                    kind = 'reported'
                return _color_val(kind, raw_i if raw_i is not None else raw) + _norm_suffix(row)
            if aid in (199, 191, 254, 189, 192, 4, 12, 9, 240):
                raw_i = _first_int_from_text(raw)
                if aid in (199, 191, 254, 189, 192):
                    kind = 'crc' if aid == 199 else 'timeout'
                    # treat these as medium signals when non-zero
                    return _color_val('timeout', raw_i if raw_i is not None else raw) + _norm_suffix(row)
                return f"{Colors.OKGREEN}{raw}{Colors.ENDC}{_norm_suffix(row)}"
            if aid in (190, 194):
                raw_i = _first_int_from_text(raw)
                if raw_i is None:
                    return f"{Colors.OKGREEN}{raw}{Colors.ENDC}{_norm_suffix(row)}"
                s = str(raw)
                head = str(raw_i)
                # Preserve the full raw field (including Min/Max etc) but color the leading temperature.
                if s.startswith(head):
                    return _color_val('temp', raw_i) + s[len(head):] + _norm_suffix(row)
                return _color_val('temp', raw_i) + _norm_suffix(row)
            return f"{Colors.OKGREEN}{raw}{Colors.ENDC}{_norm_suffix(row)}"

        rr_meaning = (
            "Seagate RAW is often packed; treat normalized VALUE trend as primary. diskmgr shows decoded ops+errors when possible."
            if is_seagate else
            "Vendor-specific RAW encoding is common; prioritize normalized VALUE/WORST/THRESH trend."
        )
        seek_meaning = (
            "Seagate RAW is often packed; treat normalized VALUE trend as primary. diskmgr shows decoded ops+errors when possible."
            if is_seagate else
            "Vendor-specific RAW encoding is common; prioritize normalized VALUE/WORST/THRESH trend."
        )

        ranked = [
            (1, 187, "Reported_Uncorrect", "Uncorrectable errors reached the OS/host; corruption has already happened."),
            (2, 198, "Offline_Uncorrectable", "Unrecoverable sectors found during offline scan/self-test; physical defects confirmed."),
            (3, 5, "Reallocated_Sector_Ct", "Bad sectors remapped to spares; increasing suggests real media degradation."),
            (4, 197, "Current_Pending_Sector", "Unstable sectors awaiting re-read/rewrite; data at risk until resolved."),
            (5, 184, "End-to-End_Error", "Internal data-path corruption (cache/buffer <-> media); logic/RAM path issues."),
            (6, 10, "Spin_Retry_Count", "Spin-up retries; motor/bearing/power trouble can trap data permanently."),
            (7, 1, "Raw_Read_Error_Rate", rr_meaning),
            (8, 7, "Seek_Error_Rate", seek_meaning),
            (9, 3, "Spin_Up_Time", "Drive taking longer to become ready; can indicate wear (trend matters)."),
            (10, 188, "Command_Timeout", "Drive commands timing out/hanging; often link/power/bridge issues (trend matters)."),
            (11, 199, "UDMA_CRC_Error_Count", "Interface CRC errors; usually cable/port/bridge noise, not platter damage."),
            (12, 191, "G-Sense_Error_Rate", "Shock/vibration events while running; can cause (not just reflect) damage."),
            (13, 254, "Free_Fall_Sensor", "Recorded free-fall/drop events (history of dangerous handling)."),
            (14, 193, "Load_Cycle_Count", "Head parking cycles; very high counts increase mechanical wear risk."),
            (15, 189, "High_Fly_Writes", "Head flying height anomalies during writes; risk weak writes/data fade."),
            (16, 194, "Temperature_Celsius", "Internal temperature; only critical when extreme (e.g. >60C)."),
            (17, 190, "Airflow_Temperature_Cel", "Alternate temperature sensor; only critical when extreme."),
            (18, 9, "Power_On_Hours", "Lifetime hours; context only (older drives have higher baseline risk)."),
            (19, 4, "Start_Stop_Count", "Spindle start/stop cycles; wear context."),
            (20, 12, "Power_Cycle_Count", "Power cycles; wear/environment context."),
            (21, 192, "Power-Off_Retract_Count", "Emergency retracts (power loss/unplug); environment context."),
            (22, 241, "Total_LBAs_Written", "Cumulative writes; statistics/context."),
            (23, 242, "Total_LBAs_Read", "Cumulative reads; statistics/context."),
            (24, 240, "Head_Flying_Hours", "Head flying time; informational."),
        ]

        zone_headers = {
            1: "The \"Data is Already Gone\" Zone",
            6: "The \"Mechanical Failure Imminent\" Zone",
            11: "The \"Environmental & Usage Stress\" Zone",
            16: "The \"Old Age & Thermometer\" Zone",
            22: "The \"Pure Statistics\" Zone (Least Critical)",
        }

        print(f"\n{Colors.BOLD}SMART attributes ranked strictly from 1 (most critical) to 24 (least critical):{Colors.ENDC}")
        print("Each attribute is printed on one line (ID + name + current value + meaning).")
        for rank, aid, nm, meaning in ranked:
            if rank in zone_headers:
                print(f"\n{Colors.BOLD}{zone_headers[rank]}:{Colors.ENDC}")
            c = _rank_color(rank)
            v = _fmt_smart_value(aid)
            print(f"{c}{rank:2d}.{Colors.ENDC} {Colors.BOLD}{aid}{Colors.ENDC} {nm}: {v} - {meaning}")

        if overall or temp or poh or realloc or pending or offline_unc:
            if overall:
                print(f"\n{Colors.BOLD}Overall:{Colors.ENDC} {_color_overall(overall)}")
            if temp:
                print(f"{Colors.BOLD}Temp:{Colors.ENDC} {_color_val('temp', temp)} C")
            if temp_life_min is not None and temp_life_max is not None:
                print(f"{Colors.BOLD}Lifetime temp min/max:{Colors.ENDC} {temp_life_min}/{temp_life_max} C ({temp_life_src})")
            if poh:
                print(f"{Colors.BOLD}Power-on hours:{Colors.ENDC} {poh}")
            if realloc:
                print(f"{Colors.BOLD}Reallocated sectors:{Colors.ENDC} {_color_val('realloc', realloc)}")
            if pending:
                print(f"{Colors.BOLD}Pending sectors:{Colors.ENDC} {_color_val('pending', pending)}")
            if offline_unc:
                print(f"{Colors.BOLD}Offline uncorrectable:{Colors.ENDC} {_color_val('unc', offline_unc)}")
            print("")

        _print_smartctl_remaining_block()
        if err.strip():
            print(err.rstrip(), file=sys.stderr)

        # smartctl uses a bitmask exit code; non-zero can mean "drive has issues" and is still useful output.
        if getattr(res, 'returncode', 0) != 0:
            log(f"smartctl exit status: {res.returncode} (non-zero may indicate SMART warnings).", 'WARN')

    def do_smart(self, arg):
        '''Alias for health: smart <name/id>'''
        return self.do_health(arg)

    def do_selftest(self, arg):
        '''Start a SMART long self-test: selftest <name/id>

        Runs smartctl long test against the underlying DISK device for the mapping.
        - If the mapping points to a partition, diskmgr targets the parent disk.
        - If the disk transport is USB and the device is /dev/sdX, diskmgr uses:
              smartctl -d sat -t long /dev/sdX
          (common for USB-SATA bridges).
        '''
        parser = CmdArgumentParser(prog='selftest', add_help=False)
        parser.add_argument('name')
        parser.add_argument('--watch', action='store_true', help='Poll SMART self-test progress until complete')
        parser.add_argument('--interval', type=int, default=60, help='Polling interval seconds for --watch (default: 60)')
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.name
        watch = bool(getattr(args, 'watch', False))
        interval = int(getattr(args, 'interval', 60) or 60)
        if interval < 5:
            interval = 5
        src = self.resolve_target(name, allow_id=True)
        if not src:
            log(f"Unknown target: '{name}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        smartctl_bin = _find_tool_or_common_paths('smartctl', [
            '/usr/sbin/smartctl',
            '/sbin/smartctl',
            '/usr/local/sbin/smartctl',
        ])
        if smartctl_bin is None:
            log("smartctl not found. Install 'smartmontools' and retry.", 'ERROR')
            return

        mapped_dev = os.path.realpath(src)

        # Always run SMART commands on the underlying whole-disk device (SMART is not partition-scoped).
        disk_dev = mapped_dev
        try:
            mapped_name = _sysfs_block_name(mapped_dev)
            disk_name = _sysfs_to_parent_disk_name(mapped_name)
            candidate = os.path.realpath(f"/dev/{disk_name}")
            if os.path.exists(candidate):
                disk_dev = candidate
        except Exception:
            disk_dev = mapped_dev

        tran = ""
        try:
            res_tran = run_command(['lsblk', '-no', 'TRAN', disk_dev], check=False)
            tran = (getattr(res_tran, 'stdout', '') or '').strip().lower()
        except Exception:
            tran = ""

        use_sat = (tran == 'usb' and os.path.basename(disk_dev).startswith('sd'))
        cmd = [smartctl_bin, '-t', 'long', disk_dev]
        if use_sat:
            cmd = [smartctl_bin, '-d', 'sat', '-t', 'long', disk_dev]

        mode = "-d sat" if ('-d' in cmd) else ""
        print(f"Starting SMART long self-test: {Colors.BOLD}{name}{Colors.ENDC} -> {disk_dev} {mode}".strip())

        # Confirmation (high-impact; not directly destructive but stresses the drive).
        if not self.extensive_confirm(f"selftest {name} ({disk_dev})", destructive=False):
            return

        run_command(['sudo', '-v'])

        log_path = _cmd_log_open("selftest") if (_CMD_LOG_FH is None) else _CMD_LOG_PATH
        if log_path:
            print(f"Log: {log_path}")
        start_ts = time.time()
        try:
            res = run_command(cmd, sudo=True, capture_output=True, check=False)
            out = (res.stdout or "").rstrip()
            err = (res.stderr or "").rstrip()

            if out:
                print(out)
            if err:
                print(err, file=sys.stderr)

            if getattr(res, 'returncode', 0) != 0:
                log(f"smartctl exit status: {res.returncode} (non-zero may indicate it could not start the test).", 'WARN')
                return

            if not watch:
                print(f"\nTo check progress/results: run {Colors.BOLD}health {name}{Colors.ENDC} and look at the SMART Self-test log.")
                return

            def _parse_remaining_pct(text):
                # ATA: "Self-test execution status: ... 90% of test remaining."
                m = re.search(r"(?im)\\b([0-9]{1,3})%\\s+of\\s+test\\s+remaining\\b", text)
                if m:
                    try:
                        return int(m.group(1), 10)
                    except ValueError:
                        return None
                return None

            print(f"\nWatching SMART self-test progress (interval={interval}s). Ctrl+C to stop watching.")
            last_line = None
            parse_fail = 0
            while True:
                res_p = run_command([smartctl_bin, '-a', disk_dev] if not use_sat else [smartctl_bin, '-d', 'sat', '-a', disk_dev],
                                    sudo=True, capture_output=True, check=False)
                txt = ((res_p.stdout or "") + "\n" + (res_p.stderr or "")).strip()
                rem = _parse_remaining_pct(txt)
                in_progress = False
                if rem is not None:
                    in_progress = True
                    done = max(0, min(100, 100 - rem))
                    line = f"SMART self-test: {done}% complete ({rem}% remaining)"
                else:
                    # If we can't parse remaining%, fall back to detecting the "in progress" phrase.
                    if re.search(r"(?im)self-test\\s+routine\\s+in\\s+progress", txt):
                        in_progress = True
                        line = "SMART self-test: in progress (unable to parse % remaining)"
                    else:
                        in_progress = False
                        line = "SMART self-test: not in progress (completed or not running)"

                if line != last_line:
                    print(line)
                    _cmd_log_write(line)
                    last_line = line

                if not in_progress:
                    break

                if rem is None:
                    parse_fail += 1
                    if parse_fail >= 3:
                        print("SMART self-test is in progress but % remaining could not be parsed; use `health` to inspect the self-test log.")
                        break
                else:
                    parse_fail = 0

                time.sleep(interval)
        finally:
            print(f"Duration: {_fmt_hms(time.time() - start_ts)}")
            _cmd_log_close()

    def get_mountpoint(self, name):
        '''Resolves the current mountpoint for a friendly name.'''
        self.mappings = read_luks_map()
        if name not in self.mappings:
            return None
        
        src = self.mappings[name]
        devnode = os.path.realpath(src)
        
        # Check if it's LUKS and open
        mapper_path = f"/dev/mapper/{name}"
        target = mapper_path if os.path.exists(mapper_path) else devnode
        
        targets = find_mount_targets(target)
        if not targets:
            return None

        preferred = f"/media/{os.environ.get('USER', 'root')}/{name}"
        return preferred if preferred in targets else targets[0]

    def do_sync(self, arg):
        '''Synchronize two filesystems: sync <primary> <secondary>
        
        UNDER THE HOOD:
        1.  Validation: Verifies both endpoints resolve to directories.
            - Mapped names must already be mounted.
            - Absolute paths must exist and be directories.
        2.  Pre-scan: Runs rsync dry-run stats to compute planned transfer bytes.
        3.  Confirmation: Requires solving two math problems (DESTRUCTIVE for secondary).
        4.  Execution: Runs rsync and reports real progress as bytes_done / planned_bytes.
        
        Note: The SECONDARY disk will be modified to match the PRIMARY disk.
        All files on the secondary that do not exist on the primary will be DELETED.
        '''
        parser = CmdArgumentParser(prog='sync', add_help=False)
        parser.add_argument('primary')
        parser.add_argument('secondary')
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        primary = args.primary
        secondary = args.secondary

        def _resolve_sync_endpoint(value, role_label):
            if os.path.isabs(value):
                p = os.path.realpath(value)
                if not os.path.exists(p):
                    log(f"{role_label} path does not exist: {value}", 'ERROR')
                    return None, None
                if not os.path.isdir(p):
                    log(f"{role_label} path must be a directory: {value}", 'ERROR')
                    return None, None
                return p, 'path'

            mp = self.get_mountpoint(value)
            if not mp:
                log(f"{role_label} disk '{value}' is not mounted.", 'ERROR')
                return None, None
            return mp, 'mapping'

        pri_mnt, pri_kind = _resolve_sync_endpoint(primary, "Primary")
        sec_mnt, sec_kind = _resolve_sync_endpoint(secondary, "Secondary")
        if not pri_mnt or not sec_mnt:
            return

        # Block syncing TO the system root drive (destination only).
        # Source on root is allowed for backup use-cases like /home -> external disk.
        try:
            if sec_kind == 'mapping':
                res_s = run_command(['findmnt', '-rn', '-M', sec_mnt, '-o', 'SOURCE'], check=False)
            else:
                res_s = run_command(['findmnt', '-rn', '-T', sec_mnt, '-o', 'SOURCE'], check=False)
            sec_src = (getattr(res_s, 'stdout', '') or '').strip()
            if sec_src and self._block_if_root_drive(os.path.realpath(sec_src), f"sync {primary} {secondary}"):
                return
        except Exception:
            pass

        # Ensure trailing slashes so rsync copies directory CONTENTS.
        src_path = pri_mnt.rstrip('/') + '/'
        dst_path = sec_mnt.rstrip('/') + '/'

        print(f"Syncing: {Colors.BOLD}{src_path}{Colors.ENDC} -> {Colors.WARNING}{dst_path}{Colors.ENDC}")
        run_command(['sudo', '-v'])

        # Pre-scan before confirmation to compute planned bytes for stable progress.
        log("Running pre-scan (dry-run) to compute planned transfer...")
        pre_cmd = ['rsync', '-an', '--delete', '--stats', src_path, dst_path]
        pre_res = run_command(pre_cmd, sudo=True, check=False)
        pre_rc = getattr(pre_res, 'returncode', 0)
        pre_out = (getattr(pre_res, 'stdout', '') or '') + "\n" + (getattr(pre_res, 'stderr', '') or '')
        if pre_rc not in (0, 24):
            log(f"Pre-scan failed: rsync exited with status {pre_rc}.", 'ERROR')
            if pre_out.strip():
                print(pre_out.rstrip())
            return

        def _parse_stat_int(label):
            m = re.search(rf"^\s*{re.escape(label)}:\s*([0-9,]+)\b", pre_out, re.MULTILINE)
            if not m:
                return 0
            try:
                return int(m.group(1).replace(',', ''))
            except Exception:
                return 0

        planned_bytes = _parse_stat_int("Total transferred file size")
        planned_files = _parse_stat_int("Number of regular files transferred")
        if planned_files <= 0:
            planned_files = _parse_stat_int("Number of files transferred")
        planned_deletes = _parse_stat_int("Number of deleted files")

        print("Pre-scan summary (dry-run):")
        print(f"  Planned file transfers: {planned_files:,}")
        print(f"  Planned deletions:      {planned_deletes:,}")
        print(f"  Planned transfer bytes: {planned_bytes:,} ({self._format_bytes_binary(str(planned_bytes), decimals=2)})")

        if not self.extensive_confirm(secondary):
            return

        run_command(['sudo', '-v'])
        log(f"Starting rsync: {primary} -> {secondary}...")
        start_ts = time.time()

        try:
            cmd = [
                'sudo', 'rsync', '-aHh', '--delete',
                '--info=stats2,name0',
                '--out-format=%l\t%n',
                src_path, dst_path
            ]
            proc = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )

            done_bytes = 0
            progress_stop = threading.Event()
            progress_lock = threading.Lock()

            def _fmt_speed_bps(bps):
                try:
                    b = max(0, int(float(bps)))
                except Exception:
                    b = 0
                return self._format_bytes_binary(str(b), decimals=2)

            def _progress_reporter():
                last_bytes = 0
                last_ts = time.time()
                while not progress_stop.wait(0.5):
                    now = time.time()
                    with progress_lock:
                        cur_bytes = int(done_bytes)
                    dt = max(now - last_ts, 1e-6)
                    speed = (cur_bytes - last_bytes) / dt
                    if planned_bytes > 0:
                        pct = int(min(100.0, (cur_bytes * 100.0) / planned_bytes))
                        cur_disp = self._format_bytes_binary(str(cur_bytes), decimals=2)
                        total_disp = self._format_bytes_binary(str(planned_bytes), decimals=2)
                        print(f"Progress: {pct:3d}% ({cur_disp} / {total_disp}) | Speed: {_fmt_speed_bps(speed)}/s", flush=True)
                    else:
                        cur_disp = self._format_bytes_binary(str(cur_bytes), decimals=2)
                        print(f"Progress: ---% ({cur_disp}) | Speed: {_fmt_speed_bps(speed)}/s", flush=True)
                    last_bytes = cur_bytes
                    last_ts = now

            progress_thread = threading.Thread(target=_progress_reporter, daemon=True)
            progress_thread.start()

            if proc.stdout is not None:
                for raw in proc.stdout:
                    line = raw.rstrip('\n')
                    m = re.match(r'^\s*([0-9,]+)\t(.*)$', line)
                    if m:
                        try:
                            with progress_lock:
                                done_bytes += int(m.group(1).replace(',', ''))
                        except Exception:
                            pass
                    elif line.strip():
                        print(line)

            rc_sync = proc.wait()
            progress_stop.set()
            progress_thread.join(timeout=1.0)

            with progress_lock:
                final_done = int(done_bytes)
            if planned_bytes > 0:
                pct = int(min(100.0, (final_done * 100.0) / planned_bytes))
                cur_disp = self._format_bytes_binary(str(final_done), decimals=2)
                total_disp = self._format_bytes_binary(str(planned_bytes), decimals=2)
                print(f"Progress: {pct:3d}% ({cur_disp} / {total_disp}) | Speed: 0 B/s", flush=True)
            else:
                cur_disp = self._format_bytes_binary(str(final_done), decimals=2)
                print(f"Progress: ---% ({cur_disp}) | Speed: 0 B/s", flush=True)

            if rc_sync == 0:
                log("Sync complete.")
            elif rc_sync == 24:
                log("Sync completed with warnings: some source files vanished during transfer (rsync exit 24).", 'WARN')
                log("This is expected on active trees (e.g., browser cache, temp files). Re-run sync to converge.", 'WARN')
            else:
                log(f"Sync failed: rsync exited with status {rc_sync}.", 'ERROR')
        except Exception as e:
            log(f"Sync failed: {e}", 'ERROR')
        finally:
            print(f"Duration: {_fmt_hms(time.time() - start_ts)}")

    def do_diff(self, arg):
        '''Preview differences between two mounted filesystems: diff <primary_name> <secondary_name> [--depth N] [-d] [--fast] [--checksum]

        Endpoints may be mapping names/IDs (must be mounted) or absolute directory paths.
        Uses rsync dry-run itemized output (primary -> secondary) and prints:
        1) Change counts and byte estimates (created/modified/deleted, net change).
        2) Hierarchy summary by subtree up to --depth levels.
        '''
        parser = CmdArgumentParser(prog='diff', add_help=False)
        parser.add_argument('primary_name')
        parser.add_argument('secondary_name')
        parser.add_argument('--depth', type=int, default=2, help='Hierarchy depth for subtree summary (default: 2)')
        parser.add_argument('-d', '--dirs-only', action='store_true', help='Show directories only in hierarchy output')
        parser.add_argument('--fast', action='store_true', help='Show raw rsync -an --delete --stats output only')
        parser.add_argument('--checksum', action='store_true', help='Compare file content using checksums (slower)')
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        if args.depth < 1:
            log("--depth must be >= 1.", 'ERROR')
            return

        primary = args.primary_name
        secondary = args.secondary_name
        depth = args.depth
        dirs_only = args.dirs_only
        fast_mode = args.fast
        checksum_mode = args.checksum

        def _resolve_diff_endpoint(value, role_label):
            if os.path.isabs(value):
                p = os.path.realpath(value)
                if not os.path.exists(p):
                    log(f"{role_label} path does not exist: {value}", 'ERROR')
                    return None
                if not os.path.isdir(p):
                    log(f"{role_label} path must be a directory: {value}", 'ERROR')
                    return None
                return p

            mp = self.get_mountpoint(value)
            if not mp:
                log(f"{role_label} disk '{value}' is not mounted.", 'ERROR')
                return None
            return mp

        pri_mnt = _resolve_diff_endpoint(primary, "Primary")
        if not pri_mnt:
            return
        sec_mnt = _resolve_diff_endpoint(secondary, "Secondary")
        if not sec_mnt:
            return

        src_path = pri_mnt.rstrip('/') + '/'
        dst_path = sec_mnt.rstrip('/') + '/'
        if fast_mode:
            print(f"Diff (fast dry-run, source->destination): {Colors.BOLD}{src_path}{Colors.ENDC} -> {Colors.WARNING}{dst_path}{Colors.ENDC}")
            print("  Source is copied FROM; destination is what would be replaced to match source.")
        else:
            print(f"Diff (dry-run, source->destination): {Colors.BOLD}{src_path}{Colors.ENDC} -> {Colors.WARNING}{dst_path}{Colors.ENDC}")
            print("  Source is copied FROM; destination is what would be replaced to match source.")
        if checksum_mode:
            print("  Comparison mode: checksum/content-based (rsync -c).")

        run_command(['sudo', '-v'])

        if fast_mode:
            if dirs_only:
                log("--fast ignores -d/--dirs-only.", 'WARN')
            if depth != 2:
                log("--fast ignores --depth.", 'WARN')

            fast_cmd = ['rsync', '-an']
            if checksum_mode:
                fast_cmd.append('-c')
            fast_cmd.extend(['--delete', '--stats', src_path, dst_path])
            res_fast = run_command(
                fast_cmd,
                sudo=True,
                capture_output=True,
                check=False
            )
            out_fast = (getattr(res_fast, 'stdout', '') or '')
            err_fast = (getattr(res_fast, 'stderr', '') or '')
            if out_fast.strip():
                print(out_fast.rstrip())
            if err_fast.strip():
                print(err_fast.rstrip(), file=sys.stderr)

            m_rf = re.search(r'^\s*Number of regular files transferred:\s*([0-9][0-9,]*)\s*$', out_fast, flags=re.MULTILINE)
            if m_rf:
                n_rf = int(m_rf.group(1).replace(',', ''))
                print(f"Fast note: created (new+updated regular files) = {n_rf:,}.")

            rc_fast = getattr(res_fast, 'returncode', 0)
            if rc_fast not in (0, 24):
                log(f"rsync dry-run exited with status {rc_fast}. Output may be incomplete.", 'WARN')
            return

        def _parse_int(s):
            m = re.search(r"[0-9][0-9,]*", str(s or ""))
            if not m:
                return 0
            try:
                return int(m.group(0).replace(',', ''), 10)
            except ValueError:
                return 0

        def _norm_relpath(p):
            p = (p or '').strip()
            while p.startswith('./'):
                p = p[2:]
            return p

        def _add_subtree(kind, relpath, seen, counts):
            relpath = _norm_relpath(relpath)
            if not relpath or relpath.endswith('/'):
                return
            # Root always tracks full-tree totals for all changed files.
            seen["."] = True
            counts[(".", kind)] = counts.get((".", kind), 0) + 1
            parts = relpath.split('/')
            max_folder_parts = len(parts) - 1
            if max_folder_parts < 1:
                return

            cur = []
            upto = min(max_folder_parts, depth)
            for i in range(upto):
                cur.append(parts[i])
                k = "/".join(cur)
                seen[k] = True
                counts[(k, kind)] = counts.get((k, kind), 0) + 1

        def _add_subtree_bytes(kind, relpath, seen, byte_totals, amount):
            relpath = _norm_relpath(relpath)
            if not relpath or relpath.endswith('/'):
                return
            # Root always tracks full-tree totals for all changed-file byte deltas.
            seen["."] = True
            byte_totals[(".", kind)] = byte_totals.get((".", kind), 0) + int(amount)
            parts = relpath.split('/')
            max_folder_parts = len(parts) - 1
            if max_folder_parts < 1:
                return

            cur = []
            upto = min(max_folder_parts, depth)
            for i in range(upto):
                cur.append(parts[i])
                k = "/".join(cur)
                seen[k] = True
                byte_totals[(k, kind)] = byte_totals.get((k, kind), 0) + int(amount)

        def _add_file_change(kind, relpath, file_counts, file_bytes, amount):
            relpath = _norm_relpath(relpath)
            if not relpath or relpath.endswith('/'):
                return
            file_counts[(relpath, kind)] = file_counts.get((relpath, kind), 0) + 1
            file_bytes[(relpath, kind)] = file_bytes.get((relpath, kind), 0) + int(amount)

        def _fmt_size_human(num_bytes, signed=False):
            n = int(num_bytes or 0)
            neg = n < 0
            v = abs(float(n))
            units = ['B', 'KB', 'MB', 'GB']
            idx = 0
            while idx < len(units) - 1 and v >= 1024.0:
                v /= 1024.0
                idx += 1
            if idx == 0:
                txt = f"{int(v)}B"
            else:
                txt = f"{v:.2f}".rstrip('0').rstrip('.') + units[idx]
            if signed:
                return ("-" if neg else "+") + txt
            return ("-" if neg else "") + txt

        def _build_tree_entries(root_dir, max_depth, dirs_only_mode, extra_dirs=None, extra_files=None):
            """
            Build entries in tree order (directories first) up to max_depth.
            Includes unchanged files/dirs from the primary path so output mirrors:
              tree -L <depth> --dirsfirst
            """
            entries = [('dir', '.')]
            extra_dirs = set(extra_dirs or [])
            extra_files = set(extra_files or [])

            def _split_parent_name(relp):
                if not relp or relp == ".":
                    return ("", "")
                if "/" in relp:
                    parent, name = relp.rsplit("/", 1)
                    return (parent, name)
                return ("", relp)

            extra_dirs_by_parent = {}
            for relp in extra_dirs:
                parent, name = _split_parent_name(relp)
                if not name:
                    continue
                extra_dirs_by_parent.setdefault(parent, set()).add(name)

            extra_files_by_parent = {}
            for relp in extra_files:
                parent, name = _split_parent_name(relp)
                if not name:
                    continue
                extra_files_by_parent.setdefault(parent, set()).add(name)

            def _walk_virtual(rel_dir, level):
                if level >= max_depth:
                    return
                vdirs = sorted(extra_dirs_by_parent.get(rel_dir, set()))
                vfiles = sorted(extra_files_by_parent.get(rel_dir, set())) if not dirs_only_mode else []
                for dname in vdirs:
                    relp = dname if not rel_dir else f"{rel_dir}/{dname}"
                    entries.append(('dir', relp))
                    _walk_virtual(relp, level + 1)
                if not dirs_only_mode:
                    for fname in vfiles:
                        relp = fname if not rel_dir else f"{rel_dir}/{fname}"
                        entries.append(('file', relp))

            def _walk(abs_dir, rel_dir, level):
                if level >= max_depth:
                    return
                source_dir_names = set()
                source_file_names = set()
                try:
                    with os.scandir(abs_dir) as it:
                        for ent in it:
                            try:
                                is_dir = ent.is_dir(follow_symlinks=False)
                            except OSError:
                                is_dir = False
                            if is_dir:
                                source_dir_names.add(ent.name)
                            elif not dirs_only_mode:
                                source_file_names.add(ent.name)
                except (OSError, PermissionError, FileNotFoundError, NotADirectoryError):
                    _walk_virtual(rel_dir, level)
                    return

                dirs = sorted(source_dir_names | extra_dirs_by_parent.get(rel_dir, set()))
                files = sorted(source_file_names | extra_files_by_parent.get(rel_dir, set())) if not dirs_only_mode else []

                for dname in dirs:
                    relp = dname if not rel_dir else f"{rel_dir}/{dname}"
                    entries.append(('dir', relp))
                    if dname in source_dir_names:
                        _walk(os.path.join(abs_dir, dname), relp, level + 1)
                    else:
                        _walk_virtual(relp, level + 1)

                if not dirs_only_mode:
                    for fname in files:
                        relp = fname if not rel_dir else f"{rel_dir}/{fname}"
                        entries.append(('file', relp))

            _walk(root_dir, "", 0)
            return entries

        def _batch_stat_sizes(base_path, relpaths, chunk_size=512):
            """
            Resolve file sizes for many destination-relative paths using batched stat calls.
            Falls back to os.stat for paths missing from batched output.
            Returns: {relpath: size_bytes}
            """
            sizes = {}
            if not relpaths:
                return sizes

            unique_relpaths = list(dict.fromkeys(relpaths))
            for i in range(0, len(unique_relpaths), chunk_size):
                chunk_rel = unique_relpaths[i:i + chunk_size]
                abs_chunk = []
                abs_to_rel = {}
                for rel in chunk_rel:
                    ap = os.path.join(base_path, rel)
                    abs_chunk.append(ap)
                    abs_to_rel[ap] = rel

                seen_rel = set()
                res_stat = run_command(
                    ['stat', '-c', '%n\t%s', '--'] + abs_chunk,
                    sudo=True,
                    capture_output=True,
                    check=False
                )
                out_stat = (getattr(res_stat, 'stdout', '') or '')
                for line in out_stat.splitlines():
                    line = (line or '').rstrip('\n')
                    if '\t' not in line:
                        continue
                    out_path, out_size = line.rsplit('\t', 1)
                    rel = abs_to_rel.get(out_path)
                    if not rel:
                        continue
                    sizes[rel] = _parse_int(out_size)
                    seen_rel.add(rel)

                for rel in chunk_rel:
                    if rel in seen_rel:
                        continue
                    ap = os.path.join(base_path, rel)
                    try:
                        st = os.stat(ap)
                        sizes[rel] = int(st.st_size)
                    except OSError:
                        pass
            return sizes

        # Summary 1 counters
        new_files = 0
        mod_files = 0
        del_files = 0
        del_dirs = 0
        new_bytes = 0
        mod_bytes = 0
        del_bytes = 0
        pending_delete_paths = []
        modified_entries = []

        # Summary 2 counters (folder view)
        seen = {}
        c = {}
        cb = {}
        fc = {}
        fb = {}
        total_new = 0
        total_upd = 0
        total_del = 0

        cmd = ['sudo', 'rsync', '-anH']
        if checksum_mode:
            cmd.append('-c')
        cmd.extend([
            '--delete', '--itemize-changes',
            '--out-format=%i\t%l\t%n',
            src_path, dst_path
        ])
        stderr_lines = []

        def _drain_stderr(stream, sink):
            try:
                for line in stream:
                    sink.append(line)
            except Exception:
                pass

        proc = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1
        )
        stderr_thread = threading.Thread(target=_drain_stderr, args=(proc.stderr, stderr_lines), daemon=True)
        stderr_thread.start()

        for raw in proc.stdout:
            line = (raw or "").rstrip()
            if not line:
                continue

            # Delete lines do not reliably respect out-format.
            if line.startswith('*deleting'):
                body = line[len('*deleting'):].lstrip()
                del_size = None
                # With --out-format, rsync delete lines may appear as:
                #   *deleting 0<TAB>path
                # Strip the optional leading size field so it doesn't pollute folder names.
                if '\t' in body:
                    first, rest = body.split('\t', 1)
                    if re.fullmatch(r"[0-9][0-9,]*", first.strip()):
                        del_size = _parse_int(first)
                        body = rest

                p = _norm_relpath(body.strip())
                if p.endswith('/'):
                    del_dirs += 1
                else:
                    del_files += 1
                    total_del += 1
                    _add_subtree('del', p, seen, c)
                    if del_size is not None and del_size > 0:
                        del_bytes += del_size
                        _add_subtree_bytes('del', p, seen, cb, del_size)
                        _add_file_change('del', p, fc, fb, del_size)
                    else:
                        # rsync delete lines often report 0 size; resolve after parse in batches.
                        pending_delete_paths.append(p)
                continue

            parts = line.split('\t', 2)
            if len(parts) < 3:
                continue
            item = parts[0].strip()
            lraw = parts[1].strip()
            relp = _norm_relpath(parts[2].strip())
            size_b = _parse_int(lraw)

            if len(item) < 2:
                continue
            item_type = item[1]
            is_new_nondir = (
                item.startswith('>f+') or item.startswith('cf+') or
                item.startswith('>L+') or item.startswith('cL+')
            )

            # New files/symlinks.
            if is_new_nondir:
                new_files += 1
                total_new += 1
                new_bytes += size_b
                _add_subtree('new', relp, seen, c)
                _add_subtree_bytes('new', relp, seen, cb, size_b)
                _add_file_change('new', relp, fc, fb, size_b)
                continue

            # Modified regular files (delta estimated as src_size - dst_size).
            if item_type == 'f':
                mod_files += 1
                total_upd += 1
                modified_entries.append((relp, size_b))
                _add_subtree('upd', relp, seen, c)
                continue

            # Modified symlinks (delta from rsync item size field only; no dst stat fallback).
            if item_type == 'L':
                mod_files += 1
                total_upd += 1
                mod_bytes += size_b
                _add_subtree('upd', relp, seen, c)
                _add_subtree_bytes('upd', relp, seen, cb, size_b)
                _add_file_change('upd', relp, fc, fb, size_b)
                continue

        if proc.stdout:
            proc.stdout.close()
        rc = proc.wait()
        stderr_thread.join(timeout=1.0)

        if rc not in (0, 24):
            log(f"rsync dry-run exited with status {rc}. Output may be incomplete.", 'WARN')
        err = "".join(stderr_lines)
        if err.strip():
            print(err.rstrip(), file=sys.stderr)

        # Batch-resolve file sizes for delete fallback and modified destination sizes.
        if pending_delete_paths:
            del_sizes = _batch_stat_sizes(dst_path, pending_delete_paths)
            for rel in pending_delete_paths:
                sz = del_sizes.get(rel, 0)
                del_bytes += sz
                _add_subtree_bytes('del', rel, seen, cb, sz)
                _add_file_change('del', rel, fc, fb, sz)

        if modified_entries:
            mod_dst_sizes = _batch_stat_sizes(dst_path, [rel for rel, _ in modified_entries])
            for rel, src_size in modified_entries:
                delta = src_size - mod_dst_sizes.get(rel, 0)
                mod_bytes += delta
                _add_subtree_bytes('upd', rel, seen, cb, delta)
                _add_file_change('upd', rel, fc, fb, delta)

        print(f"Created files:  {new_files}")
        print(f"Modified files: {mod_files}")
        print(f"Deleted files:  {del_files}")
        print(f"Deleted dirs:   {del_dirs}")
        print("-----------------------")
        print(f"New Data:       {new_bytes:,} bytes")
        print(f"Updated Data:   {mod_bytes:,} bytes")
        print(f"Deleted Data:   {del_bytes:,} bytes")
        print("-----------------------")
        print(f"Net Change:     {new_bytes + mod_bytes - del_bytes:,} bytes")
        print("")

        print("Rsync dry-run change summary by hierarchy")
        print(f"Source -> Dest: {src_path}  ->  {dst_path}")
        print("Source = copied FROM; Dest = replaced to match source")
        print(f"Depth shown: {depth} level(s)")
        print("")
        print("Format: <name[/]>  (+N [C]  ~U [U]  -D [R])")
        print("  +N = files/symlinks that would be CREATED under this entry/subtree")
        print("  ~U = files/symlinks that would be MODIFIED/UPDATED under this entry/subtree")
        print("  -D = files/symlinks that would be DELETED under this entry/subtree")
        print("  [C]/[U]/[R] = created/updated(delta)/removed bytes (shown only when non-zero)")
        print("  Directories end with '/'.")
        print("  Unchanged entries are uncolored.")
        print("Counts are inclusive of all descendants (subtree totals).")
        print("-----------------------------------------------")

        deleted_dirs = {
            k for k in seen.keys()
            if k != "." and c.get((k, 'del'), 0) > 0
        }
        deleted_files = {
            p for (p, kind) in fc.keys()
            if kind == 'del'
        }
        entries = _build_tree_entries(
            src_path.rstrip('/'),
            depth,
            dirs_only,
            extra_dirs=deleted_dirs,
            extra_files=deleted_files
        )

        for etype, path in entries:
            if etype == 'dir':
                depth_here = 0 if path == "." else (path.count('/') + 1)
                indent = " " * (depth_here * 2)
                name = dst_path if path == "." else (path.split('/')[-1] + "/")
                n_new = c.get((path, 'new'), 0)
                n_upd = c.get((path, 'upd'), 0)
                n_del = c.get((path, 'del'), 0)
                b_new = cb.get((path, 'new'), 0)
                b_upd = cb.get((path, 'upd'), 0)
                b_del = cb.get((path, 'del'), 0)
            else:
                depth_here = path.count('/') + 1
                indent = " " * (depth_here * 2)
                name = path.split('/')[-1]
                n_new = fc.get((path, 'new'), 0)
                n_upd = fc.get((path, 'upd'), 0)
                n_del = fc.get((path, 'del'), 0)
                b_new = fb.get((path, 'new'), 0)
                b_upd = fb.get((path, 'upd'), 0)
                b_del = fb.get((path, 'del'), 0)

            kinds = 0
            if n_new > 0:
                kinds += 1
            if n_upd > 0:
                kinds += 1
            if n_del > 0:
                kinds += 1

            if kinds > 1:
                color = Colors.WARNING
            elif n_new > 0:
                color = Colors.OKGREEN
            elif n_del > 0:
                color = Colors.FAIL
            elif n_upd > 0:
                color = Colors.WARNING
            else:
                color = None

            new_part = f"+{n_new}" + (f" [{_fmt_size_human(b_new)}]" if b_new != 0 else "")
            upd_part = f"~{n_upd}" + (f" [{_fmt_size_human(b_upd, signed=True)}]" if b_upd != 0 else "")
            del_part = f"-{n_del}" + (f" [{_fmt_size_human(b_del)}]" if b_del != 0 else "")
            cname = f"{color}{name}{Colors.ENDC}" if color else name
            print(
                f"{indent}{cname}  "
                f"({new_part}  "
                f"{upd_part}  "
                f"{del_part})"
            )

        print("-----------------------------------------------")
        print(f"Totals (files/symlinks): create={total_new}  modify={total_upd}  delete={total_del}")

    def do_defrag(self, arg):
        '''Defragment a mounted filesystem: defrag <name> [--compress]

        UNDER THE HOOD:
        1.  Validation: Verifies the disk is mapped and currently mounted.
        2.  Confirmation: Requires solving two math problems.
        3.  Execution:
            - ext4:  runs 'sudo e4defrag <mountpoint>'
            - btrfs: runs 'sudo btrfs filesystem defragment -r -v <mountpoint>'
                     optional: add '--compress' to use '-czstd' recompression mode.
                     with live progress counters (total files + current directory),
                     then 'sudo btrfs balance start -dusage=50 <mountpoint>'
        4.  Recording: Stores a timestamp on the mountpoint root via:
              sudo setfattr -n user.last_defrag -v "<date>" <mountpoint>
        '''
        parser = CmdArgumentParser(prog='defrag', add_help=False)
        parser.add_argument('name')
        parser.add_argument('--compress', action='store_true', help='Enable btrfs recompression during defrag (-czstd)')
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.name
        compress_mode = bool(getattr(args, 'compress', False))
        mnt = self.get_mountpoint(name)
        if not mnt:
            log(f"Disk '{name}' is not mounted. Run 'open {name}' first.", 'ERROR')
            return

        # Block defrag on the system root drive (writes lots of blocks/metadata).
        try:
            res_src = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'SOURCE'], check=False)
            src = (getattr(res_src, 'stdout', '') or '').strip()
            if src and self._block_if_root_drive(os.path.realpath(src), f"defrag {name}"):
                return
        except Exception:
            pass

        # Determine filesystem type.
        fstype = ""
        try:
            res_fs = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'FSTYPE'], check=False)
            fstype = (getattr(res_fs, 'stdout', '') or '').strip().lower()
        except Exception:
            fstype = ""

        if fstype not in ("ext4", "btrfs"):
            log(f"Defrag not supported for filesystem type '{fstype or 'unknown'}' at {mnt}.", 'ERROR')
            log("Supported: ext4 (e4defrag), btrfs (defragment + balance -dusage=50).", 'ERROR')
            return

        # Confirmation (not strictly destructive, but high-impact: rewrites lots of blocks/metadata).
        print(f"Defragmenting: {Colors.BOLD}{mnt}{Colors.ENDC} (fstype={fstype})")
        if not self.extensive_confirm(f"defrag {name} ({mnt})", destructive=False):
            return

        run_command(['sudo', '-v'])

        # Find tools (PATH may not include sbin).
        e4defrag_bin = _find_tool_or_common_paths('e4defrag', [
            '/usr/sbin/e4defrag',
            '/sbin/e4defrag',
            '/usr/local/sbin/e4defrag',
            '/usr/bin/e4defrag',
            '/bin/e4defrag',
        ])
        btrfs_bin = _find_tool_or_common_paths('btrfs', [
            '/usr/sbin/btrfs',
            '/sbin/btrfs',
            '/usr/local/sbin/btrfs',
            '/usr/bin/btrfs',
            '/bin/btrfs',
        ])
        setfattr_bin = _find_tool_or_common_paths('setfattr', [
            '/usr/bin/setfattr',
            '/bin/setfattr',
            '/usr/sbin/setfattr',
            '/sbin/setfattr',
        ])

        try:
            if fstype == "ext4":
                start_ts = time.time()
                if compress_mode:
                    log("--compress applies to btrfs only; ignoring for ext4.", 'WARN')
                if e4defrag_bin is None:
                    log("e4defrag not found. Install 'e2fsprogs' and retry.", 'ERROR')
                    return
                log(f"Running: {e4defrag_bin} {mnt}")
                run_command([e4defrag_bin, mnt], sudo=True, capture_output=False, check=False)
                print(f"Duration: {_fmt_hms(time.time() - start_ts)}")
            else:
                if btrfs_bin is None:
                    log("btrfs not found. Install 'btrfs-progs' and retry.", 'ERROR')
                    return
                start_ts_total = time.time()
                start_ts = time.time()
                log_path = f"/tmp/diskmgr_btrfs_defrag_{os.getpid()}_{int(start_ts)}.log"
                cmd = ['sudo', btrfs_bin, 'filesystem', 'defragment', '-r', '-v']
                if compress_mode:
                    cmd.append('-czstd')
                cmd.append(mnt)
                cmd_str = " ".join(cmd[1:])
                log(f"Running: {cmd_str}")
                log(f"Progress log: {log_path}")

                total_done = 0
                current_dir = "Scanning..."
                dir_counts = {}
                last_render = 0.0
                proc = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                )
                with open(log_path, 'w', encoding='utf-8', errors='replace') as lf:
                    if proc.stdout:
                        for raw in proc.stdout:
                            line = (raw or '').rstrip('\n')
                            lf.write(line + "\n")
                            txt = line.strip()
                            if txt.startswith('/'):
                                # btrfs -v emits one path per processed file; use it as progress signal.
                                path = txt.rstrip(':')
                                current_dir = os.path.dirname(path) or '/'
                                total_done += 1
                                dir_counts[current_dir] = dir_counts.get(current_dir, 0) + 1
                            now = time.time()
                            if now - last_render >= 1.0:
                                in_dir = dir_counts.get(current_dir, 0)
                                msg = (
                                    f"\rFiles: {total_done:<10} | "
                                    f"In Current Dir: {in_dir:<8} | "
                                    f"Path: {current_dir[:70]}"
                                )
                                sys.stdout.write(msg)
                                sys.stdout.flush()
                                last_render = now
                        proc.stdout.close()
                rc_defrag = proc.wait()
                in_dir = dir_counts.get(current_dir, 0)
                final_msg = (
                    f"\rFiles: {total_done:<10} | "
                    f"In Current Dir: {in_dir:<8} | "
                    f"Path: {current_dir[:70]}"
                )
                sys.stdout.write(final_msg + "\n")
                sys.stdout.flush()

                elapsed = time.time() - start_ts
                print("--------------------------------------------------------")
                print(f"Btrfs defragment complete. Duration: {_fmt_hms(elapsed)}")
                print(f"Total files processed (verbose paths): {total_done}")
                print(f"Progress log saved at: {log_path}")
                if rc_defrag not in (0,):
                    log(f"btrfs defragment exited with status {rc_defrag}. Continuing with balance.", 'WARN')
                log(f"Running: {btrfs_bin} balance start -dusage=50 {mnt}")
                res_balance_start = run_command(
                    [btrfs_bin, 'balance', 'start', '-dusage=50', mnt],
                    sudo=True,
                    capture_output=True,
                    check=False
                )
                out_start = (getattr(res_balance_start, 'stdout', '') or '').strip()
                err_start = (getattr(res_balance_start, 'stderr', '') or '').strip()
                if out_start:
                    print(out_start)
                if err_start:
                    print(err_start, file=sys.stderr)
                if getattr(res_balance_start, 'returncode', 0) not in (0,):
                    log(
                        f"btrfs balance start exited with status {getattr(res_balance_start, 'returncode', 0)}. "
                        f"Will still query balance status.",
                        'WARN'
                    )

                log(f"Monitoring: {btrfs_bin} balance status {mnt}")
                last_status = None
                while True:
                    res_status = run_command(
                        [btrfs_bin, 'balance', 'status', mnt],
                        sudo=True,
                        capture_output=True,
                        check=False
                    )
                    out_status = (getattr(res_status, 'stdout', '') or '').strip()
                    err_status = (getattr(res_status, 'stderr', '') or '').strip()
                    status_text = out_status or err_status or "(no status output)"

                    if status_text != last_status:
                        print(status_text)
                        last_status = status_text

                    s = status_text.lower()
                    if ("is running" in s) or ("is paused" in s):
                        time.sleep(2.0)
                        continue
                    break

            # Record timestamp in xattr on mountpoint root.
            if setfattr_bin is None:
                log("setfattr not found. Install 'attr' and retry to record last_defrag.", 'WARN')
                print(f"Duration: {_fmt_hms(time.time() - start_ts_total)}")
                return

            ds = ""
            try:
                res_date = run_command(['date'], capture_output=True, check=False)
                ds = (getattr(res_date, 'stdout', '') or '').strip()
            except Exception:
                ds = ""
            if not ds:
                ds = datetime.datetime.now().isoformat(sep=' ', timespec='seconds')

            run_command([setfattr_bin, '-n', 'user.last_defrag', '-v', ds, mnt], sudo=True, check=False)
            log(f"Recorded xattr: user.last_defrag={ds} on {mnt}")
            print(f"Duration: {_fmt_hms(time.time() - start_ts_total)}")
        except Exception as e:
            log(f"Defrag failed: {e}", 'ERROR')

    def do_fshealth(self, arg):
        '''Filesystem health/diagnostics: fshealth <name>

        Shows filesystem-specific diagnostic output and local "maintenance" timestamps.

        - ext4:  sudo tune2fs -l <device>
                sudo e4defrag -c <mountpoint>   (fragmentation score + extents/files ratio)
        - btrfs: sudo btrfs filesystem usage <mountpoint>
                sudo btrfs filesystem show <mountpoint>
                sudo btrfs filesystem df <mountpoint>
                sudo btrfs device stats <mountpoint>
                sudo btrfs scrub status <mountpoint>
                sudo compsize <mountpoint>  (extents/files ratio)
        - xfs:   xfs_info <mountpoint>

        Also reads xattrs from the mountpoint root:
          user.last_defrag, user.last_scrub
        '''
        args = arg.split()
        if len(args) != 1:
            log("Usage: fshealth <name>", 'ERROR')
            return

        name = args[0]
        mnt = self.get_mountpoint(name)
        if not mnt:
            log(f"Disk '{name}' is not mounted. Run 'open {name}' first.", 'ERROR')
            return

        fstype = ""
        src = ""
        try:
            res = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'FSTYPE,SOURCE'], check=False)
            parts = (getattr(res, 'stdout', '') or '').strip().split()
            if len(parts) >= 2:
                fstype = parts[0].strip().lower()
                src = parts[1].strip()
            else:
                # Fallback to separate calls.
                res_fs = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'FSTYPE'], check=False)
                fstype = (getattr(res_fs, 'stdout', '') or '').strip().lower()
                res_src = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'SOURCE'], check=False)
                src = (getattr(res_src, 'stdout', '') or '').strip()
        except Exception:
            pass

        src_real = os.path.realpath(src) if src else ""

        def _read_xattr_text(path, key):
            try:
                v = os.getxattr(path, key)
            except OSError:
                return None
            try:
                if isinstance(v, (bytes, bytearray)):
                    return v.decode('utf-8', errors='replace')
            except Exception:
                return str(v)
            return str(v)

        last_defrag = _read_xattr_text(mnt, 'user.last_defrag')
        last_scrub = _read_xattr_text(mnt, 'user.last_scrub')

        print(f"\n{Colors.HEADER}{Colors.BOLD}=== Filesystem health: {name} ==={Colors.ENDC}")
        print(f"{Colors.BOLD}Mountpoint:{Colors.ENDC} {mnt}")
        if src_real:
            print(f"{Colors.BOLD}Source:{Colors.ENDC} {src_real}")
        if fstype:
            print(f"{Colors.BOLD}FSType:{Colors.ENDC} {fstype}")
        print(f"{Colors.BOLD}Last defrag:{Colors.ENDC} {last_defrag or '-'}")
        print(f"{Colors.BOLD}Last scrub:{Colors.ENDC} {last_scrub or '-'}")

        print(f"\n{Colors.HEADER}{Colors.BOLD}--- findmnt -A --output-all --json {mnt} ---{Colors.ENDC}")
        res_fm = run_command(['findmnt', '-A', '--output-all', '--json', mnt], check=False)
        fm_out = (getattr(res_fm, 'stdout', '') or '')
        fm_err = (getattr(res_fm, 'stderr', '') or '')
        if fm_out.strip():
            print(fm_out.rstrip())
        else:
            print("{}")
        if fm_err.strip():
            print(fm_err.rstrip(), file=sys.stderr)

        run_command(['sudo', '-v'])

        # Compute fragmentation state (best-effort), but print it at the end of fshealth output.
        frag_lines = []
        def _frag(line):
            frag_lines.append(line)

        compsize_bin = None
        compsize_out = ""
        compsize_err = ""
        def _ratio_state_ext4(epf):
            # Requested rubric: <1.1 healthy, >1.5 bad, >5 critical.
            if epf < 1.1:
                return (f"{Colors.OKGREEN}HEALTHY{Colors.ENDC}", "<1.1 healthy")
            if epf > 5.0:
                return (f"{Colors.FAIL}CRITICAL{Colors.ENDC}", ">5 critical")
            if epf > 1.5:
                return (f"{Colors.WARNING}BAD{Colors.ENDC}", ">1.5 bad")
            return (f"{Colors.WARNING}WATCH{Colors.ENDC}", "between 1.1 and 1.5")

        def _ratio_state_btrfs(epf):
            # Requested rubric: <1 good, >5 bad, >20 critical.
            if epf < 1.0:
                return (f"{Colors.OKGREEN}GOOD{Colors.ENDC}", "<1 good")
            if epf > 20.0:
                return (f"{Colors.FAIL}CRITICAL{Colors.ENDC}", ">20 critical")
            if epf > 5.0:
                return (f"{Colors.WARNING}BAD{Colors.ENDC}", ">5 bad")
            return (f"{Colors.WARNING}WATCH{Colors.ENDC}", "between 1 and 5")

        if fstype == 'ext4':
            e4defrag_bin = _find_tool_or_common_paths('e4defrag', [
                '/usr/sbin/e4defrag',
                '/sbin/e4defrag',
                '/usr/local/sbin/e4defrag',
                '/usr/bin/e4defrag',
                '/bin/e4defrag',
            ])
            if e4defrag_bin:
                res_f = run_command([e4defrag_bin, '-c', mnt], sudo=True, capture_output=True, check=False)
                frag_out = (getattr(res_f, 'stdout', '') or '') + (getattr(res_f, 'stderr', '') or '')
                m = re.search(r"(?im)Fragmentation score(?: is)?\s*([0-9]+)\b", frag_out)
                m_tb = re.search(
                    r"(?im)^\s*Total/best\s+extents\s*:?\s*([0-9][0-9,]*)\s*/\s*([0-9][0-9,]*)\s*$",
                    frag_out,
                )
                m_avg = re.search(
                    r"(?im)^\s*Average\s+size\s+per\s+extent\s*:?\s*(.+?)\s*$",
                    frag_out,
                )
                score = None
                if m:
                    try:
                        score = int(m.group(1), 10)
                    except ValueError:
                        score = None

                total_extents = None
                best_extents = None
                if m_tb:
                    try:
                        total_extents = int(m_tb.group(1).replace(",", ""), 10)
                        best_extents = int(m_tb.group(2).replace(",", ""), 10)
                    except ValueError:
                        total_extents = None
                        best_extents = None

                # Prefer a real file-count if e4defrag reports one; otherwise fall back to best_extents proxy.
                total_files = None
                m_files = re.search(
                    r"(?im)^\s*Fragmented\s+files/Total\s+files\s*:?\s*([0-9][0-9,]*)\s*/\s*([0-9][0-9,]*)\s*$",
                    frag_out,
                )
                if m_files:
                    try:
                        total_files = int(m_files.group(2).replace(",", ""), 10)
                    except ValueError:
                        total_files = None

                epf = None
                if total_extents is not None and total_files is not None and total_files > 0:
                    epf = total_extents / float(total_files)
                elif total_extents is not None and best_extents is not None and best_extents > 0:
                    epf = total_extents / float(best_extents)

                if epf is not None:
                    state, _ = _ratio_state_ext4(epf)
                    score_part = f"; score {score}" if score is not None else ""
                    _frag(
                        f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} "
                        f"{state} (ext4 ratio ~{epf:.2f} extents/file; thresholds: "
                        f"<1.1 healthy, >1.5 bad, >5 critical{score_part})"
                    )
                elif score is not None:
                    _frag(
                        f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} "
                        f"- (ext4 thresholds: <1.1 healthy, >1.5 bad, >5 critical; "
                        f"extents/files ratio unavailable; score {score})"
                    )
                else:
                    _frag(f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} - (could not parse e4defrag output)")

                if total_extents is not None and best_extents is not None:
                    extra_extents = max(total_extents - best_extents, 0)
                    overhead_pct = (extra_extents / float(best_extents) * 100.0) if best_extents > 0 else 0.0
                    _frag(
                        f"{Colors.BOLD}Extent overhead:{Colors.ENDC} "
                        f"{extra_extents} extra extents over ideal ({overhead_pct:.2f}%)"
                    )
                if m_avg:
                    avg_extent = (m_avg.group(1) or "").strip()
                    if avg_extent:
                        _frag(f"{Colors.BOLD}Average extent size:{Colors.ENDC} {avg_extent}")
            else:
                _frag(f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} - (e4defrag not found)")
        elif fstype == 'btrfs':
            compsize_bin = _find_tool_or_common_paths('compsize', [
                '/usr/sbin/compsize',
                '/sbin/compsize',
                '/usr/local/sbin/compsize',
                '/usr/bin/compsize',
                '/bin/compsize',
            ])
            if compsize_bin is None:
                _frag(f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} - (compsize not found)")
            else:
                res_c = run_command([compsize_bin, mnt], sudo=True, capture_output=True, check=False)
                compsize_out = (getattr(res_c, 'stdout', '') or '')
                compsize_err = (getattr(res_c, 'stderr', '') or '')

                m = re.search(
                    r"(?im)^\s*Processed\s+([0-9][0-9,]*)\s+files,\s+([0-9][0-9,]*)\s+regular\s+extents\b",
                    compsize_out + "\n" + compsize_err,
                )
                if m:
                    try:
                        files = int(m.group(1).replace(",", ""), 10)
                        extents = int(m.group(2).replace(",", ""), 10)
                    except ValueError:
                        files = None
                        extents = None
                    if files is not None and extents is not None and files > 0:
                        epf = extents / float(files)
                        state, _ = _ratio_state_btrfs(epf)
                        _frag(
                            f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} "
                            f"{state} (btrfs ratio ~{epf:.2f} extents/file; thresholds: "
                            f"<1 good, >5 bad, >20 critical; "
                            f"{extents} extents/{files} files; via compsize)"
                        )
                    else:
                        _frag(f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} - (could not parse compsize counters)")
                else:
                    _frag(f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} - (compsize did not report Processed counters)")
        else:
            _frag(f"{Colors.BOLD}Defragmentation state:{Colors.ENDC} - (no global defrag metric for {fstype or 'unknown'})")

        # Filesystem diagnostics output (read-only).
        if fstype == 'ext4':
            tune2fs_bin = _find_tool_or_common_paths('tune2fs', [
                '/usr/sbin/tune2fs',
                '/sbin/tune2fs',
                '/usr/local/sbin/tune2fs',
                '/usr/bin/tune2fs',
                '/bin/tune2fs',
            ])
            if tune2fs_bin is None:
                log("tune2fs not found. Install 'e2fsprogs' to view ext4 diagnostics.", 'WARN')
            elif not src_real:
                log("Could not determine source device for this mount (findmnt SOURCE).", 'ERROR')
            else:
                print(f"\n{Colors.HEADER}{Colors.BOLD}--- tune2fs -l {src_real} ---{Colors.ENDC}")
                res = run_command([tune2fs_bin, '-l', src_real], sudo=True, capture_output=True, check=False)
                if (res.stdout or "").strip():
                    print(res.stdout.rstrip())
                if (res.stderr or "").strip():
                    print(res.stderr.rstrip(), file=sys.stderr)
        elif fstype == 'btrfs':
            btrfs_bin = _find_tool_or_common_paths('btrfs', [
                '/usr/sbin/btrfs',
                '/sbin/btrfs',
                '/usr/local/sbin/btrfs',
                '/usr/bin/btrfs',
                '/bin/btrfs',
            ])
            if btrfs_bin is None:
                log("btrfs not found. Install 'btrfs-progs' to view btrfs diagnostics.", 'WARN')
            else:
                print(f"\n{Colors.HEADER}{Colors.BOLD}--- btrfs filesystem usage {mnt} ---{Colors.ENDC}")
                res = run_command([btrfs_bin, 'filesystem', 'usage', mnt], sudo=True, capture_output=True, check=False)
                if (res.stdout or "").strip():
                    print(res.stdout.rstrip())
                if (res.stderr or "").strip():
                    print(res.stderr.rstrip(), file=sys.stderr)

                print(f"\n{Colors.HEADER}{Colors.BOLD}--- btrfs filesystem show {mnt} ---{Colors.ENDC}")
                res = run_command([btrfs_bin, 'filesystem', 'show', mnt], sudo=True, capture_output=True, check=False)
                if (res.stdout or "").strip():
                    print(res.stdout.rstrip())
                if (res.stderr or "").strip():
                    print(res.stderr.rstrip(), file=sys.stderr)

                print(f"\n{Colors.HEADER}{Colors.BOLD}--- btrfs filesystem df {mnt} ---{Colors.ENDC}")
                res = run_command([btrfs_bin, 'filesystem', 'df', mnt], sudo=True, capture_output=True, check=False)
                if (res.stdout or "").strip():
                    print(res.stdout.rstrip())
                if (res.stderr or "").strip():
                    print(res.stderr.rstrip(), file=sys.stderr)

                print(f"\n{Colors.HEADER}{Colors.BOLD}--- btrfs device stats {mnt} ---{Colors.ENDC}")
                res = run_command([btrfs_bin, 'device', 'stats', mnt], sudo=True, capture_output=True, check=False)
                if (res.stdout or "").strip():
                    print(res.stdout.rstrip())
                if (res.stderr or "").strip():
                    print(res.stderr.rstrip(), file=sys.stderr)

                print(f"\n{Colors.HEADER}{Colors.BOLD}--- btrfs scrub status {mnt} ---{Colors.ENDC}")
                res = run_command([btrfs_bin, 'scrub', 'status', mnt], sudo=True, capture_output=True, check=False)
                if (res.stdout or "").strip():
                    print(res.stdout.rstrip())
                if (res.stderr or "").strip():
                    print(res.stderr.rstrip(), file=sys.stderr)
                if compsize_bin is None:
                    log("compsize not found. Install 'compsize' to view btrfs fragmentation amount.", 'WARN')
                else:
                    print(f"\n{Colors.HEADER}{Colors.BOLD}--- compsize {mnt} ---{Colors.ENDC}")
                    if compsize_out.strip():
                        print(compsize_out.rstrip())
                    if compsize_err.strip():
                        print(compsize_err.rstrip(), file=sys.stderr)
        elif fstype == 'xfs':
            xfs_info_bin = _find_tool_or_common_paths('xfs_info', [
                '/usr/sbin/xfs_info',
                '/sbin/xfs_info',
                '/usr/local/sbin/xfs_info',
                '/usr/bin/xfs_info',
                '/bin/xfs_info',
            ]) or 'xfs_info'
            print(f"\n{Colors.HEADER}{Colors.BOLD}--- xfs_info {mnt} ---{Colors.ENDC}")
            res = run_command([xfs_info_bin, mnt], sudo=False, capture_output=True, check=False)
            if (res.stdout or "").strip():
                print(res.stdout.rstrip())
            if (res.stderr or "").strip():
                print(res.stderr.rstrip(), file=sys.stderr)
        else:
            log(f"Unsupported or unknown filesystem type '{fstype or 'unknown'}'.", 'ERROR')

        # Print fragmentation summary last.
        if frag_lines:
            print("")
            for line in frag_lines:
                print(line)

    def do_fsdiag(self, arg):
        '''(Deprecated) Alias for fshealth: fsdiag <name>

        This command was renamed to 'fshealth'. Prefer: fshealth <name>
        '''
        log("fsdiag was renamed to fshealth; running fshealth ...", 'WARN')
        return self.do_fshealth(arg)

    def do_scrub(self, arg):
        '''Scrub a mounted btrfs filesystem: scrub <name> [--no-watch]

        UNDER THE HOOD:
        1.  Validation: Verifies the disk is mapped and currently mounted.
        2.  Confirmation: Requires solving two math problems.
        3.  Execution: Runs 'sudo btrfs scrub start -B -R <mountpoint>'.
        4.  Recording: Stores a timestamp on the mountpoint root via:
              sudo setfattr -n user.last_scrub -v "<date>" <mountpoint>

        OPTIONAL:
        - default (watch mode): tails kernel logs during the scrub and prints checksum errors as they happen.
        - --no-watch: disable log tailing (quiet; you only get the scrub summary output).
          Btrfs typically logs logical addresses (and sometimes inode numbers); diskmgr will attempt
          to resolve those to paths via:
            btrfs inspect-internal logical-resolve <logical> <mountpoint>
            btrfs inspect-internal inode-resolve <ino> <mountpoint>
        '''
        parser = CmdArgumentParser(prog='scrub', add_help=False)
        parser.add_argument('name')
        g = parser.add_mutually_exclusive_group()
        g.add_argument('--watch', '-w', action='store_true', help='(default) Tail kernel logs for checksum errors during scrub')
        g.add_argument('--no-watch', action='store_true', help='Disable log tailing during scrub')
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.name
        # Default to watch mode unless explicitly disabled.
        watch = (not bool(getattr(args, 'no_watch', False)))
        mnt = self.get_mountpoint(name)
        if not mnt:
            log(f"Disk '{name}' is not mounted. Run 'open {name}' first.", 'ERROR')
            return

        # Determine filesystem type.
        fstype = ""
        try:
            res_fs = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'FSTYPE'], check=False)
            fstype = (getattr(res_fs, 'stdout', '') or '').strip().lower()
        except Exception:
            fstype = ""

        if fstype != "btrfs":
            log(f"Scrub requires btrfs, but {mnt} is '{fstype or 'unknown'}'.", 'ERROR')
            return

        # Block scrub on the system root drive.
        try:
            res_src = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'SOURCE'], check=False)
            src = (getattr(res_src, 'stdout', '') or '').strip()
            if src and self._block_if_root_drive(os.path.realpath(src), f"scrub {name}"):
                return
        except Exception:
            pass

        print(f"Scrubbing: {Colors.BOLD}{mnt}{Colors.ENDC} (fstype=btrfs)")
        if not self.extensive_confirm(f"scrub {name} ({mnt})", destructive=False):
            return

        run_command(['sudo', '-v'])
        start_ts = time.time()

        btrfs_bin = _find_tool_or_common_paths('btrfs', [
            '/usr/sbin/btrfs',
            '/sbin/btrfs',
            '/usr/local/sbin/btrfs',
            '/usr/bin/btrfs',
            '/bin/btrfs',
        ])
        if btrfs_bin is None:
            log("btrfs not found. Install 'btrfs-progs' and retry.", 'ERROR')
            return

        setfattr_bin = _find_tool_or_common_paths('setfattr', [
            '/usr/bin/setfattr',
            '/bin/setfattr',
            '/usr/sbin/setfattr',
            '/sbin/setfattr',
        ])

        def _watch_btrfs_checksum_errors(mountpoint, device_tag=None):
            """
            Best-effort: follow kernel logs and print checksum errors with resolved paths, while scrub runs.
            """
            since = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cmd_j = ['sudo', 'journalctl', '-k', '-b', '-f', '--since', since, '--no-pager', '-o', 'short-precise']
            try:
                proc = subprocess.Popen(cmd_j, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)
            except Exception as e:
                log(f"Failed to start journalctl watcher: {e}", 'WARN')
                return None, None

            stop = threading.Event()
            seen = set()

            def _resolve_paths(logical=None, ino=None):
                paths = []
                try:
                    if logical is not None:
                        res_l = run_command([btrfs_bin, 'inspect-internal', 'logical-resolve', str(logical), mountpoint],
                                            sudo=True, capture_output=True, check=False)
                        out_l = (getattr(res_l, 'stdout', '') or '').strip()
                        if out_l:
                            paths.extend(out_l.splitlines())
                    if ino is not None:
                        res_i = run_command([btrfs_bin, 'inspect-internal', 'inode-resolve', str(ino), mountpoint],
                                            sudo=True, capture_output=True, check=False)
                        out_i = (getattr(res_i, 'stdout', '') or '').strip()
                        if out_i:
                            paths.extend(out_i.splitlines())
                except Exception:
                    pass
                # Deduplicate while keeping order.
                uniq = []
                for p in paths:
                    p = p.strip()
                    if p and p not in uniq:
                        uniq.append(p)
                return uniq

            def _reader():
                # Typical kernel lines include "BTRFS ... csum failed" and/or "csum error at logical ...".
                re_logical = re.compile(r"\blogical\s+([0-9]+)\b", re.IGNORECASE)
                re_ino = re.compile(r"\bino\s+([0-9]+)\b", re.IGNORECASE)
                while not stop.is_set():
                    line = proc.stdout.readline() if proc.stdout else ""
                    if not line:
                        if proc.poll() is not None:
                            break
                        time.sleep(0.05)
                        continue
                    if "BTRFS" not in line and "btrfs" not in line:
                        continue
                    low = line.lower()
                    if "csum" not in low and "checksum" not in low:
                        continue
                    # If we know the device tag for this mount, prefer matching "(device <tag>)" to avoid unrelated noise.
                    if device_tag:
                        if re.search(rf"\\(device\\s+{re.escape(device_tag)}\\)", line, re.IGNORECASE) is None:
                            continue

                    logical = None
                    ino = None
                    m1 = re_logical.search(line)
                    if m1:
                        try:
                            logical = int(m1.group(1), 10)
                        except ValueError:
                            logical = None
                    m2 = re_ino.search(line)
                    if m2:
                        try:
                            ino = int(m2.group(1), 10)
                        except ValueError:
                            ino = None

                    # Dedupe aggressively to reduce spam: only print first occurrence per (logical, ino).
                    # If we can't parse either, skip (no actionable mapping).
                    if logical is None and ino is None:
                        continue
                    key = (logical, ino)
                    if key in seen:
                        continue
                    seen.add(key)

                    paths = _resolve_paths(logical=logical, ino=ino) if (logical is not None or ino is not None) else []
                    parts = []
                    if logical is not None:
                        parts.append(f"logical={logical}")
                    if ino is not None:
                        parts.append(f"ino={ino}")
                    head = ", ".join(parts) if parts else "checksum error"
                    suffix = (" " + " ".join([f"[{p}]" for p in paths])) if paths else ""
                    print(f"{Colors.FAIL}{Colors.BOLD}BTRFS checksum error:{Colors.ENDC} {head}{suffix}", flush=True)

            t = threading.Thread(target=_reader, daemon=True)
            t.start()
            return proc, stop

        try:
            watcher_proc = None
            watcher_stop = None
            if watch:
                import threading
                device_tag = None
                try:
                    res_src = run_command(['findmnt', '-rn', '-M', mnt, '-o', 'SOURCE'], check=False)
                    src = (getattr(res_src, 'stdout', '') or '').strip()
                    if src:
                        device_tag = os.path.basename(os.path.realpath(src))
                except Exception:
                    device_tag = None

                watcher_proc, watcher_stop = _watch_btrfs_checksum_errors(mnt, device_tag=device_tag)
                if watcher_proc:
                    log("Watching kernel logs for BTRFS checksum errors during scrub (deduped).")

            # -B blocks until complete; -R reports stats.
            res_scrub = run_command([btrfs_bin, 'scrub', 'start', '-B', '-R', mnt], sudo=True, capture_output=True, check=False)

            if watch and watcher_stop is not None:
                watcher_stop.set()
                try:
                    if watcher_proc:
                        watcher_proc.terminate()
                except Exception:
                    pass

            if (getattr(res_scrub, 'stdout', '') or '').strip():
                print((getattr(res_scrub, 'stdout', '') or '').rstrip())
            if (getattr(res_scrub, 'stderr', '') or '').strip():
                print((getattr(res_scrub, 'stderr', '') or '').rstrip(), file=sys.stderr)

            if setfattr_bin is None:
                log("setfattr not found. Install 'attr' and retry to record last_scrub.", 'WARN')
                return

            ds = ""
            try:
                res_date = run_command(['date'], capture_output=True, check=False)
                ds = (getattr(res_date, 'stdout', '') or '').strip()
            except Exception:
                ds = ""
            if not ds:
                ds = datetime.datetime.now().isoformat(sep=' ', timespec='seconds')

            run_command([setfattr_bin, '-n', 'user.last_scrub', '-v', ds, mnt], sudo=True, check=False)
            log(f"Recorded xattr: user.last_scrub={ds} on {mnt}")
        except Exception as e:
            log(f"Scrub failed: {e}", 'ERROR')
        finally:
            print(f"Duration: {_fmt_hms(time.time() - start_ts)}")

    def do_convert(self, arg):
        '''Convert ext4 -> btrfs in place (no data copy): convert <name/id>

        Uses btrfs-convert on an UNMOUNTED ext4 filesystem.
        - Plain ext4 targets are supported directly.
        - If target is crypto_LUKS, diskmgr tries to resolve the open payload device
          (e.g. /dev/mapper/<name> or a crypt child) and convert that.
        '''
        parser = CmdArgumentParser(prog='convert', add_help=False)
        parser.add_argument('target', help='Mapping name or discovery ID (#N)')
        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        target_in = args.target
        resolved = None
        if target_in.startswith('#') and target_in[1:].isdigit():
            # For convert, allow IDs from the full list row cache (disk/part/crypt),
            # not only the map/unmapped discovery subset.
            rid = target_in[1:]
            resolved = self.id_cache.get(rid)
            if not resolved:
                # Backward-compatible fallback to discovery-ID resolver.
                resolved = self.resolve_target(target_in, allow_id=True)
                if not resolved:
                    log(f"Unknown discovery ID: '{target_in}'. Run 'list' first to refresh IDs.", 'ERROR')
                    return
        else:
            resolved = self.resolve_target(target_in, allow_id=True)
        if not resolved:
            log(f"Unknown target: '{target_in}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        real_target = os.path.realpath(resolved)
        if not os.path.exists(real_target):
            log(f"Target not found: {real_target}", 'ERROR')
            return

        self.mappings = read_luks_map()
        mapping_name = target_in if target_in in self.mappings else None

        convert_dev = None
        convert_hint = ""
        fstype = (_lsblk_fstype(real_target) or "").strip().lower()
        dev_type = (_lsblk_type(real_target) or "").strip().lower()

        def _lsblk_rows(dev_path):
            rows = []
            res = run_command(['lsblk', '-nr', '-o', 'NAME,TYPE,FSTYPE', dev_path], check=False)
            for raw in (getattr(res, 'stdout', '') or '').splitlines():
                line = raw.strip()
                if not line:
                    continue
                parts = line.split(None, 2)
                if len(parts) < 2:
                    continue
                nm = parts[0].strip()
                ty = parts[1].strip().lower()
                fs = parts[2].strip().lower() if len(parts) >= 3 else ""
                rows.append({'name': nm, 'type': ty, 'fstype': fs})
            return rows

        if fstype == 'ext4':
            convert_dev = real_target
            convert_hint = "direct ext4 target"
        elif fstype == 'crypto_luks':
            payload_candidates = []

            if mapping_name:
                mapper_path = f"/dev/mapper/{mapping_name}"
                if os.path.exists(mapper_path):
                    mapper_real = os.path.realpath(mapper_path)
                    mapper_fs = (_lsblk_fstype(mapper_real) or "").strip().lower()
                    if mapper_fs == 'ext4':
                        payload_candidates.append((mapper_real, f"/dev/mapper/{mapping_name}"))

            for row in _lsblk_rows(real_target):
                if row.get('type') != 'crypt':
                    continue
                fs = (row.get('fstype') or "").strip().lower()
                if fs != 'ext4':
                    continue
                cdev = os.path.realpath(f"/dev/{row['name']}")
                payload_candidates.append((cdev, f"/dev/{row['name']}"))

            uniq = {}
            for path, hint in payload_candidates:
                uniq[path] = hint
            payload_candidates = [(p, h) for p, h in uniq.items()]

            if len(payload_candidates) == 1:
                convert_dev, convert_hint = payload_candidates[0]
            elif len(payload_candidates) > 1:
                log("Target is LUKS with multiple open ext4 payload candidates; refusing ambiguous conversion.", 'ERROR')
                for p, h in payload_candidates:
                    log(f"  candidate: {h} ({p})", 'ERROR')
                log("Map and convert the exact payload target explicitly.", 'ERROR')
                return
            else:
                log("Target is crypto_LUKS but no open ext4 payload device was detected.", 'ERROR')
                log("Open the LUKS container and ensure its payload is ext4 before converting.", 'ERROR')
                return
        elif dev_type == 'disk':
            parts = _lsblk_partitions(real_target)
            ext_parts = [p for p in parts if (p.get('fstype') or '').strip().lower() == 'ext4']
            if len(ext_parts) == 1:
                convert_dev = os.path.realpath(f"/dev/{ext_parts[0]['name']}")
                convert_hint = f"single ext4 partition /dev/{ext_parts[0]['name']}"
            elif len(ext_parts) > 1:
                log("Disk has multiple ext4 partitions; map and convert a single partition target explicitly.", 'ERROR')
                return
            else:
                log(f"No ext4 filesystem found on {real_target}.", 'ERROR')
                return
        else:
            log(f"Unsupported target type/fstype for convert: type={dev_type or '-'}, fstype={fstype or '-'}", 'ERROR')
            return

        convert_dev = os.path.realpath(convert_dev)
        if not os.path.exists(convert_dev):
            log(f"Resolved convert target does not exist: {convert_dev}", 'ERROR')
            return

        if self._block_if_root_drive(convert_dev, f"convert {target_in}"):
            return

        # convert requires an unmounted source filesystem.
        targets = find_mount_targets(convert_dev)
        if targets:
            log(f"OPERATION BLOCKED: {convert_dev} is mounted at {', '.join(targets)}. Unmount/close it first.", 'ERROR')
            return

        final_fs = (_lsblk_fstype(convert_dev) or "").strip().lower()
        if final_fs != 'ext4':
            log(f"Resolved target is '{final_fs or 'unknown'}', but convert currently supports ext4 -> btrfs only.", 'ERROR')
            return

        print(f"Converting: {Colors.BOLD}{convert_dev}{Colors.ENDC} ({convert_hint})")
        if not self.extensive_confirm(f"convert {target_in} ({convert_dev})", destructive=False):
            return

        run_command(['sudo', '-v'])
        log_path = _cmd_log_open("convert") if (_CMD_LOG_FH is None) else _CMD_LOG_PATH
        if log_path:
            print(f"Log: {log_path}")
        start_ts = time.time()

        try:
            btrfs_convert_bin = _find_tool_or_common_paths('btrfs-convert', [
                '/usr/sbin/btrfs-convert',
                '/sbin/btrfs-convert',
                '/usr/local/sbin/btrfs-convert',
                '/usr/bin/btrfs-convert',
                '/bin/btrfs-convert',
            ])
            if btrfs_convert_bin is None:
                log("btrfs-convert not found. Install 'btrfs-progs' and retry.", 'ERROR')
                return

            e2fsck_bin = _find_tool_or_common_paths('e2fsck', [
                '/usr/sbin/e2fsck',
                '/sbin/e2fsck',
                '/usr/local/sbin/e2fsck',
                '/usr/bin/e2fsck',
                '/bin/e2fsck',
            ])
            if e2fsck_bin:
                log(f"Running pre-conversion fsck: {e2fsck_bin} -f -p {convert_dev}")
                res_ck = run_command([e2fsck_bin, '-f', '-p', convert_dev], sudo=True, capture_output=True, check=False)
                if (getattr(res_ck, 'stdout', '') or '').strip():
                    print((getattr(res_ck, 'stdout', '') or '').rstrip())
                if (getattr(res_ck, 'stderr', '') or '').strip():
                    print((getattr(res_ck, 'stderr', '') or '').rstrip(), file=sys.stderr)
                if getattr(res_ck, 'returncode', 0) not in (0, 1):
                    log(f"Pre-conversion fsck failed with exit code {res_ck.returncode}. Aborting conversion.", 'ERROR')
                    return

            log(f"Running in-place conversion (streaming output): {btrfs_convert_bin} {convert_dev}")
            _cmd_log_write(f"CMD: sudo {btrfs_convert_bin} {convert_dev}")
            proc = subprocess.Popen(
                ['sudo', btrfs_convert_bin, convert_dev],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )
            try:
                if proc.stdout is not None:
                    for line in proc.stdout:
                        # Keep output live so conversions continue safely over flaky SSH.
                        print(line, end='', flush=True)
                        _cmd_log_write(line.rstrip("\n"))
            finally:
                try:
                    if proc.stdout is not None:
                        proc.stdout.close()
                except Exception:
                    pass
            rc = proc.wait()
            _cmd_log_write(f"RC: {rc}")

            if rc != 0:
                log(f"Conversion failed with exit code {rc}.", 'ERROR')
                return

            log("Conversion complete: ext4 -> btrfs.")
            log("Rollback data is kept by btrfs-convert. Avoid btrfs balance if you may need rollback.", 'WARN')
        finally:
            print(f"Duration: {_fmt_hms(time.time() - start_ts)}")
            _cmd_log_close()

    def do_format(self, arg):
        '''Format a superfloppy disk/partition volume: format <name/id> [options]
        
        Note: You must 'map' a disk first to give it a name before initializing it.
        
        NUANCES & SCOPE:
        1. Running format on a Partition (e.g., sda2)
           - Formats inside the existing partition boundary (plain or LUKS + payload FS).
           - Other partitions on the disk are untouched.

        2. Running format on a Whole Disk (e.g., sda)
           - Creates a superfloppy-style volume directly on the disk (plain or LUKS + payload FS).
           - Refuses if the disk already has a partition table (non-destructive policy).
           - To wipe partition metadata first, use: erase <name>
        
        Options:
          --fs <ext4|xfs|btrfs>   Filesystem type (default: ext4)
          --label <label>   Set a different internal filesystem label (other than <name>)
          --luks            Encrypt target first with LUKS2, then format payload filesystem

        UNDER THE HOOD:
        1.  Safety: Refuses to run if anything is mounted on the target device tree.
        2.  Disk Type Policy:
            - If target is a whole disk, it must be unpartitioned (no GPT/MBR table present).
            - If target is a partition, format is applied directly within that partition.
        3.  LUKS Format (only when --luks is used):
            - Uses 'passgen' to generate a master key.
            - Runs 'cryptsetup luksFormat' with LUKS2 encryption.
            - Opens the container as /dev/mapper/<name>.
        4.  Filesystem:
            - Plain mode (default): formats target directly with ext4, xfs, or btrfs.
            - --luks mode: formats the opened mapper payload with ext4, xfs, or btrfs.
            - (ext4 only): Reclaims the 5% reserved space for root using 'tune2fs -m 0'.
        5.  Persistence: Adds the new disk's PDP to diskmap.tsv automatically (best-effort).

        Note: This is a DESTRUCTIVE operation. Solving two math problems is MANDATORY to proceed.
        '''
        parser = CmdArgumentParser(prog='format', add_help=False)
        parser.add_argument('args', nargs=1, help='<name>')
        parser.add_argument('--fs', default='ext4', choices=['ext4', 'xfs', 'btrfs'])
        parser.add_argument('--label', help='Filesystem label')
        parser.add_argument('--luks', action='store_true', help='Encrypt target with LUKS2 before mkfs')

        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.args[0]
        target = self.resolve_target(name, allow_id=True)
        if not target:
            log(f"Unknown target: '{name}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        # Wait/Verify target existence
        real_target = os.path.realpath(target)
        if not os.path.exists(real_target):
            log(f"Target device not found: {target} (resolved: {real_target})", 'ERROR')
            return
            
        if self.is_root_disk(real_target):
            log(f"OPERATION BLOCKED: {real_target} is part of the system root drive!", 'ERROR')
            return

        log(f"Target: {real_target}")
        log(f"Name: {name}")
        
        # Safety checks
        if not self.extensive_confirm(f"{name} ({real_target})"):
            return

        run_command(['sudo', '-v'])

        # Refuse if anything on the target device tree is mounted.
        try:
            res_m = run_command(['lsblk', '-nr', '-o', 'MOUNTPOINT', real_target], check=False)
            mounts = [ln.strip() for ln in (getattr(res_m, 'stdout', '') or '').splitlines() if ln.strip()]
            if mounts:
                log(f"OPERATION BLOCKED: {real_target} has mounted filesystems ({', '.join(mounts)}). Unmount/close it first.", 'ERROR')
                return
        except Exception:
            pass

        crypt_target = real_target
        dev_type = _lsblk_type(real_target)

        if dev_type not in ('disk', 'part'):
            log(f"Unsupported target type for format: {dev_type or 'unknown'}. Map a disk or partition.", 'ERROR')
            return

        # Superfloppy mode only: whole disks must be unpartitioned.
        if dev_type == 'disk':
            try:
                res_pt = run_command(['lsblk', '-no', 'PTTYPE', real_target], check=False)
                pttype = (getattr(res_pt, 'stdout', '') or '').strip().lower()
            except Exception:
                pttype = ""
            if pttype:
                log(f"OPERATION BLOCKED: {real_target} is partitioned ({pttype}). Refusing to format a whole-disk superfloppy over an existing partition table.", 'ERROR')
                log("Use erase <name> first to wipe partition metadata, then run format again.", 'ERROR')
                return

        if args.luks:
            # LUKS Format
            log(f"Formatting LUKS on {crypt_target}...")
            pg_cmd = subprocess.Popen([PASSGEN_BIN], stdout=subprocess.PIPE, text=True)
            try:
                run_command(
                    ['cryptsetup', 'luksFormat', '--type', 'luks2', '--batch-mode', '--key-file', '-', crypt_target],
                    input_str=pg_cmd.communicate()[0],
                    sudo=True,
                    check=True
                )
            except Exception as e:
                log(f"LUKS Format failed: {e}", 'ERROR')
                return

            # Open
            log("Opening new LUKS volume...")
            pg_cmd = subprocess.Popen([PASSGEN_BIN], stdout=subprocess.PIPE, text=True)
            run_command(
                ['cryptsetup', 'open', '--key-file', '-', crypt_target, name],
                input_str=pg_cmd.communicate()[0],
                sudo=True,
                check=True
            )
            fs_target = f"/dev/mapper/{name}"
        else:
            log("Using plain format mode (no LUKS).")
            fs_target = crypt_target

        # Mkfs
        label = args.label if args.label else name
        log(f"Formatting filesystem {args.fs} (label={label}) on {fs_target}...")
        
        if args.fs == 'ext4':
            run_command(['mkfs.ext4', '-F', '-L', label, fs_target], sudo=True)
            log("Reclaiming 5% reserved space (tune2fs -m 0)...")
            run_command(['tune2fs', '-m', '0', fs_target], sudo=True)
        elif args.fs == 'xfs':
            run_command(['mkfs.xfs', '-f', '-L', label, fs_target], sudo=True)
        elif args.fs == 'btrfs':
            mkfs_btrfs = _find_tool_or_common_paths('mkfs.btrfs', [
                '/usr/sbin/mkfs.btrfs',
                '/sbin/mkfs.btrfs',
                '/usr/local/sbin/mkfs.btrfs',
            ]) or 'mkfs.btrfs'
            # -f required because we just wipefs'ed; still safer to be explicit.
            run_command([mkfs_btrfs, '-f', '-L', label, fs_target], sudo=True)

        # Mount (prefer /etc/fstab mountpoint when an entry exists for this filesystem).
        fallback_mountpoint = f"/media/{os.environ.get('USER', 'root')}/{label}"
        mountpoint, use_fstab_mount, fstab_entry = self._select_mountpoint_for_device(
            fs_target,
            fallback_mountpoint,
            preferred_label=label
        )
        if use_fstab_mount:
            log(f"Using fstab mount after format: {fstab_entry['spec']} -> {mountpoint}")
        
        # Safety Check: Is this mountpoint already in use by another device?
        res_check = run_command(['findmnt', '-rn', '-M', mountpoint], check=False)
        if res_check.returncode == 0:
            res_src = run_command(['findmnt', '-rn', '-M', mountpoint, '-o', 'SOURCE'], capture_output=True)
            current_src = os.path.realpath(res_src.stdout.strip())
            if current_src != os.path.realpath(fs_target):
                log(f"MOUNT BLOCKED: Path {mountpoint} is already in use by {current_src}.", 'ERROR')
                log("Disk was initialized successfully, but could not be mounted at the preferred path.", 'WARN')
                return

        self._mount_device(fs_target, mountpoint, use_fstab=use_fstab_mount)
        self._chown_new_filesystem_root(mountpoint)

        # Update map if needed
        self.mappings = read_luks_map()
        if name not in self.mappings:
            stable_path = crypt_target
            # Try to find by-id
            pdp = self.find_persistent_path(os.path.basename(crypt_target))
            if pdp != '-':
                stable_path = pdp
            
            self.mappings[name] = stable_path
            save_luks_map(self.mappings)
            log(f"Added mapping: {name} -> {stable_path}")

        log("Disk initialization complete.")

    def do_create(self, arg):
        '''Create partition table or partition on a whole disk: create <name/id> [--gpt|--mbr] [--partition] [--start X] [--end Y]

        Scope:
          - Whole disks only (not partitions).
          - Table creation requires prior erase: target must look erased (no partitions, no PT metadata, no signatures).
          - Partition-only mode can add a partition to an existing partitioned disk.

        Actions:
          - --gpt / --mbr: create a new partition table (erased disk only)
          - --partition:
              * with --gpt/--mbr: create first partition after table creation
              * without --gpt/--mbr: create an additional partition on existing table
              * when --start/--end are omitted, the largest free extent is selected automatically
              * overlapping ranges are rejected; existing partitions are not overwritten

        Examples:
          erase 1b
          create 1b --gpt
          create 1b --gpt --partition
          create 1b --partition
          create 1b --partition --start 500GiB --end 100%
          create #4 --mbr --partition
        '''
        parser = CmdArgumentParser(prog='create', add_help=False)
        parser.add_argument('target', help='Whole-disk target mapping name or discovery ID (#N)')
        group = parser.add_mutually_exclusive_group(required=False)
        group.add_argument('--gpt', action='store_true', help='Create GPT partition table')
        group.add_argument('--mbr', action='store_true', help='Create MBR (msdos) partition table')
        parser.add_argument('--partition', action='store_true', help='Create partition (new table first if --gpt/--mbr is provided)')
        parser.add_argument('--start', help='Partition start (parted syntax, e.g. 1MiB, 500GiB, 2048s)')
        parser.add_argument('--end', help='Partition end (parted syntax, e.g. 100%, 750GiB)')

        try:
            split_args = shlex.split(arg)
            args = parser.parse_args(split_args)
        except argparse.ArgumentError as e:
            log(str(e), 'ERROR')
            return
        except SystemExit:
            return

        name = args.target
        real_target = self.resolve_target(name, allow_id=True)

        if not real_target:
            log(f"Unknown target: '{name}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        if not os.path.exists(real_target):
            log(f"Target not found: {real_target}", 'ERROR')
            return

        real_target = os.path.realpath(real_target)
        if self._block_if_root_drive(real_target, f"create {name}"):
            return

        if _lsblk_type(real_target) != 'disk':
            log(f"create only supports whole-disk targets. '{name}' resolved to {real_target} ({_lsblk_type(real_target) or 'unknown'}).", 'ERROR')
            return

        if not args.gpt and not args.mbr and not args.partition:
            log("Usage: create <name/id> [--gpt|--mbr] [--partition] [--start X] [--end Y]", 'ERROR')
            log("Provide --gpt/--mbr to create a table, and/or --partition to create a partition.", 'ERROR')
            return

        # Refuse to operate on mounted devices.
        try:
            res_m = run_command(['lsblk', '-nr', '-o', 'MOUNTPOINT', real_target], check=False)
            mounts = [ln.strip() for ln in (getattr(res_m, 'stdout', '') or '').splitlines() if ln.strip()]
            if mounts:
                log(f"OPERATION BLOCKED: {real_target} has mounted filesystems ({', '.join(mounts)}). Unmount/close it first.", 'ERROR')
                return
        except Exception:
            pass

        creating_table = args.gpt or args.mbr
        creating_partition = args.partition

        table = 'gpt' if args.gpt else ('msdos' if args.mbr else None)
        p_start = args.start
        p_end = args.end

        if creating_table:
            erased_ok, erased_reason = self._disk_looks_erased_for_create(real_target)
            if not erased_ok:
                log(f"OPERATION BLOCKED: create requires erase first; {erased_reason}.", 'ERROR')
                log(f"Run: erase {name}", 'ERROR')
                return

        if creating_partition and not creating_table:
            # Existing table required when creating an additional partition.
            try:
                res_pt = run_command(['lsblk', '-no', 'PTTYPE', real_target], check=False)
                pttype = (getattr(res_pt, 'stdout', '') or '').strip().lower()
            except Exception:
                pttype = ""
            if not pttype:
                log("OPERATION BLOCKED: no partition table found on target disk. Create one first with --gpt or --mbr.", 'ERROR')
                return

            if p_end and not p_start:
                log("Invalid partition range: --end requires --start when adding to an existing table.", 'ERROR')
                return

            # Auto-place in largest free extent when no explicit start/end is provided.
            if not p_start and not p_end:
                extent = self._largest_free_extent_sectors(real_target)
                if not extent:
                    log("No free extent found for new partition.", 'ERROR')
                    return
                p_start = f"{extent[0]}s"
                p_end = f"{extent[1]}s"
                # Ignore tiny gaps (e.g., 34s..2047s on GPT/MBR).
                if extent[2] < 4096:
                    log("Largest free extent is too small to create a useful partition.", 'ERROR')
                    return

        if creating_partition and creating_table:
            if not p_start:
                p_start = '1MiB'
            if not p_end:
                p_end = '100%'

        action_parts = []
        if creating_table:
            action_parts.append(f"create {table} table")
        if creating_partition:
            action_parts.append(f"create partition ({p_start or '?'}..{p_end or '?'})")
        action = " + ".join(action_parts)
        log(f"Planned action on {real_target}: {action}")

        if not self.extensive_confirm(real_target):
            return

        run_command(['sudo', '-v'])
        if creating_table:
            run_command(['parted', '-s', real_target, 'mklabel', table], sudo=True)

        if creating_partition:
            run_command(['parted', '-s', real_target, 'mkpart', 'primary', p_start, p_end], sudo=True)

        run_command(['udevadm', 'settle'], sudo=True, check=False)
        run_command(['partprobe', real_target], sudo=True, check=False)

        if creating_partition:
            created_parts = []
            try:
                res_p = run_command(['lsblk', '-nr', '-o', 'NAME,TYPE', real_target], check=False)
                for line in (getattr(res_p, 'stdout', '') or '').splitlines():
                    cols = line.strip().split()
                    if len(cols) >= 2 and cols[1] == 'part':
                        created_parts.append(f"/dev/{cols[0]}")
            except Exception:
                created_parts = []

            if created_parts:
                if creating_table:
                    log(f"Created partition table ({table}) and partition(s): {', '.join(created_parts)}")
                else:
                    log(f"Created partition(s): {', '.join(created_parts)}")
            else:
                if creating_table:
                    log(f"Created partition table ({table}) and requested one partition.", 'WARN')
                else:
                    log("Requested partition creation completed, but no new partition was detected.", 'WARN')
        elif creating_table:
            log(f"Created empty partition table: {table} on {real_target}")

    def do_remove(self, arg):
        '''Remove a partition from its parent disk: remove <name/id>

        Scope:
          - Partition targets only.
          - Whole-disk targets are refused.
        '''
        target = arg.strip()
        if not target:
            log("Usage: remove <name/id>", 'ERROR')
            return

        resolved = self.resolve_target(target, allow_id=True)
        if not resolved:
            log(f"Unknown target: '{target}'. Use a mapping name or discovery ID (#N).", 'ERROR')
            log("Tip: run 'list' first to refresh discovery IDs.", 'ERROR')
            return

        part_dev = os.path.realpath(resolved)
        if not os.path.exists(part_dev):
            log(f"Target not found: {part_dev}", 'ERROR')
            return

        if self._block_if_root_drive(part_dev, f"remove {target}"):
            return

        if _lsblk_type(part_dev) != 'part':
            log(f"remove only supports partitions. '{target}' resolved to {part_dev} ({_lsblk_type(part_dev) or 'unknown'}).", 'ERROR')
            return

        # Refuse to remove mounted partition.
        try:
            res_m = run_command(['lsblk', '-nr', '-o', 'MOUNTPOINT', part_dev], check=False)
            mounts = [ln.strip() for ln in (getattr(res_m, 'stdout', '') or '').splitlines() if ln.strip()]
            if mounts:
                log(f"OPERATION BLOCKED: {part_dev} is mounted at {', '.join(mounts)}. Unmount/close it first.", 'ERROR')
                return
        except Exception:
            pass

        # Find parent disk and partition number.
        res_pk = run_command(['lsblk', '-no', 'PKNAME', part_dev], check=False)
        pkname = (getattr(res_pk, 'stdout', '') or '').strip()
        res_partn = run_command(['lsblk', '-no', 'PARTN', part_dev], check=False)
        partn = (getattr(res_partn, 'stdout', '') or '').strip()
        if not pkname or not partn:
            log(f"Could not determine parent disk/partition number for {part_dev}.", 'ERROR')
            return

        parent_disk = f"/dev/{pkname}"
        if self._block_if_root_drive(parent_disk, f"remove {target}"):
            return

        log(f"Planned action: remove partition {part_dev} (part #{partn}) from {parent_disk}")
        if not self.extensive_confirm(part_dev):
            return

        run_command(['sudo', '-v'])
        run_command(['parted', '-s', parent_disk, 'rm', partn], sudo=True)
        run_command(['udevadm', 'settle'], sudo=True, check=False)
        run_command(['partprobe', parent_disk], sudo=True, check=False)

        log(f"Removed partition {part_dev} from {parent_disk}")


if __name__ == '__main__':
    try:
        os.chmod(__file__, 0o755)
    except:
        pass
    try:
        DiskMgrShell().cmdloop()
    except KeyboardInterrupt:
        print("\nExiting...")
